{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07f61d0a",
      "metadata": {
        "id": "07f61d0a"
      },
      "source": [
        "–ó–∞–¥–∞—á–∞\n",
        "\n",
        "üî∏–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –∏ –∑–ª–æ–Ω–∞–º–µ—Ä–µ–Ω–Ω—ã–π. –ü—Ä–∏ —ç—Ç–æ–º –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ü–µ–Ω–∞ –æ—à–∏–±–∫–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞.\n",
        "üî∏–û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: precision, recall, f1_score, accuracy.\n",
        "üî∏(*) –î–µ–ø–ª–æ–π: —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å REST API —Å–µ—Ä–≤–∏—Å, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –¥–∞–Ω–Ω—ã–µ —Ç—Ä–∞—Ñ–∏–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∫–ª–∞—Å—Å —ç—Ç–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7e09a0",
      "metadata": {
        "id": "bb7e09a0"
      },
      "source": [
        "## –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96b51a4",
      "metadata": {
        "id": "e96b51a4"
      },
      "source": [
        "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6874331c",
      "metadata": {
        "id": "6874331c"
      },
      "source": [
        "#### –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5d4e52aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5d4e52aa",
        "outputId": "79640f37-cd9a-42ff-d737-a8d5e3af1063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Options for pandas\n",
        "pd.options.display.max_columns = 50\n",
        "pd.options.display.max_rows = 30\n",
        "\n",
        "# Display all cell outputs\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "\n",
        "\n",
        "# autoreload extension\n",
        "if 'autoreload' not in ipython.extension_manager.loaded:\n",
        "    %load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "#ml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "%pip install catboost\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cc4457cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4457cc",
        "outputId": "b7974d22-901e-4531-9ca3-96347d860553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "#!pip install phik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1742d590",
      "metadata": {
        "id": "1742d590"
      },
      "outputs": [],
      "source": [
        "#–Ω–µ–º–Ω–æ–≥–æ –æ–ø—Ü–∏–π –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
        "\n",
        "pd.options.display.max_rows = 80\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "large = 16; med = 12; small = 10\n",
        "params = {'axes.titlesize': large,\n",
        "          'legend.fontsize': med,\n",
        "          'figure.figsize': (12, 8),\n",
        "          'axes.labelsize': med,\n",
        "          'axes.titlesize': med,\n",
        "          'xtick.labelsize': med,\n",
        "          'ytick.labelsize': med,\n",
        "          'figure.titlesize': large}\n",
        "\n",
        "plt.rcParams.update(params)\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "sns.set_palette('deep')\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3af9022c",
      "metadata": {
        "id": "3af9022c"
      },
      "source": [
        "#### –ó–∞–≥—Ä—É–∑–∫–∞  —Ñ–∞–π–ª–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bdK2H5MkFEkr",
      "metadata": {
        "id": "bdK2H5MkFEkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07704d25-399a-4edf-f84b-dee15c2fe54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ —Å –ì—É–≥–ª –¥–∏—Å–∫–∞\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e10da3d",
      "metadata": {
        "id": "1e10da3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9bdd81-f20e-44df-fd55-f8c7d0010bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ\n"
          ]
        }
      ],
      "source": [
        "# –∑–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã\n",
        "\n",
        "pth1='https://disk.yandex.ru/d/QYraoEwmfQZ90Q'\n",
        "pth2='/home/alexandra/data_science/network_traffic_data.csv'\n",
        "pth3='/content/gdrive/MyDrive/network_traffic_data.csv'\n",
        "\n",
        "try:\n",
        "    if os.path.exists(pth1):\n",
        "        data = pd.read_csv(pth1, delimiter='\\,')\n",
        "    elif os.path.exists(pth2):\n",
        "        data = pd.read_csv(pth2, delimiter='\\,')\n",
        "    else:\n",
        "        data = pd.read_csv(pth3, delimiter='\\,')\n",
        "\n",
        "    print('–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ')\n",
        "\n",
        "except:\n",
        "    print('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ca3651",
      "metadata": {
        "id": "94ca3651"
      },
      "source": [
        "#### –ü–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ba02410f",
      "metadata": {
        "id": "ba02410f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "156072d9-bcb2-41ef-fb57-d33f0fdae041"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Destination Port   Flow Duration   Total Fwd Packets  \\\n",
              "0                     80         5480074                   3   \n",
              "1                    443          711977                   9   \n",
              "2                     53          153398                   2   \n",
              "3                     53           57660                   1   \n",
              "4                   8446             767                   3   \n",
              "...                  ...             ...                 ...   \n",
              "539611                80        11512204                   8   \n",
              "539612                80        11513325                   5   \n",
              "539613                80        11509201                   7   \n",
              "539614                80        11509095                   8   \n",
              "539615                80        11512230                   5   \n",
              "\n",
              "         Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "0                             1                           12   \n",
              "1                            10                          703   \n",
              "2                             2                           80   \n",
              "3                             1                           46   \n",
              "4                             1                           43   \n",
              "...                         ...                          ...   \n",
              "539611                        5                          326   \n",
              "539612                        5                          471   \n",
              "539613                        6                          314   \n",
              "539614                        5                          369   \n",
              "539615                        5                          672   \n",
              "\n",
              "         Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
              "0                                  0                       6   \n",
              "1                               3950                     267   \n",
              "2                                224                      40   \n",
              "3                                128                      46   \n",
              "4                                  6                      31   \n",
              "...                              ...                     ...   \n",
              "539611                         11632                     326   \n",
              "539612                          3525                     471   \n",
              "539613                         11632                     314   \n",
              "539614                         11632                     369   \n",
              "539615                          3525                     672   \n",
              "\n",
              "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
              "0                            0                    4.000   \n",
              "1                            0                   78.100   \n",
              "2                           40                   40.000   \n",
              "3                           46                   46.000   \n",
              "4                            6                   14.336   \n",
              "...                        ...                      ...   \n",
              "539611                       0                   40.750   \n",
              "539612                       0                   94.200   \n",
              "539613                       0                   44.840   \n",
              "539614                       0                   46.120   \n",
              "539615                       0                  134.400   \n",
              "\n",
              "         Fwd Packet Length Std  Bwd Packet Length Max   Bwd Packet Length Min  \\\n",
              "0                        3.465                      0                       0   \n",
              "1                      103.300                   1448                       0   \n",
              "2                        0.000                    112                     112   \n",
              "3                        0.000                    128                     128   \n",
              "4                       14.440                      6                       6   \n",
              "...                        ...                    ...                     ...   \n",
              "539611                 115.250                  10184                       0   \n",
              "539612                 210.600                   2077                       0   \n",
              "539613                 118.700                   5792                       0   \n",
              "539614                 130.500                  10184                       0   \n",
              "539615                 300.500                   2077                       0   \n",
              "\n",
              "         Bwd Packet Length Mean   Bwd Packet Length Std  Flow Bytes/s  \\\n",
              "0                           0.0                     0.0      2.189751   \n",
              "1                         395.0                   587.5   6535.323473   \n",
              "2                         112.0                     0.0   1981.772904   \n",
              "3                         128.0                     0.0   3017.689906   \n",
              "4                           6.0                     0.0  63885.267280   \n",
              "...                         ...                     ...           ...   \n",
              "539611                   2326.0                  4436.0   1038.723775   \n",
              "539612                    705.0                   990.5    347.076105   \n",
              "539613                   1939.0                  2544.0   1037.952157   \n",
              "539614                   2326.0                  4436.0   1042.740546   \n",
              "539615                    705.0                   990.5    364.568811   \n",
              "\n",
              "         Flow Packets/s   Flow IAT Mean   Flow IAT Std   Flow IAT Max  \\\n",
              "0              0.729917    1.826691e+06   3.131700e+06        5442804   \n",
              "1             26.686255    3.955428e+04   5.015462e+04         120501   \n",
              "2             26.075959    5.113267e+04   8.855831e+04         153391   \n",
              "3             34.686091    5.766000e+04   0.000000e+00          57660   \n",
              "4           5215.123859    2.556667e+02   3.942896e+02            710   \n",
              "...                 ...             ...            ...            ...   \n",
              "539611         1.129236    9.593503e+05   2.262616e+06        6507197   \n",
              "539612         0.868559    1.279258e+06   2.565153e+06        6508582   \n",
              "539613         1.129531    9.591001e+05   2.261842e+06        6503248   \n",
              "539614         1.129541    9.590912e+05   2.262122e+06        6504954   \n",
              "539615         0.868641    1.279137e+06   2.565060e+06        6506213   \n",
              "\n",
              "         Flow IAT Min  Fwd IAT Total   Fwd IAT Mean   Fwd IAT Std  \\\n",
              "0                 101        5480074    2740037.000  3.822290e+06   \n",
              "1                   1         616301      77037.625  7.299598e+04   \n",
              "2                   3              3          3.000  0.000000e+00   \n",
              "3               57660              0          0.000  0.000000e+00   \n",
              "4                   3            713        356.500  4.999245e+02   \n",
              "...               ...            ...            ...           ...   \n",
              "539611              1        6510770     930110.000  2.460477e+06   \n",
              "539612             53        6512631    1628157.800  3.255639e+06   \n",
              "539613             46        6507056    1084509.400  2.655701e+06   \n",
              "539614             47        6507794     929684.900  2.458891e+06   \n",
              "539615              4        6509115    1627278.800  3.253892e+06   \n",
              "\n",
              "         Fwd IAT Max   Fwd IAT Min  Bwd IAT Total   Bwd IAT Mean  \\\n",
              "0            5442804         37270              0          0.000   \n",
              "1             215614           230         616874      68541.555   \n",
              "2                  3             3              4          4.000   \n",
              "3                  0             0              0          0.000   \n",
              "4                710             3              0          0.000   \n",
              "...              ...           ...            ...            ...   \n",
              "539611       6509948             1       11500000    2878039.500   \n",
              "539612       6511616           176       11500000    2878318.000   \n",
              "539613       6505437           255       11500000    2301830.500   \n",
              "539614       6505926           168       11500000    2877262.000   \n",
              "539615       6508117             4       11500000    2878045.500   \n",
              "\n",
              "         Bwd IAT Std   Bwd IAT Max   Bwd IAT Min  Fwd PSH Flags  \\\n",
              "0               0.00             0             0              0   \n",
              "1           71985.97        199836             1              0   \n",
              "2               0.00             4             4              0   \n",
              "3               0.00             0             0              0   \n",
              "4               0.00             0             0              0   \n",
              "...              ...           ...           ...            ...   \n",
              "539611    3378874.20       6507197           196              0   \n",
              "539612    3379306.00       6508582           192              0   \n",
              "539613    3195689.20       6503248            47              0   \n",
              "539614    3377879.00       6504954           196              0   \n",
              "539615    3378842.00       6506213            49              0   \n",
              "\n",
              "         Bwd PSH Flags   Fwd URG Flags   Bwd URG Flags   Fwd Header Length  \\\n",
              "0                    0               0               0                  72   \n",
              "1                    0               0               0                 296   \n",
              "2                    0               0               0                  40   \n",
              "3                    0               0               0                  20   \n",
              "4                    0               0               0                  60   \n",
              "...                ...             ...             ...                 ...   \n",
              "539611               0               0               0                 264   \n",
              "539612               0               0               0                 168   \n",
              "539613               0               0               0                 232   \n",
              "539614               0               0               0                 264   \n",
              "539615               0               0               0                 168   \n",
              "\n",
              "         Bwd Header Length  Fwd Packets/s   Bwd Packets/s   Min Packet Length  \\\n",
              "0                       32       0.547438        0.182479                   0   \n",
              "1                      328      12.640858       14.045398                   0   \n",
              "2                       40      13.037980       13.037980                  40   \n",
              "3                       20      17.343046       17.343046                  46   \n",
              "4                       20    3911.342800     1303.781000                   6   \n",
              "...                    ...            ...             ...                 ...   \n",
              "539611                 168       0.694915        0.434322                   0   \n",
              "539612                 168       0.434279        0.434279                   0   \n",
              "539613                 200       0.608209        0.521322                   0   \n",
              "539614                 168       0.695102        0.434439                   0   \n",
              "539615                 168       0.434321        0.434321                   0   \n",
              "\n",
              "         Max Packet Length   Packet Length Mean   Packet Length Std  \\\n",
              "0                        6                  2.4               3.287   \n",
              "1                     1448                232.6             442.800   \n",
              "2                      112                 68.8              39.440   \n",
              "3                      128                 73.3              47.340   \n",
              "4                       31                 11.0              11.180   \n",
              "...                    ...                  ...                 ...   \n",
              "539611               10184                854.0            2714.000   \n",
              "539612                2077                363.2             720.000   \n",
              "539613                5792                853.5            1857.000   \n",
              "539614               10184                857.0            2712.000   \n",
              "539615                2077                381.5             725.500   \n",
              "\n",
              "         Packet Length Variance  FIN Flag Count   SYN Flag Count  \\\n",
              "0                  1.080000e+01               0                0   \n",
              "1                  1.960127e+05               0                0   \n",
              "2                  1.555200e+03               0                0   \n",
              "3                  2.241333e+03               0                0   \n",
              "4                  1.250000e+02               0                0   \n",
              "...                         ...             ...              ...   \n",
              "539611             7.361769e+06               0                0   \n",
              "539612             5.180836e+05               0                0   \n",
              "539613             3.449144e+06               0                0   \n",
              "539614             7.358407e+06               0                0   \n",
              "539615             5.260871e+05               0                0   \n",
              "\n",
              "         RST Flag Count   PSH Flag Count   ACK Flag Count   URG Flag Count  \\\n",
              "0                     0                1                0                0   \n",
              "1                     0                1                0                0   \n",
              "2                     0                0                0                0   \n",
              "3                     0                0                0                0   \n",
              "4                     0                0                1                0   \n",
              "...                 ...              ...              ...              ...   \n",
              "539611                0                1                0                0   \n",
              "539612                0                1                0                0   \n",
              "539613                0                1                0                0   \n",
              "539614                0                1                0                0   \n",
              "539615                0                1                0                0   \n",
              "\n",
              "         CWE Flag Count   ECE Flag Count   Down/Up Ratio  \\\n",
              "0                     0                0               0   \n",
              "1                     0                0               1   \n",
              "2                     0                0               1   \n",
              "3                     0                0               1   \n",
              "4                     0                0               0   \n",
              "...                 ...              ...             ...   \n",
              "539611                0                0               0   \n",
              "539612                0                0               1   \n",
              "539613                0                0               0   \n",
              "539614                0                0               0   \n",
              "539615                0                0               1   \n",
              "\n",
              "         Average Packet Size   Avg Fwd Segment Size   Avg Bwd Segment Size  \\\n",
              "0                       3.00                  4.000                    0.0   \n",
              "1                     244.90                 78.100                  395.0   \n",
              "2                      86.00                 40.000                  112.0   \n",
              "3                     110.00                 46.000                  128.0   \n",
              "4                      13.75                 14.336                    6.0   \n",
              "...                      ...                    ...                    ...   \n",
              "539611                920.00                 40.750                 2326.0   \n",
              "539612                399.50                 94.200                  705.0   \n",
              "539613                919.00                 44.840                 1939.0   \n",
              "539614                923.00                 46.120                 2326.0   \n",
              "539615                419.80                134.400                  705.0   \n",
              "\n",
              "         Fwd Header Length.1  Fwd Avg Bytes/Bulk   Fwd Avg Packets/Bulk  \\\n",
              "0                         72                   0                      0   \n",
              "1                        296                   0                      0   \n",
              "2                         40                   0                      0   \n",
              "3                         20                   0                      0   \n",
              "4                         60                   0                      0   \n",
              "...                      ...                 ...                    ...   \n",
              "539611                   264                   0                      0   \n",
              "539612                   168                   0                      0   \n",
              "539613                   232                   0                      0   \n",
              "539614                   264                   0                      0   \n",
              "539615                   168                   0                      0   \n",
              "\n",
              "         Fwd Avg Bulk Rate   Bwd Avg Bytes/Bulk   Bwd Avg Packets/Bulk  \\\n",
              "0                        0                    0                      0   \n",
              "1                        0                    0                      0   \n",
              "2                        0                    0                      0   \n",
              "3                        0                    0                      0   \n",
              "4                        0                    0                      0   \n",
              "...                    ...                  ...                    ...   \n",
              "539611                   0                    0                      0   \n",
              "539612                   0                    0                      0   \n",
              "539613                   0                    0                      0   \n",
              "539614                   0                    0                      0   \n",
              "539615                   0                    0                      0   \n",
              "\n",
              "        Bwd Avg Bulk Rate  Subflow Fwd Packets   Subflow Fwd Bytes  \\\n",
              "0                       0                    3                  12   \n",
              "1                       0                    9                 703   \n",
              "2                       0                    2                  80   \n",
              "3                       0                    1                  46   \n",
              "4                       0                    3                  43   \n",
              "...                   ...                  ...                 ...   \n",
              "539611                  0                    8                 326   \n",
              "539612                  0                    5                 471   \n",
              "539613                  0                    7                 314   \n",
              "539614                  0                    8                 369   \n",
              "539615                  0                    5                 672   \n",
              "\n",
              "         Subflow Bwd Packets   Subflow Bwd Bytes  Init_Win_bytes_forward  \\\n",
              "0                          1                   0                    8192   \n",
              "1                         10                3950                   29200   \n",
              "2                          2                 224                      -1   \n",
              "3                          1                 128                      -1   \n",
              "4                          1                   6                    1017   \n",
              "...                      ...                 ...                     ...   \n",
              "539611                     5               11632                   29200   \n",
              "539612                     5                3525                   29200   \n",
              "539613                     6               11632                   29200   \n",
              "539614                     5               11632                   29200   \n",
              "539615                     5                3525                   29200   \n",
              "\n",
              "         Init_Win_bytes_backward   act_data_pkt_fwd   min_seg_size_forward  \\\n",
              "0                          42780                  2                     20   \n",
              "1                            252                  4                     32   \n",
              "2                             -1                  1                     20   \n",
              "3                             -1                  0                     20   \n",
              "4                              0                  2                     20   \n",
              "...                          ...                ...                    ...   \n",
              "539611                       235                  1                     32   \n",
              "539612                       235                  1                     32   \n",
              "539613                       235                  1                     32   \n",
              "539614                       235                  1                     32   \n",
              "539615                       237                  1                     32   \n",
              "\n",
              "        Active Mean   Active Std   Active Max   Active Min  Idle Mean  \\\n",
              "0               0.0          0.0            0            0        0.0   \n",
              "1               0.0          0.0            0            0        0.0   \n",
              "2               0.0          0.0            0            0        0.0   \n",
              "3               0.0          0.0            0            0        0.0   \n",
              "4               0.0          0.0            0            0        0.0   \n",
              "...             ...          ...          ...          ...        ...   \n",
              "539611        892.0          0.0          892          892  6507197.0   \n",
              "539612        918.0          0.0          918          918  6508582.0   \n",
              "539613        899.0          0.0          899          899  6503248.0   \n",
              "539614        914.0          0.0          914          914  6504954.0   \n",
              "539615        821.0          0.0          821          821  6506213.0   \n",
              "\n",
              "         Idle Std   Idle Max   Idle Min          Label  \n",
              "0             0.0          0          0         BENIGN  \n",
              "1             0.0          0          0         BENIGN  \n",
              "2             0.0          0          0         BENIGN  \n",
              "3             0.0          0          0         BENIGN  \n",
              "4             0.0          0          0         BENIGN  \n",
              "...           ...        ...        ...            ...  \n",
              "539611        0.0    6507197    6507197  DoS GoldenEye  \n",
              "539612        0.0    6508582    6508582  DoS GoldenEye  \n",
              "539613        0.0    6503248    6503248  DoS GoldenEye  \n",
              "539614        0.0    6504954    6504954  DoS GoldenEye  \n",
              "539615        0.0    6506213    6506213  DoS GoldenEye  \n",
              "\n",
              "[539616 rows x 79 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed5fec85-e92e-426c-816b-3add1a597a70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>80</td>\n",
              "      <td>5480074</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4.000</td>\n",
              "      <td>3.465</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.189751</td>\n",
              "      <td>0.729917</td>\n",
              "      <td>1.826691e+06</td>\n",
              "      <td>3.131700e+06</td>\n",
              "      <td>5442804</td>\n",
              "      <td>101</td>\n",
              "      <td>5480074</td>\n",
              "      <td>2740037.000</td>\n",
              "      <td>3.822290e+06</td>\n",
              "      <td>5442804</td>\n",
              "      <td>37270</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>32</td>\n",
              "      <td>0.547438</td>\n",
              "      <td>0.182479</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.287</td>\n",
              "      <td>1.080000e+01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8192</td>\n",
              "      <td>42780</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>443</td>\n",
              "      <td>711977</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>703</td>\n",
              "      <td>3950</td>\n",
              "      <td>267</td>\n",
              "      <td>0</td>\n",
              "      <td>78.100</td>\n",
              "      <td>103.300</td>\n",
              "      <td>1448</td>\n",
              "      <td>0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>587.5</td>\n",
              "      <td>6535.323473</td>\n",
              "      <td>26.686255</td>\n",
              "      <td>3.955428e+04</td>\n",
              "      <td>5.015462e+04</td>\n",
              "      <td>120501</td>\n",
              "      <td>1</td>\n",
              "      <td>616301</td>\n",
              "      <td>77037.625</td>\n",
              "      <td>7.299598e+04</td>\n",
              "      <td>215614</td>\n",
              "      <td>230</td>\n",
              "      <td>616874</td>\n",
              "      <td>68541.555</td>\n",
              "      <td>71985.97</td>\n",
              "      <td>199836</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>328</td>\n",
              "      <td>12.640858</td>\n",
              "      <td>14.045398</td>\n",
              "      <td>0</td>\n",
              "      <td>1448</td>\n",
              "      <td>232.6</td>\n",
              "      <td>442.800</td>\n",
              "      <td>1.960127e+05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>244.90</td>\n",
              "      <td>78.100</td>\n",
              "      <td>395.0</td>\n",
              "      <td>296</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>703</td>\n",
              "      <td>10</td>\n",
              "      <td>3950</td>\n",
              "      <td>29200</td>\n",
              "      <td>252</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>53</td>\n",
              "      <td>153398</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>224</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>40.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1981.772904</td>\n",
              "      <td>26.075959</td>\n",
              "      <td>5.113267e+04</td>\n",
              "      <td>8.855831e+04</td>\n",
              "      <td>153391</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>13.037980</td>\n",
              "      <td>13.037980</td>\n",
              "      <td>40</td>\n",
              "      <td>112</td>\n",
              "      <td>68.8</td>\n",
              "      <td>39.440</td>\n",
              "      <td>1.555200e+03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>86.00</td>\n",
              "      <td>40.000</td>\n",
              "      <td>112.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>224</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>57660</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>128</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>46.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3017.689906</td>\n",
              "      <td>34.686091</td>\n",
              "      <td>5.766000e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>57660</td>\n",
              "      <td>57660</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>17.343046</td>\n",
              "      <td>17.343046</td>\n",
              "      <td>46</td>\n",
              "      <td>128</td>\n",
              "      <td>73.3</td>\n",
              "      <td>47.340</td>\n",
              "      <td>2.241333e+03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>110.00</td>\n",
              "      <td>46.000</td>\n",
              "      <td>128.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8446</td>\n",
              "      <td>767</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>6</td>\n",
              "      <td>14.336</td>\n",
              "      <td>14.440</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63885.267280</td>\n",
              "      <td>5215.123859</td>\n",
              "      <td>2.556667e+02</td>\n",
              "      <td>3.942896e+02</td>\n",
              "      <td>710</td>\n",
              "      <td>3</td>\n",
              "      <td>713</td>\n",
              "      <td>356.500</td>\n",
              "      <td>4.999245e+02</td>\n",
              "      <td>710</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>3911.342800</td>\n",
              "      <td>1303.781000</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.180</td>\n",
              "      <td>1.250000e+02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.75</td>\n",
              "      <td>14.336</td>\n",
              "      <td>6.0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1017</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539611</th>\n",
              "      <td>80</td>\n",
              "      <td>11512204</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>326</td>\n",
              "      <td>11632</td>\n",
              "      <td>326</td>\n",
              "      <td>0</td>\n",
              "      <td>40.750</td>\n",
              "      <td>115.250</td>\n",
              "      <td>10184</td>\n",
              "      <td>0</td>\n",
              "      <td>2326.0</td>\n",
              "      <td>4436.0</td>\n",
              "      <td>1038.723775</td>\n",
              "      <td>1.129236</td>\n",
              "      <td>9.593503e+05</td>\n",
              "      <td>2.262616e+06</td>\n",
              "      <td>6507197</td>\n",
              "      <td>1</td>\n",
              "      <td>6510770</td>\n",
              "      <td>930110.000</td>\n",
              "      <td>2.460477e+06</td>\n",
              "      <td>6509948</td>\n",
              "      <td>1</td>\n",
              "      <td>11500000</td>\n",
              "      <td>2878039.500</td>\n",
              "      <td>3378874.20</td>\n",
              "      <td>6507197</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>264</td>\n",
              "      <td>168</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>0.434322</td>\n",
              "      <td>0</td>\n",
              "      <td>10184</td>\n",
              "      <td>854.0</td>\n",
              "      <td>2714.000</td>\n",
              "      <td>7.361769e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>920.00</td>\n",
              "      <td>40.750</td>\n",
              "      <td>2326.0</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>326</td>\n",
              "      <td>5</td>\n",
              "      <td>11632</td>\n",
              "      <td>29200</td>\n",
              "      <td>235</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>892.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>892</td>\n",
              "      <td>892</td>\n",
              "      <td>6507197.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6507197</td>\n",
              "      <td>6507197</td>\n",
              "      <td>DoS GoldenEye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539612</th>\n",
              "      <td>80</td>\n",
              "      <td>11513325</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>471</td>\n",
              "      <td>3525</td>\n",
              "      <td>471</td>\n",
              "      <td>0</td>\n",
              "      <td>94.200</td>\n",
              "      <td>210.600</td>\n",
              "      <td>2077</td>\n",
              "      <td>0</td>\n",
              "      <td>705.0</td>\n",
              "      <td>990.5</td>\n",
              "      <td>347.076105</td>\n",
              "      <td>0.868559</td>\n",
              "      <td>1.279258e+06</td>\n",
              "      <td>2.565153e+06</td>\n",
              "      <td>6508582</td>\n",
              "      <td>53</td>\n",
              "      <td>6512631</td>\n",
              "      <td>1628157.800</td>\n",
              "      <td>3.255639e+06</td>\n",
              "      <td>6511616</td>\n",
              "      <td>176</td>\n",
              "      <td>11500000</td>\n",
              "      <td>2878318.000</td>\n",
              "      <td>3379306.00</td>\n",
              "      <td>6508582</td>\n",
              "      <td>192</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>168</td>\n",
              "      <td>0.434279</td>\n",
              "      <td>0.434279</td>\n",
              "      <td>0</td>\n",
              "      <td>2077</td>\n",
              "      <td>363.2</td>\n",
              "      <td>720.000</td>\n",
              "      <td>5.180836e+05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>399.50</td>\n",
              "      <td>94.200</td>\n",
              "      <td>705.0</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>471</td>\n",
              "      <td>5</td>\n",
              "      <td>3525</td>\n",
              "      <td>29200</td>\n",
              "      <td>235</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>918.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>918</td>\n",
              "      <td>918</td>\n",
              "      <td>6508582.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6508582</td>\n",
              "      <td>6508582</td>\n",
              "      <td>DoS GoldenEye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539613</th>\n",
              "      <td>80</td>\n",
              "      <td>11509201</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>314</td>\n",
              "      <td>11632</td>\n",
              "      <td>314</td>\n",
              "      <td>0</td>\n",
              "      <td>44.840</td>\n",
              "      <td>118.700</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>1939.0</td>\n",
              "      <td>2544.0</td>\n",
              "      <td>1037.952157</td>\n",
              "      <td>1.129531</td>\n",
              "      <td>9.591001e+05</td>\n",
              "      <td>2.261842e+06</td>\n",
              "      <td>6503248</td>\n",
              "      <td>46</td>\n",
              "      <td>6507056</td>\n",
              "      <td>1084509.400</td>\n",
              "      <td>2.655701e+06</td>\n",
              "      <td>6505437</td>\n",
              "      <td>255</td>\n",
              "      <td>11500000</td>\n",
              "      <td>2301830.500</td>\n",
              "      <td>3195689.20</td>\n",
              "      <td>6503248</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>232</td>\n",
              "      <td>200</td>\n",
              "      <td>0.608209</td>\n",
              "      <td>0.521322</td>\n",
              "      <td>0</td>\n",
              "      <td>5792</td>\n",
              "      <td>853.5</td>\n",
              "      <td>1857.000</td>\n",
              "      <td>3.449144e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>919.00</td>\n",
              "      <td>44.840</td>\n",
              "      <td>1939.0</td>\n",
              "      <td>232</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>314</td>\n",
              "      <td>6</td>\n",
              "      <td>11632</td>\n",
              "      <td>29200</td>\n",
              "      <td>235</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>899.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>899</td>\n",
              "      <td>899</td>\n",
              "      <td>6503248.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6503248</td>\n",
              "      <td>6503248</td>\n",
              "      <td>DoS GoldenEye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539614</th>\n",
              "      <td>80</td>\n",
              "      <td>11509095</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>369</td>\n",
              "      <td>11632</td>\n",
              "      <td>369</td>\n",
              "      <td>0</td>\n",
              "      <td>46.120</td>\n",
              "      <td>130.500</td>\n",
              "      <td>10184</td>\n",
              "      <td>0</td>\n",
              "      <td>2326.0</td>\n",
              "      <td>4436.0</td>\n",
              "      <td>1042.740546</td>\n",
              "      <td>1.129541</td>\n",
              "      <td>9.590912e+05</td>\n",
              "      <td>2.262122e+06</td>\n",
              "      <td>6504954</td>\n",
              "      <td>47</td>\n",
              "      <td>6507794</td>\n",
              "      <td>929684.900</td>\n",
              "      <td>2.458891e+06</td>\n",
              "      <td>6505926</td>\n",
              "      <td>168</td>\n",
              "      <td>11500000</td>\n",
              "      <td>2877262.000</td>\n",
              "      <td>3377879.00</td>\n",
              "      <td>6504954</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>264</td>\n",
              "      <td>168</td>\n",
              "      <td>0.695102</td>\n",
              "      <td>0.434439</td>\n",
              "      <td>0</td>\n",
              "      <td>10184</td>\n",
              "      <td>857.0</td>\n",
              "      <td>2712.000</td>\n",
              "      <td>7.358407e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>923.00</td>\n",
              "      <td>46.120</td>\n",
              "      <td>2326.0</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>369</td>\n",
              "      <td>5</td>\n",
              "      <td>11632</td>\n",
              "      <td>29200</td>\n",
              "      <td>235</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>914.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>914</td>\n",
              "      <td>914</td>\n",
              "      <td>6504954.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6504954</td>\n",
              "      <td>6504954</td>\n",
              "      <td>DoS GoldenEye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539615</th>\n",
              "      <td>80</td>\n",
              "      <td>11512230</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>672</td>\n",
              "      <td>3525</td>\n",
              "      <td>672</td>\n",
              "      <td>0</td>\n",
              "      <td>134.400</td>\n",
              "      <td>300.500</td>\n",
              "      <td>2077</td>\n",
              "      <td>0</td>\n",
              "      <td>705.0</td>\n",
              "      <td>990.5</td>\n",
              "      <td>364.568811</td>\n",
              "      <td>0.868641</td>\n",
              "      <td>1.279137e+06</td>\n",
              "      <td>2.565060e+06</td>\n",
              "      <td>6506213</td>\n",
              "      <td>4</td>\n",
              "      <td>6509115</td>\n",
              "      <td>1627278.800</td>\n",
              "      <td>3.253892e+06</td>\n",
              "      <td>6508117</td>\n",
              "      <td>4</td>\n",
              "      <td>11500000</td>\n",
              "      <td>2878045.500</td>\n",
              "      <td>3378842.00</td>\n",
              "      <td>6506213</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>168</td>\n",
              "      <td>0.434321</td>\n",
              "      <td>0.434321</td>\n",
              "      <td>0</td>\n",
              "      <td>2077</td>\n",
              "      <td>381.5</td>\n",
              "      <td>725.500</td>\n",
              "      <td>5.260871e+05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>419.80</td>\n",
              "      <td>134.400</td>\n",
              "      <td>705.0</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>672</td>\n",
              "      <td>5</td>\n",
              "      <td>3525</td>\n",
              "      <td>29200</td>\n",
              "      <td>237</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>821.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>821</td>\n",
              "      <td>821</td>\n",
              "      <td>6506213.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6506213</td>\n",
              "      <td>6506213</td>\n",
              "      <td>DoS GoldenEye</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>539616 rows √ó 79 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed5fec85-e92e-426c-816b-3add1a597a70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed5fec85-e92e-426c-816b-3add1a597a70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed5fec85-e92e-426c-816b-3add1a597a70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8c3c7ba-ee40-43ba-91ff-9c14d809c8e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8c3c7ba-ee40-43ba-91ff-9c14d809c8e4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8c3c7ba-ee40-43ba-91ff-9c14d809c8e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e1d31c9e",
      "metadata": {
        "id": "e1d31c9e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1fd2a6-eb3a-4790-d31b-52da9b76a846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 539616 entries, 0 to 539615\n",
            "Data columns (total 79 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   Destination Port              539616 non-null  int64  \n",
            " 1    Flow Duration                539616 non-null  int64  \n",
            " 2    Total Fwd Packets            539616 non-null  int64  \n",
            " 3    Total Backward Packets       539616 non-null  int64  \n",
            " 4   Total Length of Fwd Packets   539616 non-null  int64  \n",
            " 5    Total Length of Bwd Packets  539616 non-null  int64  \n",
            " 6    Fwd Packet Length Max        539616 non-null  int64  \n",
            " 7    Fwd Packet Length Min        539616 non-null  int64  \n",
            " 8    Fwd Packet Length Mean       539616 non-null  float64\n",
            " 9    Fwd Packet Length Std        539616 non-null  float64\n",
            " 10  Bwd Packet Length Max         539616 non-null  int64  \n",
            " 11   Bwd Packet Length Min        539616 non-null  int64  \n",
            " 12   Bwd Packet Length Mean       539616 non-null  float64\n",
            " 13   Bwd Packet Length Std        539616 non-null  float64\n",
            " 14  Flow Bytes/s                  539128 non-null  float64\n",
            " 15   Flow Packets/s               539616 non-null  float64\n",
            " 16   Flow IAT Mean                539616 non-null  float64\n",
            " 17   Flow IAT Std                 539616 non-null  float64\n",
            " 18   Flow IAT Max                 539616 non-null  int64  \n",
            " 19   Flow IAT Min                 539616 non-null  int64  \n",
            " 20  Fwd IAT Total                 539616 non-null  int64  \n",
            " 21   Fwd IAT Mean                 539616 non-null  float64\n",
            " 22   Fwd IAT Std                  539616 non-null  float64\n",
            " 23   Fwd IAT Max                  539616 non-null  int64  \n",
            " 24   Fwd IAT Min                  539616 non-null  int64  \n",
            " 25  Bwd IAT Total                 539616 non-null  int64  \n",
            " 26   Bwd IAT Mean                 539616 non-null  float64\n",
            " 27   Bwd IAT Std                  539616 non-null  float64\n",
            " 28   Bwd IAT Max                  539616 non-null  int64  \n",
            " 29   Bwd IAT Min                  539616 non-null  int64  \n",
            " 30  Fwd PSH Flags                 539616 non-null  int64  \n",
            " 31   Bwd PSH Flags                539616 non-null  int64  \n",
            " 32   Fwd URG Flags                539616 non-null  int64  \n",
            " 33   Bwd URG Flags                539616 non-null  int64  \n",
            " 34   Fwd Header Length            539616 non-null  int64  \n",
            " 35   Bwd Header Length            539616 non-null  int64  \n",
            " 36  Fwd Packets/s                 539616 non-null  float64\n",
            " 37   Bwd Packets/s                539616 non-null  float64\n",
            " 38   Min Packet Length            539616 non-null  int64  \n",
            " 39   Max Packet Length            539616 non-null  int64  \n",
            " 40   Packet Length Mean           539616 non-null  float64\n",
            " 41   Packet Length Std            539616 non-null  float64\n",
            " 42   Packet Length Variance       539616 non-null  float64\n",
            " 43  FIN Flag Count                539616 non-null  int64  \n",
            " 44   SYN Flag Count               539616 non-null  int64  \n",
            " 45   RST Flag Count               539616 non-null  int64  \n",
            " 46   PSH Flag Count               539616 non-null  int64  \n",
            " 47   ACK Flag Count               539616 non-null  int64  \n",
            " 48   URG Flag Count               539616 non-null  int64  \n",
            " 49   CWE Flag Count               539616 non-null  int64  \n",
            " 50   ECE Flag Count               539616 non-null  int64  \n",
            " 51   Down/Up Ratio                539616 non-null  int64  \n",
            " 52   Average Packet Size          539616 non-null  float64\n",
            " 53   Avg Fwd Segment Size         539616 non-null  float64\n",
            " 54   Avg Bwd Segment Size         539616 non-null  float64\n",
            " 55   Fwd Header Length.1          539616 non-null  int64  \n",
            " 56  Fwd Avg Bytes/Bulk            539616 non-null  int64  \n",
            " 57   Fwd Avg Packets/Bulk         539616 non-null  int64  \n",
            " 58   Fwd Avg Bulk Rate            539616 non-null  int64  \n",
            " 59   Bwd Avg Bytes/Bulk           539616 non-null  int64  \n",
            " 60   Bwd Avg Packets/Bulk         539616 non-null  int64  \n",
            " 61  Bwd Avg Bulk Rate             539616 non-null  int64  \n",
            " 62  Subflow Fwd Packets           539616 non-null  int64  \n",
            " 63   Subflow Fwd Bytes            539616 non-null  int64  \n",
            " 64   Subflow Bwd Packets          539616 non-null  int64  \n",
            " 65   Subflow Bwd Bytes            539616 non-null  int64  \n",
            " 66  Init_Win_bytes_forward        539616 non-null  int64  \n",
            " 67   Init_Win_bytes_backward      539616 non-null  int64  \n",
            " 68   act_data_pkt_fwd             539616 non-null  int64  \n",
            " 69   min_seg_size_forward         539616 non-null  int64  \n",
            " 70  Active Mean                   539616 non-null  float64\n",
            " 71   Active Std                   539616 non-null  float64\n",
            " 72   Active Max                   539616 non-null  int64  \n",
            " 73   Active Min                   539616 non-null  int64  \n",
            " 74  Idle Mean                     539616 non-null  float64\n",
            " 75   Idle Std                     539616 non-null  float64\n",
            " 76   Idle Max                     539616 non-null  int64  \n",
            " 77   Idle Min                     539616 non-null  int64  \n",
            " 78  Label                         539616 non-null  object \n",
            "dtypes: float64(24), int64(54), object(1)\n",
            "memory usage: 325.2+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48490bfe",
      "metadata": {
        "id": "48490bfe"
      },
      "source": [
        "–ù–µ–±–æ–ª—å—à–æ–π –≤—ã–≤–æ–¥: –¥–∞–Ω–Ω—ã–µ —É –Ω–∞—Å –ª–∏–±–æ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω–æ–º, –ª–∏–±–æ –≤ –¥–µ—Å—è—Ç–∏—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –¢–æ–ª—å–∫–æ —Ç–∞—Ä–≥–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ object. –ï—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –≤ —Å—Ç–æ–ª–±—Ü–µ 'Flow Bytes/s'. –î–∞–ª–µ–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –µ–≥–æ –ø–æ–¥—Ä–æ–±–Ω–æ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e61a200d",
      "metadata": {
        "id": "e61a200d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb893185-eb90-4348-8a68-4c348e7180d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BENIGN', 'PortScan', 'DoS Hulk', 'DDoS', 'Bot', 'Infiltration',\n",
              "       'Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ XSS',\n",
              "       'Web Attack ÔøΩ Sql Injection', 'FTP-Patator', 'SSH-Patator',\n",
              "       'DoS slowloris', 'DoS Slowhttptest', 'DoS GoldenEye', 'Heartbleed'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df=data\n",
        "df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d701749e",
      "metadata": {
        "id": "d701749e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "ca30773f-e103-4fad-8fee-6001f58868e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Label'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# –ø—Ä–æ–≤–µ—Ä–∏–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤\n",
        "df.groupby('Label')['Total Length of Fwd Packets'].count().plot.bar(x='Label', figsize=(7,3))\n",
        "\n",
        "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c05edee6",
      "metadata": {
        "id": "c05edee6"
      },
      "source": [
        "–î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å —Ä–∞–∑–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –Ω–∞–¥–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf9d74d",
      "metadata": {
        "id": "ebf9d74d"
      },
      "source": [
        "### –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e8e2df0",
      "metadata": {
        "id": "4e8e2df0"
      },
      "source": [
        "#### –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ / —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "STsLrunaBWs-",
      "metadata": {
        "id": "STsLrunaBWs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a01957-ebc4-4dd1-b013-4c500e585d7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BENIGN', 'DoS Hulk'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_test=df[df.isnull().any(1)]\n",
        "df_test['Label'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gkFDzxAsH9AJ",
      "metadata": {
        "id": "gkFDzxAsH9AJ"
      },
      "source": [
        "–í –ø—Ä–∏–Ω—Ü–∏–ø–µ, –Ω—É–ª–µ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "06sDDVLABYSt",
      "metadata": {
        "id": "06sDDVLABYSt"
      },
      "outputs": [],
      "source": [
        "df=df.dropna ()\n",
        "df=df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "epbLOR7XBabP",
      "metadata": {
        "id": "epbLOR7XBabP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "b15280b4-841f-490a-8828-1ceea719e5ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BENIGN', 'PortScan', 'DDoS', 'Bot', 'FTP-Patator'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Destination Port   Flow Duration   Total Fwd Packets  \\\n",
              "500037              8080               0                   1   \n",
              "500129             52235               0                   1   \n",
              "500585              2846               0                   1   \n",
              "500737              2876               0                   1   \n",
              "500812              2906               0                   1   \n",
              "\n",
              "         Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "500037                        1                            6   \n",
              "500129                        1                            6   \n",
              "500585                        1                            6   \n",
              "500737                        1                            6   \n",
              "500812                        1                            6   \n",
              "\n",
              "         Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
              "500037                             6                       6   \n",
              "500129                             6                       6   \n",
              "500585                             6                       6   \n",
              "500737                             6                       6   \n",
              "500812                             6                       6   \n",
              "\n",
              "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
              "500037                       6                      6.0   \n",
              "500129                       6                      6.0   \n",
              "500585                       6                      6.0   \n",
              "500737                       6                      6.0   \n",
              "500812                       6                      6.0   \n",
              "\n",
              "         Fwd Packet Length Std  Bwd Packet Length Max   Bwd Packet Length Min  \\\n",
              "500037                     0.0                      6                       6   \n",
              "500129                     0.0                      6                       6   \n",
              "500585                     0.0                      6                       6   \n",
              "500737                     0.0                      6                       6   \n",
              "500812                     0.0                      6                       6   \n",
              "\n",
              "         Bwd Packet Length Mean   Bwd Packet Length Std  Flow Bytes/s  \\\n",
              "500037                      6.0                     0.0           inf   \n",
              "500129                      6.0                     0.0           inf   \n",
              "500585                      6.0                     0.0           inf   \n",
              "500737                      6.0                     0.0           inf   \n",
              "500812                      6.0                     0.0           inf   \n",
              "\n",
              "         Flow Packets/s   Flow IAT Mean   Flow IAT Std   Flow IAT Max  \\\n",
              "500037              inf             0.0            0.0              0   \n",
              "500129              inf             0.0            0.0              0   \n",
              "500585              inf             0.0            0.0              0   \n",
              "500737              inf             0.0            0.0              0   \n",
              "500812              inf             0.0            0.0              0   \n",
              "\n",
              "         Flow IAT Min  Fwd IAT Total   Fwd IAT Mean   Fwd IAT Std  \\\n",
              "500037              0              0            0.0           0.0   \n",
              "500129              0              0            0.0           0.0   \n",
              "500585              0              0            0.0           0.0   \n",
              "500737              0              0            0.0           0.0   \n",
              "500812              0              0            0.0           0.0   \n",
              "\n",
              "         Fwd IAT Max   Fwd IAT Min  Bwd IAT Total   Bwd IAT Mean  \\\n",
              "500037             0             0              0            0.0   \n",
              "500129             0             0              0            0.0   \n",
              "500585             0             0              0            0.0   \n",
              "500737             0             0              0            0.0   \n",
              "500812             0             0              0            0.0   \n",
              "\n",
              "         Bwd IAT Std   Bwd IAT Max   Bwd IAT Min  Fwd PSH Flags  \\\n",
              "500037           0.0             0             0              0   \n",
              "500129           0.0             0             0              0   \n",
              "500585           0.0             0             0              0   \n",
              "500737           0.0             0             0              0   \n",
              "500812           0.0             0             0              0   \n",
              "\n",
              "         Bwd PSH Flags   Fwd URG Flags   Bwd URG Flags   Fwd Header Length  \\\n",
              "500037               0               0               0                  20   \n",
              "500129               0               0               0                  20   \n",
              "500585               0               0               0                  20   \n",
              "500737               0               0               0                  20   \n",
              "500812               0               0               0                  20   \n",
              "\n",
              "         Bwd Header Length  Fwd Packets/s   Bwd Packets/s   Min Packet Length  \\\n",
              "500037                  20            0.0             0.0                   6   \n",
              "500129                  20            0.0             0.0                   6   \n",
              "500585                  20            0.0             0.0                   6   \n",
              "500737                  20            0.0             0.0                   6   \n",
              "500812                  20            0.0             0.0                   6   \n",
              "\n",
              "         Max Packet Length   Packet Length Mean   Packet Length Std  \\\n",
              "500037                   6                  6.0                 0.0   \n",
              "500129                   6                  6.0                 0.0   \n",
              "500585                   6                  6.0                 0.0   \n",
              "500737                   6                  6.0                 0.0   \n",
              "500812                   6                  6.0                 0.0   \n",
              "\n",
              "         Packet Length Variance  FIN Flag Count   SYN Flag Count  \\\n",
              "500037                      0.0               0                0   \n",
              "500129                      0.0               0                0   \n",
              "500585                      0.0               0                0   \n",
              "500737                      0.0               0                0   \n",
              "500812                      0.0               0                0   \n",
              "\n",
              "         RST Flag Count   PSH Flag Count   ACK Flag Count   URG Flag Count  \\\n",
              "500037                0                0                1                0   \n",
              "500129                0                0                1                1   \n",
              "500585                0                0                1                1   \n",
              "500737                0                0                1                1   \n",
              "500812                0                0                1                1   \n",
              "\n",
              "         CWE Flag Count   ECE Flag Count   Down/Up Ratio  \\\n",
              "500037                0                0               1   \n",
              "500129                0                0               1   \n",
              "500585                0                0               1   \n",
              "500737                0                0               1   \n",
              "500812                0                0               1   \n",
              "\n",
              "         Average Packet Size   Avg Fwd Segment Size   Avg Bwd Segment Size  \\\n",
              "500037                   9.0                    6.0                    6.0   \n",
              "500129                   9.0                    6.0                    6.0   \n",
              "500585                   9.0                    6.0                    6.0   \n",
              "500737                   9.0                    6.0                    6.0   \n",
              "500812                   9.0                    6.0                    6.0   \n",
              "\n",
              "         Fwd Header Length.1  Fwd Avg Bytes/Bulk   Fwd Avg Packets/Bulk  \\\n",
              "500037                    20                   0                      0   \n",
              "500129                    20                   0                      0   \n",
              "500585                    20                   0                      0   \n",
              "500737                    20                   0                      0   \n",
              "500812                    20                   0                      0   \n",
              "\n",
              "         Fwd Avg Bulk Rate   Bwd Avg Bytes/Bulk   Bwd Avg Packets/Bulk  \\\n",
              "500037                   0                    0                      0   \n",
              "500129                   0                    0                      0   \n",
              "500585                   0                    0                      0   \n",
              "500737                   0                    0                      0   \n",
              "500812                   0                    0                      0   \n",
              "\n",
              "        Bwd Avg Bulk Rate  Subflow Fwd Packets   Subflow Fwd Bytes  \\\n",
              "500037                  0                    1                   6   \n",
              "500129                  0                    1                   6   \n",
              "500585                  0                    1                   6   \n",
              "500737                  0                    1                   6   \n",
              "500812                  0                    1                   6   \n",
              "\n",
              "         Subflow Bwd Packets   Subflow Bwd Bytes  Init_Win_bytes_forward  \\\n",
              "500037                     1                   6                     256   \n",
              "500129                     1                   6                     245   \n",
              "500585                     1                   6                     237   \n",
              "500737                     1                   6                     237   \n",
              "500812                     1                   6                     237   \n",
              "\n",
              "         Init_Win_bytes_backward   act_data_pkt_fwd   min_seg_size_forward  \\\n",
              "500037                       237                  0                     20   \n",
              "500129                       256                  0                     20   \n",
              "500585                     16393                  0                     20   \n",
              "500737                     16393                  0                     20   \n",
              "500812                     16390                  0                     20   \n",
              "\n",
              "        Active Mean   Active Std   Active Max   Active Min  Idle Mean  \\\n",
              "500037          0.0          0.0            0            0        0.0   \n",
              "500129          0.0          0.0            0            0        0.0   \n",
              "500585          0.0          0.0            0            0        0.0   \n",
              "500737          0.0          0.0            0            0        0.0   \n",
              "500812          0.0          0.0            0            0        0.0   \n",
              "\n",
              "         Idle Std   Idle Max   Idle Min Label  \n",
              "500037        0.0          0          0   Bot  \n",
              "500129        0.0          0          0   Bot  \n",
              "500585        0.0          0          0   Bot  \n",
              "500737        0.0          0          0   Bot  \n",
              "500812        0.0          0          0   Bot  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e683a09a-18ab-40ee-854b-ab651e47c11d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500037</th>\n",
              "      <td>8080</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>256</td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500129</th>\n",
              "      <td>52235</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>245</td>\n",
              "      <td>256</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500585</th>\n",
              "      <td>2846</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>237</td>\n",
              "      <td>16393</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500737</th>\n",
              "      <td>2876</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>237</td>\n",
              "      <td>16393</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500812</th>\n",
              "      <td>2906</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>237</td>\n",
              "      <td>16390</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e683a09a-18ab-40ee-854b-ab651e47c11d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e683a09a-18ab-40ee-854b-ab651e47c11d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e683a09a-18ab-40ee-854b-ab651e47c11d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60201f71-7bdb-4769-933c-34f50d01ffac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60201f71-7bdb-4769-933c-34f50d01ffac')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60201f71-7bdb-4769-933c-34f50d01ffac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# –µ—Å—Ç—å –µ—â–µ —Å—Ç—Ä–æ–∫–∏ —Å –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.\n",
        "\n",
        "df_test=df[df.isin([np.inf, -np.inf]).any(1)]\n",
        "df_test['Label'].unique()\n",
        "df_test=df_test.loc[df_test['Label']=='Bot']\n",
        "\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.replace([np.inf, -np.inf], np.nan)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "q9px4B775n4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811e2856-13dd-4603-de04-5e690e901458"
      },
      "id": "q9px4B775n4k",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 474975 entries, 0 to 539615\n",
            "Data columns (total 79 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   Destination Port              474975 non-null  int64  \n",
            " 1    Flow Duration                474975 non-null  int64  \n",
            " 2    Total Fwd Packets            474975 non-null  int64  \n",
            " 3    Total Backward Packets       474975 non-null  int64  \n",
            " 4   Total Length of Fwd Packets   474975 non-null  int64  \n",
            " 5    Total Length of Bwd Packets  474975 non-null  int64  \n",
            " 6    Fwd Packet Length Max        474975 non-null  int64  \n",
            " 7    Fwd Packet Length Min        474975 non-null  int64  \n",
            " 8    Fwd Packet Length Mean       474975 non-null  float64\n",
            " 9    Fwd Packet Length Std        474975 non-null  float64\n",
            " 10  Bwd Packet Length Max         474975 non-null  int64  \n",
            " 11   Bwd Packet Length Min        474975 non-null  int64  \n",
            " 12   Bwd Packet Length Mean       474975 non-null  float64\n",
            " 13   Bwd Packet Length Std        474975 non-null  float64\n",
            " 14  Flow Bytes/s                  474753 non-null  float64\n",
            " 15   Flow Packets/s               474753 non-null  float64\n",
            " 16   Flow IAT Mean                474975 non-null  float64\n",
            " 17   Flow IAT Std                 474975 non-null  float64\n",
            " 18   Flow IAT Max                 474975 non-null  int64  \n",
            " 19   Flow IAT Min                 474975 non-null  int64  \n",
            " 20  Fwd IAT Total                 474975 non-null  int64  \n",
            " 21   Fwd IAT Mean                 474975 non-null  float64\n",
            " 22   Fwd IAT Std                  474975 non-null  float64\n",
            " 23   Fwd IAT Max                  474975 non-null  int64  \n",
            " 24   Fwd IAT Min                  474975 non-null  int64  \n",
            " 25  Bwd IAT Total                 474975 non-null  int64  \n",
            " 26   Bwd IAT Mean                 474975 non-null  float64\n",
            " 27   Bwd IAT Std                  474975 non-null  float64\n",
            " 28   Bwd IAT Max                  474975 non-null  int64  \n",
            " 29   Bwd IAT Min                  474975 non-null  int64  \n",
            " 30  Fwd PSH Flags                 474975 non-null  int64  \n",
            " 31   Bwd PSH Flags                474975 non-null  int64  \n",
            " 32   Fwd URG Flags                474975 non-null  int64  \n",
            " 33   Bwd URG Flags                474975 non-null  int64  \n",
            " 34   Fwd Header Length            474975 non-null  int64  \n",
            " 35   Bwd Header Length            474975 non-null  int64  \n",
            " 36  Fwd Packets/s                 474975 non-null  float64\n",
            " 37   Bwd Packets/s                474975 non-null  float64\n",
            " 38   Min Packet Length            474975 non-null  int64  \n",
            " 39   Max Packet Length            474975 non-null  int64  \n",
            " 40   Packet Length Mean           474975 non-null  float64\n",
            " 41   Packet Length Std            474975 non-null  float64\n",
            " 42   Packet Length Variance       474975 non-null  float64\n",
            " 43  FIN Flag Count                474975 non-null  int64  \n",
            " 44   SYN Flag Count               474975 non-null  int64  \n",
            " 45   RST Flag Count               474975 non-null  int64  \n",
            " 46   PSH Flag Count               474975 non-null  int64  \n",
            " 47   ACK Flag Count               474975 non-null  int64  \n",
            " 48   URG Flag Count               474975 non-null  int64  \n",
            " 49   CWE Flag Count               474975 non-null  int64  \n",
            " 50   ECE Flag Count               474975 non-null  int64  \n",
            " 51   Down/Up Ratio                474975 non-null  int64  \n",
            " 52   Average Packet Size          474975 non-null  float64\n",
            " 53   Avg Fwd Segment Size         474975 non-null  float64\n",
            " 54   Avg Bwd Segment Size         474975 non-null  float64\n",
            " 55   Fwd Header Length.1          474975 non-null  int64  \n",
            " 56  Fwd Avg Bytes/Bulk            474975 non-null  int64  \n",
            " 57   Fwd Avg Packets/Bulk         474975 non-null  int64  \n",
            " 58   Fwd Avg Bulk Rate            474975 non-null  int64  \n",
            " 59   Bwd Avg Bytes/Bulk           474975 non-null  int64  \n",
            " 60   Bwd Avg Packets/Bulk         474975 non-null  int64  \n",
            " 61  Bwd Avg Bulk Rate             474975 non-null  int64  \n",
            " 62  Subflow Fwd Packets           474975 non-null  int64  \n",
            " 63   Subflow Fwd Bytes            474975 non-null  int64  \n",
            " 64   Subflow Bwd Packets          474975 non-null  int64  \n",
            " 65   Subflow Bwd Bytes            474975 non-null  int64  \n",
            " 66  Init_Win_bytes_forward        474975 non-null  int64  \n",
            " 67   Init_Win_bytes_backward      474975 non-null  int64  \n",
            " 68   act_data_pkt_fwd             474975 non-null  int64  \n",
            " 69   min_seg_size_forward         474975 non-null  int64  \n",
            " 70  Active Mean                   474975 non-null  float64\n",
            " 71   Active Std                   474975 non-null  float64\n",
            " 72   Active Max                   474975 non-null  int64  \n",
            " 73   Active Min                   474975 non-null  int64  \n",
            " 74  Idle Mean                     474975 non-null  float64\n",
            " 75   Idle Std                     474975 non-null  float64\n",
            " 76   Idle Max                     474975 non-null  int64  \n",
            " 77   Idle Min                     474975 non-null  int64  \n",
            " 78  Label                         474975 non-null  object \n",
            "dtypes: float64(24), int64(54), object(1)\n",
            "memory usage: 289.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e57LFh-hJMfl",
      "metadata": {
        "id": "e57LFh-hJMfl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#df = df.fillna(0)\n",
        "#df[df.isin([np.inf, -np.inf]).any(1)]\n",
        "df = df.fillna(df.max())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–º–µ—Å—Ç–æ inf –±—ã–ª–∏ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –Ω—É–ª–∏, —Å—Ä–µ–¥–Ω–∏–µ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ù–∞–∏–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–∏–ª—Å—è –ø—Ä–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø–æ —Å—Ç–æ–ª–±—Ü—É."
      ],
      "metadata": {
        "id": "3F6UDeh06sbw"
      },
      "id": "3F6UDeh06sbw"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "gZSAAI8cOsv8",
      "metadata": {
        "id": "gZSAAI8cOsv8"
      },
      "outputs": [],
      "source": [
        "cat_columns = [30,31,32,33,43,44,45,46,47,48,49,50]\n",
        "numeric = df.select_dtypes('float').columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f11941",
      "metadata": {
        "id": "86f11941"
      },
      "source": [
        "#### –í—ã–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ç–∞—Ä–≥–µ—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c47960be",
      "metadata": {
        "id": "c47960be"
      },
      "outputs": [],
      "source": [
        "# –î–µ–ª–∏–º –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ\n",
        "target = df['Label']\n",
        "features = df.drop('Label', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "396e6c21",
      "metadata": {
        "id": "396e6c21"
      },
      "outputs": [],
      "source": [
        "#target=np.reshape(target,-1)\n",
        "\n",
        "features_test, features_train, target_test, target_train = train_test_split(features, target, test_size=0.80, random_state=12345, stratify=target)\n",
        "\n",
        "features_val, features_train, target_val, target_train = train_test_split(features_train, target_train, test_size=0.8, random_state=12345, stratify=target_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e79032cf",
      "metadata": {
        "id": "e79032cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca5b267-cf9d-44f7-dda0-7b00f9b9c596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303984, 78)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94995, 78)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75996, 78)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303984,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94995,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75996,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "features_train.shape\n",
        "features_test.shape\n",
        "features_val.shape\n",
        "\n",
        "target_train.shape\n",
        "target_test.shape\n",
        "target_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d0be35",
      "metadata": {
        "id": "50d0be35"
      },
      "source": [
        "## –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4782eb77",
      "metadata": {
        "id": "4782eb77"
      },
      "source": [
        "### –û–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c95a862c",
      "metadata": {
        "id": "c95a862c"
      },
      "outputs": [],
      "source": [
        "def prediction(model):\n",
        "    preds = model.predict(features_val)\n",
        "    accuracy=accuracy_score(target_val, preds)\n",
        "    f1=f1_score(target_val, preds, average='macro')\n",
        "    target_names = ['BENIGN', 'PortScan', 'DoS Hulk', 'DDoS', 'Bot', 'Infiltration', 'Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ XSS',\n",
        "                    'Web Attack ÔøΩ Sql Injection', 'FTP-Patator', 'SSH-Patator','DoS slowloris', 'DoS Slowhttptest', 'DoS GoldenEye', 'Heartbleed']\n",
        "    print (\"Accuracy:\",accuracy)\n",
        "    print (\"F1_macro:\", f1)\n",
        "    print(classification_report(target_val, preds, target_names=target_names))\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f916d11c",
      "metadata": {
        "id": "f916d11c"
      },
      "source": [
        "### –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –±–µ–π–∑–ª–∞–π–Ω–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75a276b",
      "metadata": {
        "id": "d75a276b"
      },
      "source": [
        "–≤–æ–∑—å–º–µ–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ –±–∞–π–∑–ª–∞–π–Ω–∞ LogReg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9b0e304c",
      "metadata": {
        "id": "9b0e304c"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=12345, class_weight='balanced', max_iter=500, ).fit(features_train, target_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "242e6c7e",
      "metadata": {
        "id": "242e6c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "e68d46a9-4731-4ffa-a39f-99f357164292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6522974893415443\n",
            "F1_macro: 0.4745388024806812\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.93      0.41      0.57     37244\n",
            "                  PortScan       0.02      0.27      0.04       312\n",
            "                  DoS Hulk       0.68      0.97      0.80     10298\n",
            "                      DDoS       0.74      0.93      0.83      1646\n",
            "                       Bot       0.95      0.80      0.87     13960\n",
            "              Infiltration       0.42      0.84      0.56       836\n",
            "  Web Attack ÔøΩ Brute Force       0.40      0.88      0.55       862\n",
            "          Web Attack ÔøΩ XSS       0.60      0.66      0.63       949\n",
            "Web Attack ÔøΩ Sql Injection       0.40      1.00      0.57         2\n",
            "               FTP-Patator       0.01      1.00      0.02         6\n",
            "               SSH-Patator       0.47      0.99      0.64      9024\n",
            "             DoS slowloris       0.77      0.90      0.83       515\n",
            "          DoS Slowhttptest       0.03      0.05      0.04       235\n",
            "             DoS GoldenEye       0.00      0.67      0.01         3\n",
            "                Heartbleed       0.10      0.93      0.18       104\n",
            "\n",
            "                  accuracy                           0.65     75996\n",
            "                 macro avg       0.44      0.75      0.47     75996\n",
            "              weighted avg       0.82      0.65      0.67     75996\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced', max_iter=500, random_state=12345)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=500, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=500, random_state=12345)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "prediction(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef47b0ba",
      "metadata": {
        "id": "ef47b0ba"
      },
      "source": [
        "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75ab47d0",
      "metadata": {
        "id": "75ab47d0"
      },
      "source": [
        "#### CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5c6ef000",
      "metadata": {
        "id": "5c6ef000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b508d3-ad82-4c31-8de2-c9ec2c451b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.208346\n",
            "0:\tlearn: 0.7103990\ttotal: 49.4ms\tremaining: 49.3s\n",
            "1:\tlearn: 0.5330124\ttotal: 105ms\tremaining: 52.6s\n",
            "2:\tlearn: 0.4251299\ttotal: 160ms\tremaining: 53.1s\n",
            "3:\tlearn: 0.3508356\ttotal: 215ms\tremaining: 53.7s\n",
            "4:\tlearn: 0.2924896\ttotal: 266ms\tremaining: 53s\n",
            "5:\tlearn: 0.2478457\ttotal: 306ms\tremaining: 50.6s\n",
            "6:\tlearn: 0.2095375\ttotal: 331ms\tremaining: 47s\n",
            "7:\tlearn: 0.1809451\ttotal: 358ms\tremaining: 44.4s\n",
            "8:\tlearn: 0.1571204\ttotal: 385ms\tremaining: 42.4s\n",
            "9:\tlearn: 0.1388515\ttotal: 411ms\tremaining: 40.6s\n",
            "10:\tlearn: 0.1221289\ttotal: 439ms\tremaining: 39.5s\n",
            "11:\tlearn: 0.1093289\ttotal: 474ms\tremaining: 39s\n",
            "12:\tlearn: 0.0976664\ttotal: 499ms\tremaining: 37.9s\n",
            "13:\tlearn: 0.0869762\ttotal: 524ms\tremaining: 36.9s\n",
            "14:\tlearn: 0.0789329\ttotal: 547ms\tremaining: 36s\n",
            "15:\tlearn: 0.0718294\ttotal: 579ms\tremaining: 35.6s\n",
            "16:\tlearn: 0.0662951\ttotal: 602ms\tremaining: 34.8s\n",
            "17:\tlearn: 0.0616462\ttotal: 626ms\tremaining: 34.2s\n",
            "18:\tlearn: 0.0551420\ttotal: 649ms\tremaining: 33.5s\n",
            "19:\tlearn: 0.0520590\ttotal: 672ms\tremaining: 32.9s\n",
            "20:\tlearn: 0.0486751\ttotal: 697ms\tremaining: 32.5s\n",
            "21:\tlearn: 0.0454262\ttotal: 731ms\tremaining: 32.5s\n",
            "22:\tlearn: 0.0434212\ttotal: 753ms\tremaining: 32s\n",
            "23:\tlearn: 0.0409714\ttotal: 782ms\tremaining: 31.8s\n",
            "24:\tlearn: 0.0392083\ttotal: 805ms\tremaining: 31.4s\n",
            "25:\tlearn: 0.0368327\ttotal: 827ms\tremaining: 31s\n",
            "26:\tlearn: 0.0350407\ttotal: 850ms\tremaining: 30.6s\n",
            "27:\tlearn: 0.0338135\ttotal: 877ms\tremaining: 30.4s\n",
            "28:\tlearn: 0.0328842\ttotal: 898ms\tremaining: 30.1s\n",
            "29:\tlearn: 0.0314293\ttotal: 921ms\tremaining: 29.8s\n",
            "30:\tlearn: 0.0307448\ttotal: 941ms\tremaining: 29.4s\n",
            "31:\tlearn: 0.0291268\ttotal: 964ms\tremaining: 29.1s\n",
            "32:\tlearn: 0.0281445\ttotal: 993ms\tremaining: 29.1s\n",
            "33:\tlearn: 0.0269580\ttotal: 1.01s\tremaining: 28.9s\n",
            "34:\tlearn: 0.0263456\ttotal: 1.03s\tremaining: 28.5s\n",
            "35:\tlearn: 0.0256997\ttotal: 1.06s\tremaining: 28.3s\n",
            "36:\tlearn: 0.0249438\ttotal: 1.08s\tremaining: 28.1s\n",
            "37:\tlearn: 0.0238749\ttotal: 1.1s\tremaining: 27.9s\n",
            "38:\tlearn: 0.0235438\ttotal: 1.12s\tremaining: 27.7s\n",
            "39:\tlearn: 0.0230185\ttotal: 1.15s\tremaining: 27.5s\n",
            "40:\tlearn: 0.0217829\ttotal: 1.17s\tremaining: 27.4s\n",
            "41:\tlearn: 0.0212358\ttotal: 1.2s\tremaining: 27.3s\n",
            "42:\tlearn: 0.0207581\ttotal: 1.22s\tremaining: 27.2s\n",
            "43:\tlearn: 0.0200771\ttotal: 1.24s\tremaining: 27s\n",
            "44:\tlearn: 0.0197118\ttotal: 1.27s\tremaining: 26.9s\n",
            "45:\tlearn: 0.0195207\ttotal: 1.29s\tremaining: 26.7s\n",
            "46:\tlearn: 0.0193281\ttotal: 1.31s\tremaining: 26.6s\n",
            "47:\tlearn: 0.0191870\ttotal: 1.33s\tremaining: 26.4s\n",
            "48:\tlearn: 0.0189412\ttotal: 1.35s\tremaining: 26.2s\n",
            "49:\tlearn: 0.0183781\ttotal: 1.38s\tremaining: 26.2s\n",
            "50:\tlearn: 0.0179996\ttotal: 1.41s\tremaining: 26.2s\n",
            "51:\tlearn: 0.0177990\ttotal: 1.43s\tremaining: 26.1s\n",
            "52:\tlearn: 0.0176617\ttotal: 1.45s\tremaining: 25.9s\n",
            "53:\tlearn: 0.0173436\ttotal: 1.47s\tremaining: 25.8s\n",
            "54:\tlearn: 0.0170443\ttotal: 1.5s\tremaining: 25.7s\n",
            "55:\tlearn: 0.0168907\ttotal: 1.52s\tremaining: 25.6s\n",
            "56:\tlearn: 0.0165565\ttotal: 1.54s\tremaining: 25.4s\n",
            "57:\tlearn: 0.0163294\ttotal: 1.56s\tremaining: 25.4s\n",
            "58:\tlearn: 0.0159468\ttotal: 1.58s\tremaining: 25.3s\n",
            "59:\tlearn: 0.0157861\ttotal: 1.61s\tremaining: 25.3s\n",
            "60:\tlearn: 0.0155913\ttotal: 1.63s\tremaining: 25.1s\n",
            "61:\tlearn: 0.0152573\ttotal: 1.66s\tremaining: 25.1s\n",
            "62:\tlearn: 0.0149500\ttotal: 1.68s\tremaining: 25s\n",
            "63:\tlearn: 0.0148691\ttotal: 1.7s\tremaining: 24.9s\n",
            "64:\tlearn: 0.0146668\ttotal: 1.74s\tremaining: 25s\n",
            "65:\tlearn: 0.0144223\ttotal: 1.76s\tremaining: 24.9s\n",
            "66:\tlearn: 0.0141346\ttotal: 1.79s\tremaining: 24.9s\n",
            "67:\tlearn: 0.0140124\ttotal: 1.81s\tremaining: 24.8s\n",
            "68:\tlearn: 0.0139534\ttotal: 1.84s\tremaining: 24.8s\n",
            "69:\tlearn: 0.0138156\ttotal: 1.86s\tremaining: 24.8s\n",
            "70:\tlearn: 0.0136606\ttotal: 1.89s\tremaining: 24.7s\n",
            "71:\tlearn: 0.0136068\ttotal: 1.91s\tremaining: 24.6s\n",
            "72:\tlearn: 0.0135484\ttotal: 1.93s\tremaining: 24.5s\n",
            "73:\tlearn: 0.0133662\ttotal: 1.95s\tremaining: 24.4s\n",
            "74:\tlearn: 0.0131968\ttotal: 1.98s\tremaining: 24.4s\n",
            "75:\tlearn: 0.0131116\ttotal: 2s\tremaining: 24.3s\n",
            "76:\tlearn: 0.0130367\ttotal: 2.02s\tremaining: 24.2s\n",
            "77:\tlearn: 0.0129824\ttotal: 2.04s\tremaining: 24.1s\n",
            "78:\tlearn: 0.0128561\ttotal: 2.06s\tremaining: 24.1s\n",
            "79:\tlearn: 0.0126912\ttotal: 2.09s\tremaining: 24s\n",
            "80:\tlearn: 0.0125309\ttotal: 2.11s\tremaining: 23.9s\n",
            "81:\tlearn: 0.0122924\ttotal: 2.15s\tremaining: 24s\n",
            "82:\tlearn: 0.0122596\ttotal: 2.17s\tremaining: 24s\n",
            "83:\tlearn: 0.0121545\ttotal: 2.19s\tremaining: 23.9s\n",
            "84:\tlearn: 0.0120429\ttotal: 2.21s\tremaining: 23.8s\n",
            "85:\tlearn: 0.0120173\ttotal: 2.25s\tremaining: 23.9s\n",
            "86:\tlearn: 0.0119755\ttotal: 2.27s\tremaining: 23.8s\n",
            "87:\tlearn: 0.0118895\ttotal: 2.29s\tremaining: 23.7s\n",
            "88:\tlearn: 0.0118436\ttotal: 2.31s\tremaining: 23.6s\n",
            "89:\tlearn: 0.0117617\ttotal: 2.33s\tremaining: 23.6s\n",
            "90:\tlearn: 0.0117548\ttotal: 2.35s\tremaining: 23.5s\n",
            "91:\tlearn: 0.0116494\ttotal: 2.37s\tremaining: 23.4s\n",
            "92:\tlearn: 0.0115574\ttotal: 2.39s\tremaining: 23.4s\n",
            "93:\tlearn: 0.0112252\ttotal: 2.42s\tremaining: 23.3s\n",
            "94:\tlearn: 0.0111648\ttotal: 2.45s\tremaining: 23.4s\n",
            "95:\tlearn: 0.0110529\ttotal: 2.48s\tremaining: 23.3s\n",
            "96:\tlearn: 0.0110096\ttotal: 2.5s\tremaining: 23.3s\n",
            "97:\tlearn: 0.0109959\ttotal: 2.52s\tremaining: 23.2s\n",
            "98:\tlearn: 0.0109747\ttotal: 2.55s\tremaining: 23.2s\n",
            "99:\tlearn: 0.0109161\ttotal: 2.57s\tremaining: 23.1s\n",
            "100:\tlearn: 0.0108574\ttotal: 2.6s\tremaining: 23.2s\n",
            "101:\tlearn: 0.0107976\ttotal: 2.63s\tremaining: 23.2s\n",
            "102:\tlearn: 0.0107347\ttotal: 2.66s\tremaining: 23.2s\n",
            "103:\tlearn: 0.0106871\ttotal: 2.7s\tremaining: 23.3s\n",
            "104:\tlearn: 0.0106400\ttotal: 2.76s\tremaining: 23.5s\n",
            "105:\tlearn: 0.0104864\ttotal: 2.8s\tremaining: 23.6s\n",
            "106:\tlearn: 0.0104260\ttotal: 2.84s\tremaining: 23.7s\n",
            "107:\tlearn: 0.0103471\ttotal: 2.9s\tremaining: 23.9s\n",
            "108:\tlearn: 0.0102777\ttotal: 2.98s\tremaining: 24.3s\n",
            "109:\tlearn: 0.0102056\ttotal: 3.05s\tremaining: 24.7s\n",
            "110:\tlearn: 0.0101630\ttotal: 3.13s\tremaining: 25.1s\n",
            "111:\tlearn: 0.0101135\ttotal: 3.2s\tremaining: 25.4s\n",
            "112:\tlearn: 0.0100684\ttotal: 3.28s\tremaining: 25.7s\n",
            "113:\tlearn: 0.0100041\ttotal: 3.36s\tremaining: 26.1s\n",
            "114:\tlearn: 0.0099708\ttotal: 3.43s\tremaining: 26.4s\n",
            "115:\tlearn: 0.0099449\ttotal: 3.5s\tremaining: 26.7s\n",
            "116:\tlearn: 0.0099023\ttotal: 3.58s\tremaining: 27s\n",
            "117:\tlearn: 0.0098634\ttotal: 3.66s\tremaining: 27.4s\n",
            "118:\tlearn: 0.0098380\ttotal: 3.74s\tremaining: 27.7s\n",
            "119:\tlearn: 0.0098230\ttotal: 3.81s\tremaining: 27.9s\n",
            "120:\tlearn: 0.0098155\ttotal: 3.89s\tremaining: 28.3s\n",
            "121:\tlearn: 0.0098050\ttotal: 3.96s\tremaining: 28.5s\n",
            "122:\tlearn: 0.0097686\ttotal: 4.05s\tremaining: 28.9s\n",
            "123:\tlearn: 0.0097344\ttotal: 4.11s\tremaining: 29s\n",
            "124:\tlearn: 0.0096996\ttotal: 4.19s\tremaining: 29.3s\n",
            "125:\tlearn: 0.0096263\ttotal: 4.27s\tremaining: 29.6s\n",
            "126:\tlearn: 0.0095996\ttotal: 4.34s\tremaining: 29.9s\n",
            "127:\tlearn: 0.0095859\ttotal: 4.41s\tremaining: 30s\n",
            "128:\tlearn: 0.0095659\ttotal: 4.48s\tremaining: 30.3s\n",
            "129:\tlearn: 0.0095320\ttotal: 4.55s\tremaining: 30.4s\n",
            "130:\tlearn: 0.0094441\ttotal: 4.61s\tremaining: 30.6s\n",
            "131:\tlearn: 0.0094203\ttotal: 4.69s\tremaining: 30.8s\n",
            "132:\tlearn: 0.0093760\ttotal: 4.77s\tremaining: 31.1s\n",
            "133:\tlearn: 0.0093160\ttotal: 4.86s\tremaining: 31.4s\n",
            "134:\tlearn: 0.0092897\ttotal: 4.94s\tremaining: 31.7s\n",
            "135:\tlearn: 0.0092595\ttotal: 5.03s\tremaining: 32s\n",
            "136:\tlearn: 0.0092483\ttotal: 5.12s\tremaining: 32.2s\n",
            "137:\tlearn: 0.0092173\ttotal: 5.2s\tremaining: 32.5s\n",
            "138:\tlearn: 0.0091656\ttotal: 5.3s\tremaining: 32.8s\n",
            "139:\tlearn: 0.0091322\ttotal: 5.38s\tremaining: 33s\n",
            "140:\tlearn: 0.0091172\ttotal: 5.46s\tremaining: 33.3s\n",
            "141:\tlearn: 0.0091079\ttotal: 5.54s\tremaining: 33.5s\n",
            "142:\tlearn: 0.0090557\ttotal: 5.62s\tremaining: 33.7s\n",
            "143:\tlearn: 0.0090158\ttotal: 5.72s\tremaining: 34s\n",
            "144:\tlearn: 0.0089798\ttotal: 5.81s\tremaining: 34.2s\n",
            "145:\tlearn: 0.0089639\ttotal: 5.9s\tremaining: 34.5s\n",
            "146:\tlearn: 0.0089524\ttotal: 5.97s\tremaining: 34.6s\n",
            "147:\tlearn: 0.0089383\ttotal: 6.06s\tremaining: 34.9s\n",
            "148:\tlearn: 0.0089253\ttotal: 6.13s\tremaining: 35s\n",
            "149:\tlearn: 0.0089069\ttotal: 6.2s\tremaining: 35.1s\n",
            "150:\tlearn: 0.0088980\ttotal: 6.3s\tremaining: 35.4s\n",
            "151:\tlearn: 0.0088594\ttotal: 6.39s\tremaining: 35.6s\n",
            "152:\tlearn: 0.0088346\ttotal: 6.48s\tremaining: 35.9s\n",
            "153:\tlearn: 0.0087984\ttotal: 6.57s\tremaining: 36.1s\n",
            "154:\tlearn: 0.0087138\ttotal: 6.67s\tremaining: 36.4s\n",
            "155:\tlearn: 0.0086907\ttotal: 6.76s\tremaining: 36.6s\n",
            "156:\tlearn: 0.0086751\ttotal: 6.84s\tremaining: 36.7s\n",
            "157:\tlearn: 0.0086330\ttotal: 6.95s\tremaining: 37s\n",
            "158:\tlearn: 0.0085965\ttotal: 7.07s\tremaining: 37.4s\n",
            "159:\tlearn: 0.0085791\ttotal: 7.15s\tremaining: 37.6s\n",
            "160:\tlearn: 0.0085429\ttotal: 7.26s\tremaining: 37.8s\n",
            "161:\tlearn: 0.0085149\ttotal: 7.35s\tremaining: 38s\n",
            "162:\tlearn: 0.0084715\ttotal: 7.42s\tremaining: 38.1s\n",
            "163:\tlearn: 0.0084506\ttotal: 7.49s\tremaining: 38.2s\n",
            "164:\tlearn: 0.0084377\ttotal: 7.57s\tremaining: 38.3s\n",
            "165:\tlearn: 0.0084301\ttotal: 7.64s\tremaining: 38.4s\n",
            "166:\tlearn: 0.0084160\ttotal: 7.72s\tremaining: 38.5s\n",
            "167:\tlearn: 0.0083823\ttotal: 7.81s\tremaining: 38.7s\n",
            "168:\tlearn: 0.0083659\ttotal: 7.88s\tremaining: 38.8s\n",
            "169:\tlearn: 0.0083545\ttotal: 7.96s\tremaining: 38.9s\n",
            "170:\tlearn: 0.0083394\ttotal: 8.04s\tremaining: 39s\n",
            "171:\tlearn: 0.0083239\ttotal: 8.15s\tremaining: 39.2s\n",
            "172:\tlearn: 0.0083106\ttotal: 8.23s\tremaining: 39.4s\n",
            "173:\tlearn: 0.0082886\ttotal: 8.31s\tremaining: 39.5s\n",
            "174:\tlearn: 0.0082791\ttotal: 8.4s\tremaining: 39.6s\n",
            "175:\tlearn: 0.0082708\ttotal: 8.49s\tremaining: 39.7s\n",
            "176:\tlearn: 0.0082588\ttotal: 8.59s\tremaining: 39.9s\n",
            "177:\tlearn: 0.0082274\ttotal: 8.68s\tremaining: 40.1s\n",
            "178:\tlearn: 0.0082087\ttotal: 8.77s\tremaining: 40.2s\n",
            "179:\tlearn: 0.0081864\ttotal: 8.87s\tremaining: 40.4s\n",
            "180:\tlearn: 0.0081591\ttotal: 8.97s\tremaining: 40.6s\n",
            "181:\tlearn: 0.0081359\ttotal: 9.07s\tremaining: 40.8s\n",
            "182:\tlearn: 0.0081225\ttotal: 9.16s\tremaining: 40.9s\n",
            "183:\tlearn: 0.0081061\ttotal: 9.25s\tremaining: 41s\n",
            "184:\tlearn: 0.0080854\ttotal: 9.35s\tremaining: 41.2s\n",
            "185:\tlearn: 0.0080635\ttotal: 9.44s\tremaining: 41.3s\n",
            "186:\tlearn: 0.0080532\ttotal: 9.54s\tremaining: 41.5s\n",
            "187:\tlearn: 0.0080402\ttotal: 9.63s\tremaining: 41.6s\n",
            "188:\tlearn: 0.0080231\ttotal: 9.73s\tremaining: 41.8s\n",
            "189:\tlearn: 0.0080152\ttotal: 9.82s\tremaining: 41.9s\n",
            "190:\tlearn: 0.0080030\ttotal: 9.92s\tremaining: 42s\n",
            "191:\tlearn: 0.0079916\ttotal: 10s\tremaining: 42.2s\n",
            "192:\tlearn: 0.0079557\ttotal: 10.1s\tremaining: 42.3s\n",
            "193:\tlearn: 0.0079486\ttotal: 10.2s\tremaining: 42.5s\n",
            "194:\tlearn: 0.0079383\ttotal: 10.3s\tremaining: 42.6s\n",
            "195:\tlearn: 0.0079246\ttotal: 10.4s\tremaining: 42.7s\n",
            "196:\tlearn: 0.0079104\ttotal: 10.5s\tremaining: 42.8s\n",
            "197:\tlearn: 0.0079014\ttotal: 10.6s\tremaining: 42.9s\n",
            "198:\tlearn: 0.0078823\ttotal: 10.6s\tremaining: 42.8s\n",
            "199:\tlearn: 0.0078736\ttotal: 10.7s\tremaining: 42.6s\n",
            "200:\tlearn: 0.0078546\ttotal: 10.7s\tremaining: 42.5s\n",
            "201:\tlearn: 0.0078292\ttotal: 10.7s\tremaining: 42.4s\n",
            "202:\tlearn: 0.0077956\ttotal: 10.8s\tremaining: 42.2s\n",
            "203:\tlearn: 0.0077911\ttotal: 10.8s\tremaining: 42.1s\n",
            "204:\tlearn: 0.0077796\ttotal: 10.8s\tremaining: 42s\n",
            "205:\tlearn: 0.0077318\ttotal: 10.9s\tremaining: 41.8s\n",
            "206:\tlearn: 0.0077199\ttotal: 10.9s\tremaining: 41.7s\n",
            "207:\tlearn: 0.0077041\ttotal: 10.9s\tremaining: 41.5s\n",
            "208:\tlearn: 0.0076980\ttotal: 10.9s\tremaining: 41.3s\n",
            "209:\tlearn: 0.0076550\ttotal: 10.9s\tremaining: 41.2s\n",
            "210:\tlearn: 0.0076442\ttotal: 11s\tremaining: 41s\n",
            "211:\tlearn: 0.0076339\ttotal: 11s\tremaining: 40.9s\n",
            "212:\tlearn: 0.0076266\ttotal: 11s\tremaining: 40.7s\n",
            "213:\tlearn: 0.0076202\ttotal: 11s\tremaining: 40.5s\n",
            "214:\tlearn: 0.0076139\ttotal: 11.1s\tremaining: 40.4s\n",
            "215:\tlearn: 0.0075860\ttotal: 11.1s\tremaining: 40.2s\n",
            "216:\tlearn: 0.0075763\ttotal: 11.1s\tremaining: 40.1s\n",
            "217:\tlearn: 0.0075591\ttotal: 11.2s\tremaining: 40s\n",
            "218:\tlearn: 0.0075466\ttotal: 11.2s\tremaining: 39.9s\n",
            "219:\tlearn: 0.0074985\ttotal: 11.2s\tremaining: 39.7s\n",
            "220:\tlearn: 0.0074919\ttotal: 11.2s\tremaining: 39.6s\n",
            "221:\tlearn: 0.0074829\ttotal: 11.2s\tremaining: 39.4s\n",
            "222:\tlearn: 0.0074777\ttotal: 11.3s\tremaining: 39.3s\n",
            "223:\tlearn: 0.0074533\ttotal: 11.3s\tremaining: 39.1s\n",
            "224:\tlearn: 0.0074459\ttotal: 11.3s\tremaining: 39s\n",
            "225:\tlearn: 0.0074392\ttotal: 11.3s\tremaining: 38.8s\n",
            "226:\tlearn: 0.0074337\ttotal: 11.4s\tremaining: 38.7s\n",
            "227:\tlearn: 0.0074278\ttotal: 11.4s\tremaining: 38.5s\n",
            "228:\tlearn: 0.0074026\ttotal: 11.4s\tremaining: 38.4s\n",
            "229:\tlearn: 0.0073958\ttotal: 11.4s\tremaining: 38.3s\n",
            "230:\tlearn: 0.0073896\ttotal: 11.5s\tremaining: 38.1s\n",
            "231:\tlearn: 0.0073769\ttotal: 11.5s\tremaining: 38s\n",
            "232:\tlearn: 0.0073451\ttotal: 11.5s\tremaining: 37.9s\n",
            "233:\tlearn: 0.0073386\ttotal: 11.5s\tremaining: 37.7s\n",
            "234:\tlearn: 0.0073303\ttotal: 11.6s\tremaining: 37.6s\n",
            "235:\tlearn: 0.0073247\ttotal: 11.6s\tremaining: 37.5s\n",
            "236:\tlearn: 0.0073192\ttotal: 11.6s\tremaining: 37.3s\n",
            "237:\tlearn: 0.0073132\ttotal: 11.6s\tremaining: 37.2s\n",
            "238:\tlearn: 0.0073055\ttotal: 11.6s\tremaining: 37.1s\n",
            "239:\tlearn: 0.0072970\ttotal: 11.7s\tremaining: 36.9s\n",
            "240:\tlearn: 0.0072824\ttotal: 11.7s\tremaining: 36.8s\n",
            "241:\tlearn: 0.0072651\ttotal: 11.7s\tremaining: 36.7s\n",
            "242:\tlearn: 0.0072542\ttotal: 11.7s\tremaining: 36.6s\n",
            "243:\tlearn: 0.0072415\ttotal: 11.8s\tremaining: 36.5s\n",
            "244:\tlearn: 0.0072280\ttotal: 11.8s\tremaining: 36.3s\n",
            "245:\tlearn: 0.0072224\ttotal: 11.8s\tremaining: 36.2s\n",
            "246:\tlearn: 0.0072134\ttotal: 11.8s\tremaining: 36.1s\n",
            "247:\tlearn: 0.0072064\ttotal: 11.9s\tremaining: 36s\n",
            "248:\tlearn: 0.0071988\ttotal: 11.9s\tremaining: 35.8s\n",
            "249:\tlearn: 0.0071879\ttotal: 11.9s\tremaining: 35.7s\n",
            "250:\tlearn: 0.0071814\ttotal: 11.9s\tremaining: 35.6s\n",
            "251:\tlearn: 0.0071686\ttotal: 11.9s\tremaining: 35.5s\n",
            "252:\tlearn: 0.0071581\ttotal: 12s\tremaining: 35.3s\n",
            "253:\tlearn: 0.0071356\ttotal: 12s\tremaining: 35.2s\n",
            "254:\tlearn: 0.0071329\ttotal: 12s\tremaining: 35.1s\n",
            "255:\tlearn: 0.0071249\ttotal: 12s\tremaining: 35s\n",
            "256:\tlearn: 0.0071198\ttotal: 12.1s\tremaining: 34.9s\n",
            "257:\tlearn: 0.0071134\ttotal: 12.1s\tremaining: 34.8s\n",
            "258:\tlearn: 0.0070818\ttotal: 12.1s\tremaining: 34.7s\n",
            "259:\tlearn: 0.0070680\ttotal: 12.2s\tremaining: 34.6s\n",
            "260:\tlearn: 0.0070617\ttotal: 12.2s\tremaining: 34.5s\n",
            "261:\tlearn: 0.0070554\ttotal: 12.2s\tremaining: 34.3s\n",
            "262:\tlearn: 0.0070492\ttotal: 12.2s\tremaining: 34.2s\n",
            "263:\tlearn: 0.0070451\ttotal: 12.3s\tremaining: 34.2s\n",
            "264:\tlearn: 0.0070354\ttotal: 12.3s\tremaining: 34s\n",
            "265:\tlearn: 0.0070279\ttotal: 12.3s\tremaining: 33.9s\n",
            "266:\tlearn: 0.0070233\ttotal: 12.3s\tremaining: 33.8s\n",
            "267:\tlearn: 0.0069925\ttotal: 12.3s\tremaining: 33.7s\n",
            "268:\tlearn: 0.0069852\ttotal: 12.4s\tremaining: 33.6s\n",
            "269:\tlearn: 0.0069750\ttotal: 12.4s\tremaining: 33.5s\n",
            "270:\tlearn: 0.0069677\ttotal: 12.4s\tremaining: 33.4s\n",
            "271:\tlearn: 0.0069657\ttotal: 12.4s\tremaining: 33.3s\n",
            "272:\tlearn: 0.0069505\ttotal: 12.5s\tremaining: 33.2s\n",
            "273:\tlearn: 0.0069419\ttotal: 12.5s\tremaining: 33.1s\n",
            "274:\tlearn: 0.0069334\ttotal: 12.5s\tremaining: 33s\n",
            "275:\tlearn: 0.0069289\ttotal: 12.5s\tremaining: 32.9s\n",
            "276:\tlearn: 0.0069239\ttotal: 12.5s\tremaining: 32.8s\n",
            "277:\tlearn: 0.0069201\ttotal: 12.6s\tremaining: 32.6s\n",
            "278:\tlearn: 0.0069153\ttotal: 12.6s\tremaining: 32.5s\n",
            "279:\tlearn: 0.0069098\ttotal: 12.6s\tremaining: 32.4s\n",
            "280:\tlearn: 0.0068902\ttotal: 12.6s\tremaining: 32.4s\n",
            "281:\tlearn: 0.0068763\ttotal: 12.7s\tremaining: 32.3s\n",
            "282:\tlearn: 0.0068734\ttotal: 12.7s\tremaining: 32.1s\n",
            "283:\tlearn: 0.0068655\ttotal: 12.7s\tremaining: 32.1s\n",
            "284:\tlearn: 0.0068561\ttotal: 12.7s\tremaining: 32s\n",
            "285:\tlearn: 0.0068383\ttotal: 12.8s\tremaining: 31.9s\n",
            "286:\tlearn: 0.0068266\ttotal: 12.8s\tremaining: 31.8s\n",
            "287:\tlearn: 0.0068208\ttotal: 12.8s\tremaining: 31.7s\n",
            "288:\tlearn: 0.0068042\ttotal: 12.8s\tremaining: 31.6s\n",
            "289:\tlearn: 0.0067897\ttotal: 12.9s\tremaining: 31.5s\n",
            "290:\tlearn: 0.0067830\ttotal: 12.9s\tremaining: 31.4s\n",
            "291:\tlearn: 0.0067770\ttotal: 12.9s\tremaining: 31.3s\n",
            "292:\tlearn: 0.0067588\ttotal: 12.9s\tremaining: 31.2s\n",
            "293:\tlearn: 0.0067398\ttotal: 13s\tremaining: 31.1s\n",
            "294:\tlearn: 0.0067258\ttotal: 13s\tremaining: 31s\n",
            "295:\tlearn: 0.0067189\ttotal: 13s\tremaining: 30.9s\n",
            "296:\tlearn: 0.0067124\ttotal: 13s\tremaining: 30.8s\n",
            "297:\tlearn: 0.0067094\ttotal: 13.1s\tremaining: 30.8s\n",
            "298:\tlearn: 0.0067023\ttotal: 13.1s\tremaining: 30.7s\n",
            "299:\tlearn: 0.0066964\ttotal: 13.1s\tremaining: 30.6s\n",
            "300:\tlearn: 0.0066923\ttotal: 13.1s\tremaining: 30.5s\n",
            "301:\tlearn: 0.0066795\ttotal: 13.2s\tremaining: 30.4s\n",
            "302:\tlearn: 0.0066711\ttotal: 13.2s\tremaining: 30.3s\n",
            "303:\tlearn: 0.0066593\ttotal: 13.2s\tremaining: 30.3s\n",
            "304:\tlearn: 0.0066560\ttotal: 13.2s\tremaining: 30.2s\n",
            "305:\tlearn: 0.0066468\ttotal: 13.3s\tremaining: 30.1s\n",
            "306:\tlearn: 0.0066404\ttotal: 13.3s\tremaining: 30s\n",
            "307:\tlearn: 0.0066292\ttotal: 13.3s\tremaining: 29.9s\n",
            "308:\tlearn: 0.0066259\ttotal: 13.3s\tremaining: 29.8s\n",
            "309:\tlearn: 0.0066094\ttotal: 13.4s\tremaining: 29.7s\n",
            "310:\tlearn: 0.0066025\ttotal: 13.4s\tremaining: 29.6s\n",
            "311:\tlearn: 0.0065953\ttotal: 13.4s\tremaining: 29.6s\n",
            "312:\tlearn: 0.0065913\ttotal: 13.4s\tremaining: 29.5s\n",
            "313:\tlearn: 0.0065795\ttotal: 13.5s\tremaining: 29.4s\n",
            "314:\tlearn: 0.0065580\ttotal: 13.5s\tremaining: 29.3s\n",
            "315:\tlearn: 0.0065527\ttotal: 13.5s\tremaining: 29.2s\n",
            "316:\tlearn: 0.0065465\ttotal: 13.5s\tremaining: 29.2s\n",
            "317:\tlearn: 0.0065381\ttotal: 13.6s\tremaining: 29.1s\n",
            "318:\tlearn: 0.0065370\ttotal: 13.6s\tremaining: 29s\n",
            "319:\tlearn: 0.0065346\ttotal: 13.6s\tremaining: 28.9s\n",
            "320:\tlearn: 0.0065278\ttotal: 13.6s\tremaining: 28.8s\n",
            "321:\tlearn: 0.0065205\ttotal: 13.6s\tremaining: 28.7s\n",
            "322:\tlearn: 0.0065106\ttotal: 13.7s\tremaining: 28.7s\n",
            "323:\tlearn: 0.0065013\ttotal: 13.7s\tremaining: 28.6s\n",
            "324:\tlearn: 0.0064899\ttotal: 13.7s\tremaining: 28.5s\n",
            "325:\tlearn: 0.0064872\ttotal: 13.7s\tremaining: 28.4s\n",
            "326:\tlearn: 0.0064698\ttotal: 13.8s\tremaining: 28.3s\n",
            "327:\tlearn: 0.0064639\ttotal: 13.8s\tremaining: 28.3s\n",
            "328:\tlearn: 0.0064606\ttotal: 13.8s\tremaining: 28.2s\n",
            "329:\tlearn: 0.0064568\ttotal: 13.8s\tremaining: 28.1s\n",
            "330:\tlearn: 0.0064460\ttotal: 13.9s\tremaining: 28s\n",
            "331:\tlearn: 0.0064336\ttotal: 13.9s\tremaining: 27.9s\n",
            "332:\tlearn: 0.0064309\ttotal: 13.9s\tremaining: 27.8s\n",
            "333:\tlearn: 0.0064224\ttotal: 13.9s\tremaining: 27.8s\n",
            "334:\tlearn: 0.0064127\ttotal: 13.9s\tremaining: 27.7s\n",
            "335:\tlearn: 0.0064006\ttotal: 14s\tremaining: 27.6s\n",
            "336:\tlearn: 0.0063946\ttotal: 14s\tremaining: 27.5s\n",
            "337:\tlearn: 0.0063903\ttotal: 14s\tremaining: 27.5s\n",
            "338:\tlearn: 0.0063853\ttotal: 14s\tremaining: 27.4s\n",
            "339:\tlearn: 0.0063797\ttotal: 14.1s\tremaining: 27.3s\n",
            "340:\tlearn: 0.0063731\ttotal: 14.1s\tremaining: 27.2s\n",
            "341:\tlearn: 0.0063666\ttotal: 14.1s\tremaining: 27.1s\n",
            "342:\tlearn: 0.0063438\ttotal: 14.2s\tremaining: 27.1s\n",
            "343:\tlearn: 0.0063373\ttotal: 14.2s\tremaining: 27.1s\n",
            "344:\tlearn: 0.0063299\ttotal: 14.2s\tremaining: 27s\n",
            "345:\tlearn: 0.0063192\ttotal: 14.2s\tremaining: 26.9s\n",
            "346:\tlearn: 0.0063062\ttotal: 14.3s\tremaining: 26.8s\n",
            "347:\tlearn: 0.0063040\ttotal: 14.3s\tremaining: 26.8s\n",
            "348:\tlearn: 0.0062984\ttotal: 14.3s\tremaining: 26.7s\n",
            "349:\tlearn: 0.0062940\ttotal: 14.3s\tremaining: 26.6s\n",
            "350:\tlearn: 0.0062866\ttotal: 14.3s\tremaining: 26.5s\n",
            "351:\tlearn: 0.0062817\ttotal: 14.4s\tremaining: 26.5s\n",
            "352:\tlearn: 0.0062757\ttotal: 14.4s\tremaining: 26.4s\n",
            "353:\tlearn: 0.0062726\ttotal: 14.4s\tremaining: 26.3s\n",
            "354:\tlearn: 0.0062673\ttotal: 14.4s\tremaining: 26.2s\n",
            "355:\tlearn: 0.0062579\ttotal: 14.5s\tremaining: 26.2s\n",
            "356:\tlearn: 0.0062456\ttotal: 14.5s\tremaining: 26.1s\n",
            "357:\tlearn: 0.0062423\ttotal: 14.5s\tremaining: 26s\n",
            "358:\tlearn: 0.0062374\ttotal: 14.5s\tremaining: 26s\n",
            "359:\tlearn: 0.0062354\ttotal: 14.6s\tremaining: 25.9s\n",
            "360:\tlearn: 0.0062331\ttotal: 14.6s\tremaining: 25.8s\n",
            "361:\tlearn: 0.0062269\ttotal: 14.6s\tremaining: 25.8s\n",
            "362:\tlearn: 0.0062254\ttotal: 14.6s\tremaining: 25.7s\n",
            "363:\tlearn: 0.0062231\ttotal: 14.7s\tremaining: 25.6s\n",
            "364:\tlearn: 0.0062209\ttotal: 14.7s\tremaining: 25.5s\n",
            "365:\tlearn: 0.0062160\ttotal: 14.7s\tremaining: 25.5s\n",
            "366:\tlearn: 0.0062106\ttotal: 14.7s\tremaining: 25.4s\n",
            "367:\tlearn: 0.0062080\ttotal: 14.7s\tremaining: 25.3s\n",
            "368:\tlearn: 0.0062048\ttotal: 14.8s\tremaining: 25.3s\n",
            "369:\tlearn: 0.0062019\ttotal: 14.8s\tremaining: 25.2s\n",
            "370:\tlearn: 0.0061954\ttotal: 14.8s\tremaining: 25.1s\n",
            "371:\tlearn: 0.0061869\ttotal: 14.9s\tremaining: 25.1s\n",
            "372:\tlearn: 0.0061786\ttotal: 14.9s\tremaining: 25s\n",
            "373:\tlearn: 0.0061743\ttotal: 14.9s\tremaining: 24.9s\n",
            "374:\tlearn: 0.0061707\ttotal: 14.9s\tremaining: 24.9s\n",
            "375:\tlearn: 0.0061629\ttotal: 14.9s\tremaining: 24.8s\n",
            "376:\tlearn: 0.0061598\ttotal: 15s\tremaining: 24.7s\n",
            "377:\tlearn: 0.0061445\ttotal: 15s\tremaining: 24.7s\n",
            "378:\tlearn: 0.0061422\ttotal: 15s\tremaining: 24.6s\n",
            "379:\tlearn: 0.0061387\ttotal: 15s\tremaining: 24.5s\n",
            "380:\tlearn: 0.0061349\ttotal: 15.1s\tremaining: 24.5s\n",
            "381:\tlearn: 0.0061289\ttotal: 15.1s\tremaining: 24.4s\n",
            "382:\tlearn: 0.0061263\ttotal: 15.1s\tremaining: 24.3s\n",
            "383:\tlearn: 0.0061195\ttotal: 15.2s\tremaining: 24.3s\n",
            "384:\tlearn: 0.0061146\ttotal: 15.2s\tremaining: 24.2s\n",
            "385:\tlearn: 0.0061124\ttotal: 15.2s\tremaining: 24.2s\n",
            "386:\tlearn: 0.0061034\ttotal: 15.2s\tremaining: 24.1s\n",
            "387:\tlearn: 0.0061007\ttotal: 15.3s\tremaining: 24.1s\n",
            "388:\tlearn: 0.0060971\ttotal: 15.3s\tremaining: 24s\n",
            "389:\tlearn: 0.0060936\ttotal: 15.3s\tremaining: 23.9s\n",
            "390:\tlearn: 0.0060916\ttotal: 15.3s\tremaining: 23.9s\n",
            "391:\tlearn: 0.0060893\ttotal: 15.4s\tremaining: 23.8s\n",
            "392:\tlearn: 0.0060875\ttotal: 15.4s\tremaining: 23.8s\n",
            "393:\tlearn: 0.0060859\ttotal: 15.4s\tremaining: 23.7s\n",
            "394:\tlearn: 0.0060819\ttotal: 15.4s\tremaining: 23.6s\n",
            "395:\tlearn: 0.0060753\ttotal: 15.5s\tremaining: 23.6s\n",
            "396:\tlearn: 0.0060621\ttotal: 15.5s\tremaining: 23.5s\n",
            "397:\tlearn: 0.0060603\ttotal: 15.5s\tremaining: 23.4s\n",
            "398:\tlearn: 0.0060576\ttotal: 15.5s\tremaining: 23.4s\n",
            "399:\tlearn: 0.0060544\ttotal: 15.5s\tremaining: 23.3s\n",
            "400:\tlearn: 0.0060511\ttotal: 15.6s\tremaining: 23.3s\n",
            "401:\tlearn: 0.0060448\ttotal: 15.6s\tremaining: 23.2s\n",
            "402:\tlearn: 0.0060426\ttotal: 15.6s\tremaining: 23.1s\n",
            "403:\tlearn: 0.0060409\ttotal: 15.6s\tremaining: 23.1s\n",
            "404:\tlearn: 0.0060362\ttotal: 15.7s\tremaining: 23s\n",
            "405:\tlearn: 0.0060338\ttotal: 15.7s\tremaining: 22.9s\n",
            "406:\tlearn: 0.0060292\ttotal: 15.7s\tremaining: 22.9s\n",
            "407:\tlearn: 0.0060241\ttotal: 15.7s\tremaining: 22.8s\n",
            "408:\tlearn: 0.0060195\ttotal: 15.8s\tremaining: 22.8s\n",
            "409:\tlearn: 0.0060177\ttotal: 15.8s\tremaining: 22.7s\n",
            "410:\tlearn: 0.0060144\ttotal: 15.8s\tremaining: 22.6s\n",
            "411:\tlearn: 0.0060105\ttotal: 15.8s\tremaining: 22.6s\n",
            "412:\tlearn: 0.0060093\ttotal: 15.9s\tremaining: 22.5s\n",
            "413:\tlearn: 0.0060073\ttotal: 15.9s\tremaining: 22.5s\n",
            "414:\tlearn: 0.0060033\ttotal: 15.9s\tremaining: 22.4s\n",
            "415:\tlearn: 0.0060019\ttotal: 15.9s\tremaining: 22.4s\n",
            "416:\tlearn: 0.0060006\ttotal: 15.9s\tremaining: 22.3s\n",
            "417:\tlearn: 0.0059971\ttotal: 16s\tremaining: 22.2s\n",
            "418:\tlearn: 0.0059945\ttotal: 16s\tremaining: 22.2s\n",
            "419:\tlearn: 0.0059927\ttotal: 16s\tremaining: 22.1s\n",
            "420:\tlearn: 0.0059905\ttotal: 16s\tremaining: 22.1s\n",
            "421:\tlearn: 0.0059825\ttotal: 16.1s\tremaining: 22s\n",
            "422:\tlearn: 0.0059791\ttotal: 16.1s\tremaining: 21.9s\n",
            "423:\tlearn: 0.0059759\ttotal: 16.1s\tremaining: 21.9s\n",
            "424:\tlearn: 0.0059740\ttotal: 16.2s\tremaining: 21.9s\n",
            "425:\tlearn: 0.0059727\ttotal: 16.2s\tremaining: 21.8s\n",
            "426:\tlearn: 0.0059721\ttotal: 16.2s\tremaining: 21.7s\n",
            "427:\tlearn: 0.0059707\ttotal: 16.2s\tremaining: 21.7s\n",
            "428:\tlearn: 0.0059655\ttotal: 16.2s\tremaining: 21.6s\n",
            "429:\tlearn: 0.0059626\ttotal: 16.3s\tremaining: 21.6s\n",
            "430:\tlearn: 0.0059538\ttotal: 16.3s\tremaining: 21.5s\n",
            "431:\tlearn: 0.0059513\ttotal: 16.3s\tremaining: 21.4s\n",
            "432:\tlearn: 0.0059499\ttotal: 16.3s\tremaining: 21.4s\n",
            "433:\tlearn: 0.0059478\ttotal: 16.4s\tremaining: 21.3s\n",
            "434:\tlearn: 0.0059452\ttotal: 16.4s\tremaining: 21.3s\n",
            "435:\tlearn: 0.0059429\ttotal: 16.4s\tremaining: 21.2s\n",
            "436:\tlearn: 0.0059395\ttotal: 16.4s\tremaining: 21.1s\n",
            "437:\tlearn: 0.0059363\ttotal: 16.4s\tremaining: 21.1s\n",
            "438:\tlearn: 0.0059291\ttotal: 16.5s\tremaining: 21.1s\n",
            "439:\tlearn: 0.0059254\ttotal: 16.5s\tremaining: 21s\n",
            "440:\tlearn: 0.0059228\ttotal: 16.5s\tremaining: 20.9s\n",
            "441:\tlearn: 0.0059185\ttotal: 16.5s\tremaining: 20.9s\n",
            "442:\tlearn: 0.0059165\ttotal: 16.6s\tremaining: 20.8s\n",
            "443:\tlearn: 0.0059135\ttotal: 16.6s\tremaining: 20.8s\n",
            "444:\tlearn: 0.0059114\ttotal: 16.6s\tremaining: 20.7s\n",
            "445:\tlearn: 0.0059093\ttotal: 16.6s\tremaining: 20.7s\n",
            "446:\tlearn: 0.0059069\ttotal: 16.7s\tremaining: 20.6s\n",
            "447:\tlearn: 0.0059036\ttotal: 16.7s\tremaining: 20.6s\n",
            "448:\tlearn: 0.0058999\ttotal: 16.7s\tremaining: 20.5s\n",
            "449:\tlearn: 0.0058966\ttotal: 16.7s\tremaining: 20.5s\n",
            "450:\tlearn: 0.0058916\ttotal: 16.8s\tremaining: 20.4s\n",
            "451:\tlearn: 0.0058861\ttotal: 16.8s\tremaining: 20.3s\n",
            "452:\tlearn: 0.0058835\ttotal: 16.8s\tremaining: 20.3s\n",
            "453:\tlearn: 0.0058810\ttotal: 16.8s\tremaining: 20.2s\n",
            "454:\tlearn: 0.0058792\ttotal: 16.8s\tremaining: 20.2s\n",
            "455:\tlearn: 0.0058741\ttotal: 16.9s\tremaining: 20.1s\n",
            "456:\tlearn: 0.0058728\ttotal: 16.9s\tremaining: 20.1s\n",
            "457:\tlearn: 0.0058691\ttotal: 16.9s\tremaining: 20s\n",
            "458:\tlearn: 0.0058679\ttotal: 16.9s\tremaining: 20s\n",
            "459:\tlearn: 0.0058651\ttotal: 17s\tremaining: 19.9s\n",
            "460:\tlearn: 0.0058628\ttotal: 17s\tremaining: 19.9s\n",
            "461:\tlearn: 0.0058538\ttotal: 17s\tremaining: 19.8s\n",
            "462:\tlearn: 0.0058525\ttotal: 17s\tremaining: 19.8s\n",
            "463:\tlearn: 0.0058410\ttotal: 17.1s\tremaining: 19.7s\n",
            "464:\tlearn: 0.0058385\ttotal: 17.1s\tremaining: 19.7s\n",
            "465:\tlearn: 0.0058314\ttotal: 17.1s\tremaining: 19.6s\n",
            "466:\tlearn: 0.0058304\ttotal: 17.1s\tremaining: 19.6s\n",
            "467:\tlearn: 0.0058223\ttotal: 17.2s\tremaining: 19.5s\n",
            "468:\tlearn: 0.0058197\ttotal: 17.2s\tremaining: 19.5s\n",
            "469:\tlearn: 0.0058161\ttotal: 17.2s\tremaining: 19.4s\n",
            "470:\tlearn: 0.0058078\ttotal: 17.2s\tremaining: 19.4s\n",
            "471:\tlearn: 0.0058017\ttotal: 17.3s\tremaining: 19.3s\n",
            "472:\tlearn: 0.0057968\ttotal: 17.3s\tremaining: 19.3s\n",
            "473:\tlearn: 0.0057916\ttotal: 17.3s\tremaining: 19.2s\n",
            "474:\tlearn: 0.0057908\ttotal: 17.3s\tremaining: 19.2s\n",
            "475:\tlearn: 0.0057882\ttotal: 17.4s\tremaining: 19.1s\n",
            "476:\tlearn: 0.0057846\ttotal: 17.4s\tremaining: 19.1s\n",
            "477:\tlearn: 0.0057819\ttotal: 17.4s\tremaining: 19s\n",
            "478:\tlearn: 0.0057790\ttotal: 17.4s\tremaining: 19s\n",
            "479:\tlearn: 0.0057775\ttotal: 17.4s\tremaining: 18.9s\n",
            "480:\tlearn: 0.0057656\ttotal: 17.5s\tremaining: 18.9s\n",
            "481:\tlearn: 0.0057629\ttotal: 17.5s\tremaining: 18.8s\n",
            "482:\tlearn: 0.0057605\ttotal: 17.5s\tremaining: 18.8s\n",
            "483:\tlearn: 0.0057586\ttotal: 17.5s\tremaining: 18.7s\n",
            "484:\tlearn: 0.0057546\ttotal: 17.6s\tremaining: 18.7s\n",
            "485:\tlearn: 0.0057535\ttotal: 17.6s\tremaining: 18.6s\n",
            "486:\tlearn: 0.0057520\ttotal: 17.6s\tremaining: 18.6s\n",
            "487:\tlearn: 0.0057510\ttotal: 17.6s\tremaining: 18.5s\n",
            "488:\tlearn: 0.0057414\ttotal: 17.7s\tremaining: 18.5s\n",
            "489:\tlearn: 0.0057401\ttotal: 17.7s\tremaining: 18.4s\n",
            "490:\tlearn: 0.0057346\ttotal: 17.7s\tremaining: 18.4s\n",
            "491:\tlearn: 0.0057292\ttotal: 17.7s\tremaining: 18.3s\n",
            "492:\tlearn: 0.0057245\ttotal: 17.8s\tremaining: 18.3s\n",
            "493:\tlearn: 0.0057231\ttotal: 17.8s\tremaining: 18.2s\n",
            "494:\tlearn: 0.0057206\ttotal: 17.8s\tremaining: 18.2s\n",
            "495:\tlearn: 0.0057180\ttotal: 17.8s\tremaining: 18.1s\n",
            "496:\tlearn: 0.0057034\ttotal: 17.9s\tremaining: 18.1s\n",
            "497:\tlearn: 0.0057014\ttotal: 17.9s\tremaining: 18s\n",
            "498:\tlearn: 0.0057005\ttotal: 17.9s\tremaining: 18s\n",
            "499:\tlearn: 0.0056916\ttotal: 17.9s\tremaining: 17.9s\n",
            "500:\tlearn: 0.0056893\ttotal: 18s\tremaining: 17.9s\n",
            "501:\tlearn: 0.0056862\ttotal: 18s\tremaining: 17.8s\n",
            "502:\tlearn: 0.0056846\ttotal: 18s\tremaining: 17.8s\n",
            "503:\tlearn: 0.0056825\ttotal: 18s\tremaining: 17.7s\n",
            "504:\tlearn: 0.0056809\ttotal: 18.1s\tremaining: 17.7s\n",
            "505:\tlearn: 0.0056755\ttotal: 18.1s\tremaining: 17.6s\n",
            "506:\tlearn: 0.0056719\ttotal: 18.1s\tremaining: 17.6s\n",
            "507:\tlearn: 0.0056702\ttotal: 18.1s\tremaining: 17.6s\n",
            "508:\tlearn: 0.0056694\ttotal: 18.2s\tremaining: 17.5s\n",
            "509:\tlearn: 0.0056680\ttotal: 18.2s\tremaining: 17.5s\n",
            "510:\tlearn: 0.0056656\ttotal: 18.2s\tremaining: 17.4s\n",
            "511:\tlearn: 0.0056610\ttotal: 18.2s\tremaining: 17.4s\n",
            "512:\tlearn: 0.0056598\ttotal: 18.3s\tremaining: 17.3s\n",
            "513:\tlearn: 0.0056581\ttotal: 18.3s\tremaining: 17.3s\n",
            "514:\tlearn: 0.0056569\ttotal: 18.3s\tremaining: 17.2s\n",
            "515:\tlearn: 0.0056558\ttotal: 18.3s\tremaining: 17.2s\n",
            "516:\tlearn: 0.0056543\ttotal: 18.3s\tremaining: 17.1s\n",
            "517:\tlearn: 0.0056521\ttotal: 18.4s\tremaining: 17.1s\n",
            "518:\tlearn: 0.0056514\ttotal: 18.4s\tremaining: 17.1s\n",
            "519:\tlearn: 0.0056493\ttotal: 18.4s\tremaining: 17s\n",
            "520:\tlearn: 0.0056399\ttotal: 18.4s\tremaining: 17s\n",
            "521:\tlearn: 0.0056362\ttotal: 18.5s\tremaining: 16.9s\n",
            "522:\tlearn: 0.0056342\ttotal: 18.5s\tremaining: 16.9s\n",
            "523:\tlearn: 0.0056330\ttotal: 18.5s\tremaining: 16.8s\n",
            "524:\tlearn: 0.0056313\ttotal: 18.5s\tremaining: 16.8s\n",
            "525:\tlearn: 0.0056297\ttotal: 18.6s\tremaining: 16.7s\n",
            "526:\tlearn: 0.0056272\ttotal: 18.6s\tremaining: 16.7s\n",
            "527:\tlearn: 0.0056240\ttotal: 18.6s\tremaining: 16.6s\n",
            "528:\tlearn: 0.0056209\ttotal: 18.6s\tremaining: 16.6s\n",
            "529:\tlearn: 0.0056114\ttotal: 18.7s\tremaining: 16.5s\n",
            "530:\tlearn: 0.0056088\ttotal: 18.7s\tremaining: 16.5s\n",
            "531:\tlearn: 0.0056051\ttotal: 18.7s\tremaining: 16.4s\n",
            "532:\tlearn: 0.0056019\ttotal: 18.7s\tremaining: 16.4s\n",
            "533:\tlearn: 0.0055997\ttotal: 18.7s\tremaining: 16.4s\n",
            "534:\tlearn: 0.0055986\ttotal: 18.8s\tremaining: 16.3s\n",
            "535:\tlearn: 0.0055960\ttotal: 18.8s\tremaining: 16.3s\n",
            "536:\tlearn: 0.0055910\ttotal: 18.8s\tremaining: 16.2s\n",
            "537:\tlearn: 0.0055893\ttotal: 18.8s\tremaining: 16.2s\n",
            "538:\tlearn: 0.0055873\ttotal: 18.9s\tremaining: 16.1s\n",
            "539:\tlearn: 0.0055851\ttotal: 18.9s\tremaining: 16.1s\n",
            "540:\tlearn: 0.0055811\ttotal: 18.9s\tremaining: 16s\n",
            "541:\tlearn: 0.0055789\ttotal: 18.9s\tremaining: 16s\n",
            "542:\tlearn: 0.0055762\ttotal: 19s\tremaining: 16s\n",
            "543:\tlearn: 0.0055744\ttotal: 19s\tremaining: 15.9s\n",
            "544:\tlearn: 0.0055730\ttotal: 19s\tremaining: 15.9s\n",
            "545:\tlearn: 0.0055722\ttotal: 19s\tremaining: 15.8s\n",
            "546:\tlearn: 0.0055683\ttotal: 19s\tremaining: 15.8s\n",
            "547:\tlearn: 0.0055571\ttotal: 19.1s\tremaining: 15.7s\n",
            "548:\tlearn: 0.0055533\ttotal: 19.1s\tremaining: 15.7s\n",
            "549:\tlearn: 0.0055527\ttotal: 19.1s\tremaining: 15.6s\n",
            "550:\tlearn: 0.0055494\ttotal: 19.1s\tremaining: 15.6s\n",
            "551:\tlearn: 0.0055482\ttotal: 19.2s\tremaining: 15.6s\n",
            "552:\tlearn: 0.0055472\ttotal: 19.2s\tremaining: 15.5s\n",
            "553:\tlearn: 0.0055452\ttotal: 19.2s\tremaining: 15.5s\n",
            "554:\tlearn: 0.0055439\ttotal: 19.3s\tremaining: 15.4s\n",
            "555:\tlearn: 0.0055409\ttotal: 19.3s\tremaining: 15.4s\n",
            "556:\tlearn: 0.0055381\ttotal: 19.3s\tremaining: 15.3s\n",
            "557:\tlearn: 0.0055366\ttotal: 19.3s\tremaining: 15.3s\n",
            "558:\tlearn: 0.0055354\ttotal: 19.3s\tremaining: 15.3s\n",
            "559:\tlearn: 0.0055328\ttotal: 19.4s\tremaining: 15.2s\n",
            "560:\tlearn: 0.0055295\ttotal: 19.4s\tremaining: 15.2s\n",
            "561:\tlearn: 0.0055269\ttotal: 19.4s\tremaining: 15.1s\n",
            "562:\tlearn: 0.0055262\ttotal: 19.4s\tremaining: 15.1s\n",
            "563:\tlearn: 0.0055251\ttotal: 19.5s\tremaining: 15s\n",
            "564:\tlearn: 0.0055217\ttotal: 19.5s\tremaining: 15s\n",
            "565:\tlearn: 0.0055196\ttotal: 19.5s\tremaining: 15s\n",
            "566:\tlearn: 0.0055183\ttotal: 19.5s\tremaining: 14.9s\n",
            "567:\tlearn: 0.0055167\ttotal: 19.6s\tremaining: 14.9s\n",
            "568:\tlearn: 0.0055151\ttotal: 19.6s\tremaining: 14.8s\n",
            "569:\tlearn: 0.0055113\ttotal: 19.6s\tremaining: 14.8s\n",
            "570:\tlearn: 0.0055091\ttotal: 19.6s\tremaining: 14.7s\n",
            "571:\tlearn: 0.0054950\ttotal: 19.7s\tremaining: 14.7s\n",
            "572:\tlearn: 0.0054903\ttotal: 19.7s\tremaining: 14.7s\n",
            "573:\tlearn: 0.0054892\ttotal: 19.7s\tremaining: 14.6s\n",
            "574:\tlearn: 0.0054875\ttotal: 19.7s\tremaining: 14.6s\n",
            "575:\tlearn: 0.0054808\ttotal: 19.8s\tremaining: 14.5s\n",
            "576:\tlearn: 0.0054795\ttotal: 19.8s\tremaining: 14.5s\n",
            "577:\tlearn: 0.0054766\ttotal: 19.8s\tremaining: 14.4s\n",
            "578:\tlearn: 0.0054736\ttotal: 19.8s\tremaining: 14.4s\n",
            "579:\tlearn: 0.0054725\ttotal: 19.8s\tremaining: 14.4s\n",
            "580:\tlearn: 0.0054703\ttotal: 19.9s\tremaining: 14.3s\n",
            "581:\tlearn: 0.0054679\ttotal: 19.9s\tremaining: 14.3s\n",
            "582:\tlearn: 0.0054626\ttotal: 19.9s\tremaining: 14.2s\n",
            "583:\tlearn: 0.0054617\ttotal: 19.9s\tremaining: 14.2s\n",
            "584:\tlearn: 0.0054604\ttotal: 20s\tremaining: 14.2s\n",
            "585:\tlearn: 0.0054591\ttotal: 20s\tremaining: 14.1s\n",
            "586:\tlearn: 0.0054583\ttotal: 20s\tremaining: 14.1s\n",
            "587:\tlearn: 0.0054565\ttotal: 20s\tremaining: 14s\n",
            "588:\tlearn: 0.0054556\ttotal: 20s\tremaining: 14s\n",
            "589:\tlearn: 0.0054545\ttotal: 20.1s\tremaining: 13.9s\n",
            "590:\tlearn: 0.0054536\ttotal: 20.1s\tremaining: 13.9s\n",
            "591:\tlearn: 0.0054519\ttotal: 20.1s\tremaining: 13.9s\n",
            "592:\tlearn: 0.0054512\ttotal: 20.1s\tremaining: 13.8s\n",
            "593:\tlearn: 0.0054502\ttotal: 20.2s\tremaining: 13.8s\n",
            "594:\tlearn: 0.0054486\ttotal: 20.2s\tremaining: 13.8s\n",
            "595:\tlearn: 0.0054452\ttotal: 20.2s\tremaining: 13.7s\n",
            "596:\tlearn: 0.0054419\ttotal: 20.2s\tremaining: 13.7s\n",
            "597:\tlearn: 0.0054399\ttotal: 20.3s\tremaining: 13.6s\n",
            "598:\tlearn: 0.0054372\ttotal: 20.3s\tremaining: 13.6s\n",
            "599:\tlearn: 0.0054359\ttotal: 20.3s\tremaining: 13.5s\n",
            "600:\tlearn: 0.0054342\ttotal: 20.3s\tremaining: 13.5s\n",
            "601:\tlearn: 0.0054292\ttotal: 20.4s\tremaining: 13.5s\n",
            "602:\tlearn: 0.0054274\ttotal: 20.4s\tremaining: 13.4s\n",
            "603:\tlearn: 0.0054208\ttotal: 20.5s\tremaining: 13.4s\n",
            "604:\tlearn: 0.0054193\ttotal: 20.5s\tremaining: 13.4s\n",
            "605:\tlearn: 0.0054180\ttotal: 20.6s\tremaining: 13.4s\n",
            "606:\tlearn: 0.0054167\ttotal: 20.6s\tremaining: 13.4s\n",
            "607:\tlearn: 0.0054160\ttotal: 20.7s\tremaining: 13.3s\n",
            "608:\tlearn: 0.0054147\ttotal: 20.7s\tremaining: 13.3s\n",
            "609:\tlearn: 0.0054127\ttotal: 20.8s\tremaining: 13.3s\n",
            "610:\tlearn: 0.0054117\ttotal: 20.9s\tremaining: 13.3s\n",
            "611:\tlearn: 0.0054077\ttotal: 20.9s\tremaining: 13.3s\n",
            "612:\tlearn: 0.0054028\ttotal: 21s\tremaining: 13.3s\n",
            "613:\tlearn: 0.0054024\ttotal: 21.1s\tremaining: 13.2s\n",
            "614:\tlearn: 0.0054015\ttotal: 21.1s\tremaining: 13.2s\n",
            "615:\tlearn: 0.0053969\ttotal: 21.2s\tremaining: 13.2s\n",
            "616:\tlearn: 0.0053949\ttotal: 21.2s\tremaining: 13.2s\n",
            "617:\tlearn: 0.0053945\ttotal: 21.3s\tremaining: 13.2s\n",
            "618:\tlearn: 0.0053915\ttotal: 21.4s\tremaining: 13.1s\n",
            "619:\tlearn: 0.0053908\ttotal: 21.4s\tremaining: 13.1s\n",
            "620:\tlearn: 0.0053894\ttotal: 21.5s\tremaining: 13.1s\n",
            "621:\tlearn: 0.0053880\ttotal: 21.6s\tremaining: 13.1s\n",
            "622:\tlearn: 0.0053867\ttotal: 21.6s\tremaining: 13.1s\n",
            "623:\tlearn: 0.0053853\ttotal: 21.7s\tremaining: 13.1s\n",
            "624:\tlearn: 0.0053830\ttotal: 21.8s\tremaining: 13.1s\n",
            "625:\tlearn: 0.0053819\ttotal: 21.8s\tremaining: 13s\n",
            "626:\tlearn: 0.0053791\ttotal: 21.9s\tremaining: 13s\n",
            "627:\tlearn: 0.0053763\ttotal: 21.9s\tremaining: 13s\n",
            "628:\tlearn: 0.0053710\ttotal: 22s\tremaining: 13s\n",
            "629:\tlearn: 0.0053687\ttotal: 22.1s\tremaining: 13s\n",
            "630:\tlearn: 0.0053608\ttotal: 22.1s\tremaining: 12.9s\n",
            "631:\tlearn: 0.0053591\ttotal: 22.2s\tremaining: 12.9s\n",
            "632:\tlearn: 0.0053587\ttotal: 22.3s\tremaining: 12.9s\n",
            "633:\tlearn: 0.0053583\ttotal: 22.3s\tremaining: 12.9s\n",
            "634:\tlearn: 0.0053569\ttotal: 22.4s\tremaining: 12.9s\n",
            "635:\tlearn: 0.0053499\ttotal: 22.4s\tremaining: 12.8s\n",
            "636:\tlearn: 0.0053482\ttotal: 22.5s\tremaining: 12.8s\n",
            "637:\tlearn: 0.0053454\ttotal: 22.6s\tremaining: 12.8s\n",
            "638:\tlearn: 0.0053437\ttotal: 22.7s\tremaining: 12.8s\n",
            "639:\tlearn: 0.0053430\ttotal: 22.7s\tremaining: 12.8s\n",
            "640:\tlearn: 0.0053422\ttotal: 22.8s\tremaining: 12.8s\n",
            "641:\tlearn: 0.0053388\ttotal: 22.9s\tremaining: 12.7s\n",
            "642:\tlearn: 0.0053333\ttotal: 22.9s\tremaining: 12.7s\n",
            "643:\tlearn: 0.0053323\ttotal: 23s\tremaining: 12.7s\n",
            "644:\tlearn: 0.0053318\ttotal: 23.1s\tremaining: 12.7s\n",
            "645:\tlearn: 0.0053287\ttotal: 23.1s\tremaining: 12.7s\n",
            "646:\tlearn: 0.0053262\ttotal: 23.2s\tremaining: 12.7s\n",
            "647:\tlearn: 0.0053231\ttotal: 23.3s\tremaining: 12.6s\n",
            "648:\tlearn: 0.0053216\ttotal: 23.3s\tremaining: 12.6s\n",
            "649:\tlearn: 0.0053144\ttotal: 23.4s\tremaining: 12.6s\n",
            "650:\tlearn: 0.0053126\ttotal: 23.5s\tremaining: 12.6s\n",
            "651:\tlearn: 0.0053109\ttotal: 23.6s\tremaining: 12.6s\n",
            "652:\tlearn: 0.0053091\ttotal: 23.6s\tremaining: 12.6s\n",
            "653:\tlearn: 0.0053069\ttotal: 23.7s\tremaining: 12.5s\n",
            "654:\tlearn: 0.0053013\ttotal: 23.8s\tremaining: 12.5s\n",
            "655:\tlearn: 0.0052997\ttotal: 23.9s\tremaining: 12.5s\n",
            "656:\tlearn: 0.0052972\ttotal: 23.9s\tremaining: 12.5s\n",
            "657:\tlearn: 0.0052947\ttotal: 24s\tremaining: 12.5s\n",
            "658:\tlearn: 0.0052894\ttotal: 24.1s\tremaining: 12.5s\n",
            "659:\tlearn: 0.0052883\ttotal: 24.1s\tremaining: 12.4s\n",
            "660:\tlearn: 0.0052870\ttotal: 24.2s\tremaining: 12.4s\n",
            "661:\tlearn: 0.0052864\ttotal: 24.3s\tremaining: 12.4s\n",
            "662:\tlearn: 0.0052853\ttotal: 24.3s\tremaining: 12.3s\n",
            "663:\tlearn: 0.0052829\ttotal: 24.3s\tremaining: 12.3s\n",
            "664:\tlearn: 0.0052810\ttotal: 24.3s\tremaining: 12.3s\n",
            "665:\tlearn: 0.0052784\ttotal: 24.4s\tremaining: 12.2s\n",
            "666:\tlearn: 0.0052771\ttotal: 24.4s\tremaining: 12.2s\n",
            "667:\tlearn: 0.0052762\ttotal: 24.4s\tremaining: 12.1s\n",
            "668:\tlearn: 0.0052753\ttotal: 24.4s\tremaining: 12.1s\n",
            "669:\tlearn: 0.0052736\ttotal: 24.5s\tremaining: 12.1s\n",
            "670:\tlearn: 0.0052726\ttotal: 24.5s\tremaining: 12s\n",
            "671:\tlearn: 0.0052722\ttotal: 24.5s\tremaining: 12s\n",
            "672:\tlearn: 0.0052714\ttotal: 24.5s\tremaining: 11.9s\n",
            "673:\tlearn: 0.0052639\ttotal: 24.6s\tremaining: 11.9s\n",
            "674:\tlearn: 0.0052620\ttotal: 24.6s\tremaining: 11.8s\n",
            "675:\tlearn: 0.0052604\ttotal: 24.6s\tremaining: 11.8s\n",
            "676:\tlearn: 0.0052561\ttotal: 24.6s\tremaining: 11.8s\n",
            "677:\tlearn: 0.0052557\ttotal: 24.7s\tremaining: 11.7s\n",
            "678:\tlearn: 0.0052533\ttotal: 24.7s\tremaining: 11.7s\n",
            "679:\tlearn: 0.0052470\ttotal: 24.7s\tremaining: 11.6s\n",
            "680:\tlearn: 0.0052457\ttotal: 24.7s\tremaining: 11.6s\n",
            "681:\tlearn: 0.0052445\ttotal: 24.8s\tremaining: 11.5s\n",
            "682:\tlearn: 0.0052423\ttotal: 24.8s\tremaining: 11.5s\n",
            "683:\tlearn: 0.0052417\ttotal: 24.8s\tremaining: 11.5s\n",
            "684:\tlearn: 0.0052380\ttotal: 24.8s\tremaining: 11.4s\n",
            "685:\tlearn: 0.0052353\ttotal: 24.9s\tremaining: 11.4s\n",
            "686:\tlearn: 0.0052344\ttotal: 24.9s\tremaining: 11.3s\n",
            "687:\tlearn: 0.0052331\ttotal: 24.9s\tremaining: 11.3s\n",
            "688:\tlearn: 0.0052315\ttotal: 24.9s\tremaining: 11.2s\n",
            "689:\tlearn: 0.0052306\ttotal: 24.9s\tremaining: 11.2s\n",
            "690:\tlearn: 0.0052295\ttotal: 25s\tremaining: 11.2s\n",
            "691:\tlearn: 0.0052283\ttotal: 25s\tremaining: 11.1s\n",
            "692:\tlearn: 0.0052273\ttotal: 25s\tremaining: 11.1s\n",
            "693:\tlearn: 0.0052265\ttotal: 25.1s\tremaining: 11s\n",
            "694:\tlearn: 0.0052256\ttotal: 25.1s\tremaining: 11s\n",
            "695:\tlearn: 0.0052236\ttotal: 25.1s\tremaining: 11s\n",
            "696:\tlearn: 0.0052208\ttotal: 25.1s\tremaining: 10.9s\n",
            "697:\tlearn: 0.0052202\ttotal: 25.1s\tremaining: 10.9s\n",
            "698:\tlearn: 0.0052197\ttotal: 25.2s\tremaining: 10.8s\n",
            "699:\tlearn: 0.0052188\ttotal: 25.2s\tremaining: 10.8s\n",
            "700:\tlearn: 0.0052183\ttotal: 25.2s\tremaining: 10.8s\n",
            "701:\tlearn: 0.0052164\ttotal: 25.2s\tremaining: 10.7s\n",
            "702:\tlearn: 0.0052149\ttotal: 25.3s\tremaining: 10.7s\n",
            "703:\tlearn: 0.0052139\ttotal: 25.3s\tremaining: 10.6s\n",
            "704:\tlearn: 0.0052118\ttotal: 25.3s\tremaining: 10.6s\n",
            "705:\tlearn: 0.0052113\ttotal: 25.3s\tremaining: 10.5s\n",
            "706:\tlearn: 0.0052090\ttotal: 25.4s\tremaining: 10.5s\n",
            "707:\tlearn: 0.0052074\ttotal: 25.4s\tremaining: 10.5s\n",
            "708:\tlearn: 0.0052053\ttotal: 25.4s\tremaining: 10.4s\n",
            "709:\tlearn: 0.0052038\ttotal: 25.4s\tremaining: 10.4s\n",
            "710:\tlearn: 0.0052022\ttotal: 25.5s\tremaining: 10.3s\n",
            "711:\tlearn: 0.0052013\ttotal: 25.5s\tremaining: 10.3s\n",
            "712:\tlearn: 0.0051998\ttotal: 25.5s\tremaining: 10.3s\n",
            "713:\tlearn: 0.0051982\ttotal: 25.5s\tremaining: 10.2s\n",
            "714:\tlearn: 0.0051964\ttotal: 25.5s\tremaining: 10.2s\n",
            "715:\tlearn: 0.0051958\ttotal: 25.6s\tremaining: 10.1s\n",
            "716:\tlearn: 0.0051947\ttotal: 25.6s\tremaining: 10.1s\n",
            "717:\tlearn: 0.0051923\ttotal: 25.6s\tremaining: 10.1s\n",
            "718:\tlearn: 0.0051919\ttotal: 25.6s\tremaining: 10s\n",
            "719:\tlearn: 0.0051900\ttotal: 25.7s\tremaining: 9.98s\n",
            "720:\tlearn: 0.0051868\ttotal: 25.7s\tremaining: 9.94s\n",
            "721:\tlearn: 0.0051849\ttotal: 25.7s\tremaining: 9.9s\n",
            "722:\tlearn: 0.0051826\ttotal: 25.7s\tremaining: 9.86s\n",
            "723:\tlearn: 0.0051789\ttotal: 25.8s\tremaining: 9.82s\n",
            "724:\tlearn: 0.0051785\ttotal: 25.8s\tremaining: 9.78s\n",
            "725:\tlearn: 0.0051777\ttotal: 25.8s\tremaining: 9.74s\n",
            "726:\tlearn: 0.0051769\ttotal: 25.8s\tremaining: 9.7s\n",
            "727:\tlearn: 0.0051748\ttotal: 25.8s\tremaining: 9.66s\n",
            "728:\tlearn: 0.0051744\ttotal: 25.9s\tremaining: 9.62s\n",
            "729:\tlearn: 0.0051737\ttotal: 25.9s\tremaining: 9.58s\n",
            "730:\tlearn: 0.0051721\ttotal: 25.9s\tremaining: 9.54s\n",
            "731:\tlearn: 0.0051708\ttotal: 25.9s\tremaining: 9.5s\n",
            "732:\tlearn: 0.0051692\ttotal: 26s\tremaining: 9.46s\n",
            "733:\tlearn: 0.0051682\ttotal: 26s\tremaining: 9.42s\n",
            "734:\tlearn: 0.0051667\ttotal: 26s\tremaining: 9.38s\n",
            "735:\tlearn: 0.0051661\ttotal: 26s\tremaining: 9.34s\n",
            "736:\tlearn: 0.0051655\ttotal: 26.1s\tremaining: 9.3s\n",
            "737:\tlearn: 0.0051653\ttotal: 26.1s\tremaining: 9.26s\n",
            "738:\tlearn: 0.0051642\ttotal: 26.1s\tremaining: 9.22s\n",
            "739:\tlearn: 0.0051634\ttotal: 26.1s\tremaining: 9.18s\n",
            "740:\tlearn: 0.0051620\ttotal: 26.1s\tremaining: 9.14s\n",
            "741:\tlearn: 0.0051612\ttotal: 26.2s\tremaining: 9.1s\n",
            "742:\tlearn: 0.0051593\ttotal: 26.2s\tremaining: 9.06s\n",
            "743:\tlearn: 0.0051580\ttotal: 26.2s\tremaining: 9.02s\n",
            "744:\tlearn: 0.0051571\ttotal: 26.2s\tremaining: 8.98s\n",
            "745:\tlearn: 0.0051499\ttotal: 26.3s\tremaining: 8.95s\n",
            "746:\tlearn: 0.0051491\ttotal: 26.3s\tremaining: 8.91s\n",
            "747:\tlearn: 0.0051485\ttotal: 26.3s\tremaining: 8.87s\n",
            "748:\tlearn: 0.0051476\ttotal: 26.4s\tremaining: 8.83s\n",
            "749:\tlearn: 0.0051442\ttotal: 26.4s\tremaining: 8.79s\n",
            "750:\tlearn: 0.0051438\ttotal: 26.4s\tremaining: 8.75s\n",
            "751:\tlearn: 0.0051432\ttotal: 26.4s\tremaining: 8.71s\n",
            "752:\tlearn: 0.0051429\ttotal: 26.5s\tremaining: 8.68s\n",
            "753:\tlearn: 0.0051418\ttotal: 26.5s\tremaining: 8.64s\n",
            "754:\tlearn: 0.0051405\ttotal: 26.5s\tremaining: 8.6s\n",
            "755:\tlearn: 0.0051397\ttotal: 26.5s\tremaining: 8.56s\n",
            "756:\tlearn: 0.0051390\ttotal: 26.5s\tremaining: 8.52s\n",
            "757:\tlearn: 0.0051360\ttotal: 26.6s\tremaining: 8.48s\n",
            "758:\tlearn: 0.0051344\ttotal: 26.6s\tremaining: 8.44s\n",
            "759:\tlearn: 0.0051334\ttotal: 26.6s\tremaining: 8.4s\n",
            "760:\tlearn: 0.0051323\ttotal: 26.6s\tremaining: 8.37s\n",
            "761:\tlearn: 0.0051307\ttotal: 26.7s\tremaining: 8.33s\n",
            "762:\tlearn: 0.0051268\ttotal: 26.7s\tremaining: 8.29s\n",
            "763:\tlearn: 0.0051253\ttotal: 26.7s\tremaining: 8.25s\n",
            "764:\tlearn: 0.0051250\ttotal: 26.7s\tremaining: 8.21s\n",
            "765:\tlearn: 0.0051217\ttotal: 26.8s\tremaining: 8.17s\n",
            "766:\tlearn: 0.0051206\ttotal: 26.8s\tremaining: 8.13s\n",
            "767:\tlearn: 0.0051186\ttotal: 26.8s\tremaining: 8.1s\n",
            "768:\tlearn: 0.0051151\ttotal: 26.8s\tremaining: 8.06s\n",
            "769:\tlearn: 0.0051146\ttotal: 26.8s\tremaining: 8.02s\n",
            "770:\tlearn: 0.0051129\ttotal: 26.9s\tremaining: 7.98s\n",
            "771:\tlearn: 0.0051117\ttotal: 26.9s\tremaining: 7.94s\n",
            "772:\tlearn: 0.0051106\ttotal: 26.9s\tremaining: 7.91s\n",
            "773:\tlearn: 0.0051074\ttotal: 26.9s\tremaining: 7.87s\n",
            "774:\tlearn: 0.0051062\ttotal: 27s\tremaining: 7.83s\n",
            "775:\tlearn: 0.0051009\ttotal: 27s\tremaining: 7.79s\n",
            "776:\tlearn: 0.0050989\ttotal: 27s\tremaining: 7.75s\n",
            "777:\tlearn: 0.0050984\ttotal: 27s\tremaining: 7.71s\n",
            "778:\tlearn: 0.0050970\ttotal: 27.1s\tremaining: 7.68s\n",
            "779:\tlearn: 0.0050962\ttotal: 27.1s\tremaining: 7.64s\n",
            "780:\tlearn: 0.0050942\ttotal: 27.1s\tremaining: 7.6s\n",
            "781:\tlearn: 0.0050928\ttotal: 27.1s\tremaining: 7.57s\n",
            "782:\tlearn: 0.0050923\ttotal: 27.2s\tremaining: 7.53s\n",
            "783:\tlearn: 0.0050910\ttotal: 27.2s\tremaining: 7.49s\n",
            "784:\tlearn: 0.0050896\ttotal: 27.2s\tremaining: 7.45s\n",
            "785:\tlearn: 0.0050889\ttotal: 27.2s\tremaining: 7.41s\n",
            "786:\tlearn: 0.0050880\ttotal: 27.2s\tremaining: 7.38s\n",
            "787:\tlearn: 0.0050866\ttotal: 27.3s\tremaining: 7.34s\n",
            "788:\tlearn: 0.0050841\ttotal: 27.3s\tremaining: 7.3s\n",
            "789:\tlearn: 0.0050833\ttotal: 27.3s\tremaining: 7.27s\n",
            "790:\tlearn: 0.0050828\ttotal: 27.4s\tremaining: 7.23s\n",
            "791:\tlearn: 0.0050810\ttotal: 27.4s\tremaining: 7.19s\n",
            "792:\tlearn: 0.0050794\ttotal: 27.4s\tremaining: 7.16s\n",
            "793:\tlearn: 0.0050781\ttotal: 27.4s\tremaining: 7.12s\n",
            "794:\tlearn: 0.0050762\ttotal: 27.5s\tremaining: 7.08s\n",
            "795:\tlearn: 0.0050740\ttotal: 27.5s\tremaining: 7.04s\n",
            "796:\tlearn: 0.0050693\ttotal: 27.5s\tremaining: 7s\n",
            "797:\tlearn: 0.0050683\ttotal: 27.5s\tremaining: 6.97s\n",
            "798:\tlearn: 0.0050673\ttotal: 27.6s\tremaining: 6.93s\n",
            "799:\tlearn: 0.0050647\ttotal: 27.6s\tremaining: 6.89s\n",
            "800:\tlearn: 0.0050642\ttotal: 27.6s\tremaining: 6.86s\n",
            "801:\tlearn: 0.0050627\ttotal: 27.6s\tremaining: 6.82s\n",
            "802:\tlearn: 0.0050618\ttotal: 27.6s\tremaining: 6.78s\n",
            "803:\tlearn: 0.0050610\ttotal: 27.7s\tremaining: 6.74s\n",
            "804:\tlearn: 0.0050606\ttotal: 27.7s\tremaining: 6.71s\n",
            "805:\tlearn: 0.0050592\ttotal: 27.7s\tremaining: 6.67s\n",
            "806:\tlearn: 0.0050574\ttotal: 27.7s\tremaining: 6.63s\n",
            "807:\tlearn: 0.0050565\ttotal: 27.8s\tremaining: 6.6s\n",
            "808:\tlearn: 0.0050558\ttotal: 27.8s\tremaining: 6.56s\n",
            "809:\tlearn: 0.0050543\ttotal: 27.8s\tremaining: 6.52s\n",
            "810:\tlearn: 0.0050521\ttotal: 27.8s\tremaining: 6.49s\n",
            "811:\tlearn: 0.0050502\ttotal: 27.9s\tremaining: 6.45s\n",
            "812:\tlearn: 0.0050487\ttotal: 27.9s\tremaining: 6.41s\n",
            "813:\tlearn: 0.0050482\ttotal: 27.9s\tremaining: 6.38s\n",
            "814:\tlearn: 0.0050414\ttotal: 27.9s\tremaining: 6.34s\n",
            "815:\tlearn: 0.0050398\ttotal: 28s\tremaining: 6.3s\n",
            "816:\tlearn: 0.0050373\ttotal: 28s\tremaining: 6.27s\n",
            "817:\tlearn: 0.0050365\ttotal: 28s\tremaining: 6.23s\n",
            "818:\tlearn: 0.0050332\ttotal: 28s\tremaining: 6.19s\n",
            "819:\tlearn: 0.0050314\ttotal: 28s\tremaining: 6.16s\n",
            "820:\tlearn: 0.0050280\ttotal: 28.1s\tremaining: 6.12s\n",
            "821:\tlearn: 0.0050263\ttotal: 28.1s\tremaining: 6.08s\n",
            "822:\tlearn: 0.0050254\ttotal: 28.1s\tremaining: 6.05s\n",
            "823:\tlearn: 0.0050242\ttotal: 28.1s\tremaining: 6.01s\n",
            "824:\tlearn: 0.0050233\ttotal: 28.2s\tremaining: 5.97s\n",
            "825:\tlearn: 0.0050208\ttotal: 28.2s\tremaining: 5.94s\n",
            "826:\tlearn: 0.0050202\ttotal: 28.2s\tremaining: 5.9s\n",
            "827:\tlearn: 0.0050185\ttotal: 28.2s\tremaining: 5.87s\n",
            "828:\tlearn: 0.0050178\ttotal: 28.3s\tremaining: 5.83s\n",
            "829:\tlearn: 0.0050166\ttotal: 28.3s\tremaining: 5.79s\n",
            "830:\tlearn: 0.0050128\ttotal: 28.3s\tremaining: 5.76s\n",
            "831:\tlearn: 0.0050124\ttotal: 28.3s\tremaining: 5.72s\n",
            "832:\tlearn: 0.0050110\ttotal: 28.4s\tremaining: 5.69s\n",
            "833:\tlearn: 0.0050100\ttotal: 28.4s\tremaining: 5.65s\n",
            "834:\tlearn: 0.0050086\ttotal: 28.4s\tremaining: 5.61s\n",
            "835:\tlearn: 0.0050078\ttotal: 28.4s\tremaining: 5.58s\n",
            "836:\tlearn: 0.0050074\ttotal: 28.5s\tremaining: 5.54s\n",
            "837:\tlearn: 0.0050064\ttotal: 28.5s\tremaining: 5.5s\n",
            "838:\tlearn: 0.0050054\ttotal: 28.5s\tremaining: 5.47s\n",
            "839:\tlearn: 0.0049998\ttotal: 28.5s\tremaining: 5.43s\n",
            "840:\tlearn: 0.0049996\ttotal: 28.6s\tremaining: 5.4s\n",
            "841:\tlearn: 0.0049993\ttotal: 28.6s\tremaining: 5.36s\n",
            "842:\tlearn: 0.0049983\ttotal: 28.6s\tremaining: 5.33s\n",
            "843:\tlearn: 0.0049974\ttotal: 28.6s\tremaining: 5.29s\n",
            "844:\tlearn: 0.0049958\ttotal: 28.7s\tremaining: 5.26s\n",
            "845:\tlearn: 0.0049939\ttotal: 28.7s\tremaining: 5.22s\n",
            "846:\tlearn: 0.0049920\ttotal: 28.7s\tremaining: 5.18s\n",
            "847:\tlearn: 0.0049901\ttotal: 28.7s\tremaining: 5.15s\n",
            "848:\tlearn: 0.0049887\ttotal: 28.7s\tremaining: 5.11s\n",
            "849:\tlearn: 0.0049881\ttotal: 28.8s\tremaining: 5.08s\n",
            "850:\tlearn: 0.0049873\ttotal: 28.8s\tremaining: 5.04s\n",
            "851:\tlearn: 0.0049870\ttotal: 28.8s\tremaining: 5.01s\n",
            "852:\tlearn: 0.0049862\ttotal: 28.8s\tremaining: 4.97s\n",
            "853:\tlearn: 0.0049857\ttotal: 28.9s\tremaining: 4.93s\n",
            "854:\tlearn: 0.0049851\ttotal: 28.9s\tremaining: 4.9s\n",
            "855:\tlearn: 0.0049844\ttotal: 28.9s\tremaining: 4.86s\n",
            "856:\tlearn: 0.0049836\ttotal: 28.9s\tremaining: 4.83s\n",
            "857:\tlearn: 0.0049824\ttotal: 29s\tremaining: 4.79s\n",
            "858:\tlearn: 0.0049801\ttotal: 29s\tremaining: 4.76s\n",
            "859:\tlearn: 0.0049787\ttotal: 29s\tremaining: 4.72s\n",
            "860:\tlearn: 0.0049783\ttotal: 29s\tremaining: 4.69s\n",
            "861:\tlearn: 0.0049766\ttotal: 29.1s\tremaining: 4.65s\n",
            "862:\tlearn: 0.0049759\ttotal: 29.1s\tremaining: 4.62s\n",
            "863:\tlearn: 0.0049745\ttotal: 29.1s\tremaining: 4.58s\n",
            "864:\tlearn: 0.0049737\ttotal: 29.1s\tremaining: 4.54s\n",
            "865:\tlearn: 0.0049708\ttotal: 29.1s\tremaining: 4.51s\n",
            "866:\tlearn: 0.0049698\ttotal: 29.2s\tremaining: 4.47s\n",
            "867:\tlearn: 0.0049693\ttotal: 29.2s\tremaining: 4.44s\n",
            "868:\tlearn: 0.0049689\ttotal: 29.2s\tremaining: 4.4s\n",
            "869:\tlearn: 0.0049683\ttotal: 29.2s\tremaining: 4.37s\n",
            "870:\tlearn: 0.0049675\ttotal: 29.3s\tremaining: 4.33s\n",
            "871:\tlearn: 0.0049668\ttotal: 29.3s\tremaining: 4.3s\n",
            "872:\tlearn: 0.0049649\ttotal: 29.3s\tremaining: 4.26s\n",
            "873:\tlearn: 0.0049628\ttotal: 29.3s\tremaining: 4.23s\n",
            "874:\tlearn: 0.0049622\ttotal: 29.4s\tremaining: 4.2s\n",
            "875:\tlearn: 0.0049618\ttotal: 29.4s\tremaining: 4.16s\n",
            "876:\tlearn: 0.0049606\ttotal: 29.4s\tremaining: 4.13s\n",
            "877:\tlearn: 0.0049595\ttotal: 29.4s\tremaining: 4.09s\n",
            "878:\tlearn: 0.0049563\ttotal: 29.5s\tremaining: 4.06s\n",
            "879:\tlearn: 0.0049558\ttotal: 29.5s\tremaining: 4.02s\n",
            "880:\tlearn: 0.0049551\ttotal: 29.5s\tremaining: 3.99s\n",
            "881:\tlearn: 0.0049534\ttotal: 29.5s\tremaining: 3.95s\n",
            "882:\tlearn: 0.0049522\ttotal: 29.6s\tremaining: 3.92s\n",
            "883:\tlearn: 0.0049507\ttotal: 29.6s\tremaining: 3.88s\n",
            "884:\tlearn: 0.0049490\ttotal: 29.6s\tremaining: 3.85s\n",
            "885:\tlearn: 0.0049478\ttotal: 29.6s\tremaining: 3.81s\n",
            "886:\tlearn: 0.0049470\ttotal: 29.7s\tremaining: 3.78s\n",
            "887:\tlearn: 0.0049461\ttotal: 29.7s\tremaining: 3.74s\n",
            "888:\tlearn: 0.0049454\ttotal: 29.7s\tremaining: 3.71s\n",
            "889:\tlearn: 0.0049448\ttotal: 29.7s\tremaining: 3.67s\n",
            "890:\tlearn: 0.0049440\ttotal: 29.7s\tremaining: 3.64s\n",
            "891:\tlearn: 0.0049429\ttotal: 29.8s\tremaining: 3.6s\n",
            "892:\tlearn: 0.0049413\ttotal: 29.8s\tremaining: 3.57s\n",
            "893:\tlearn: 0.0049402\ttotal: 29.8s\tremaining: 3.54s\n",
            "894:\tlearn: 0.0049346\ttotal: 29.8s\tremaining: 3.5s\n",
            "895:\tlearn: 0.0049337\ttotal: 29.9s\tremaining: 3.46s\n",
            "896:\tlearn: 0.0049326\ttotal: 29.9s\tremaining: 3.43s\n",
            "897:\tlearn: 0.0049318\ttotal: 29.9s\tremaining: 3.4s\n",
            "898:\tlearn: 0.0049308\ttotal: 29.9s\tremaining: 3.36s\n",
            "899:\tlearn: 0.0049299\ttotal: 30s\tremaining: 3.33s\n",
            "900:\tlearn: 0.0049293\ttotal: 30s\tremaining: 3.29s\n",
            "901:\tlearn: 0.0049237\ttotal: 30s\tremaining: 3.26s\n",
            "902:\tlearn: 0.0049225\ttotal: 30s\tremaining: 3.23s\n",
            "903:\tlearn: 0.0049220\ttotal: 30s\tremaining: 3.19s\n",
            "904:\tlearn: 0.0049207\ttotal: 30.1s\tremaining: 3.16s\n",
            "905:\tlearn: 0.0049200\ttotal: 30.1s\tremaining: 3.12s\n",
            "906:\tlearn: 0.0049184\ttotal: 30.1s\tremaining: 3.09s\n",
            "907:\tlearn: 0.0049165\ttotal: 30.1s\tremaining: 3.05s\n",
            "908:\tlearn: 0.0049135\ttotal: 30.2s\tremaining: 3.02s\n",
            "909:\tlearn: 0.0049125\ttotal: 30.2s\tremaining: 2.98s\n",
            "910:\tlearn: 0.0049093\ttotal: 30.2s\tremaining: 2.95s\n",
            "911:\tlearn: 0.0049081\ttotal: 30.2s\tremaining: 2.92s\n",
            "912:\tlearn: 0.0049076\ttotal: 30.3s\tremaining: 2.88s\n",
            "913:\tlearn: 0.0049070\ttotal: 30.3s\tremaining: 2.85s\n",
            "914:\tlearn: 0.0049063\ttotal: 30.3s\tremaining: 2.82s\n",
            "915:\tlearn: 0.0049056\ttotal: 30.3s\tremaining: 2.78s\n",
            "916:\tlearn: 0.0049053\ttotal: 30.4s\tremaining: 2.75s\n",
            "917:\tlearn: 0.0048989\ttotal: 30.4s\tremaining: 2.71s\n",
            "918:\tlearn: 0.0048986\ttotal: 30.4s\tremaining: 2.68s\n",
            "919:\tlearn: 0.0048975\ttotal: 30.4s\tremaining: 2.65s\n",
            "920:\tlearn: 0.0048950\ttotal: 30.5s\tremaining: 2.61s\n",
            "921:\tlearn: 0.0048943\ttotal: 30.5s\tremaining: 2.58s\n",
            "922:\tlearn: 0.0048933\ttotal: 30.5s\tremaining: 2.54s\n",
            "923:\tlearn: 0.0048929\ttotal: 30.5s\tremaining: 2.51s\n",
            "924:\tlearn: 0.0048920\ttotal: 30.6s\tremaining: 2.48s\n",
            "925:\tlearn: 0.0048918\ttotal: 30.6s\tremaining: 2.44s\n",
            "926:\tlearn: 0.0048914\ttotal: 30.6s\tremaining: 2.41s\n",
            "927:\tlearn: 0.0048910\ttotal: 30.6s\tremaining: 2.38s\n",
            "928:\tlearn: 0.0048895\ttotal: 30.6s\tremaining: 2.34s\n",
            "929:\tlearn: 0.0048884\ttotal: 30.7s\tremaining: 2.31s\n",
            "930:\tlearn: 0.0048866\ttotal: 30.7s\tremaining: 2.27s\n",
            "931:\tlearn: 0.0048855\ttotal: 30.7s\tremaining: 2.24s\n",
            "932:\tlearn: 0.0048841\ttotal: 30.7s\tremaining: 2.21s\n",
            "933:\tlearn: 0.0048820\ttotal: 30.8s\tremaining: 2.17s\n",
            "934:\tlearn: 0.0048809\ttotal: 30.8s\tremaining: 2.14s\n",
            "935:\tlearn: 0.0048797\ttotal: 30.8s\tremaining: 2.11s\n",
            "936:\tlearn: 0.0048792\ttotal: 30.8s\tremaining: 2.07s\n",
            "937:\tlearn: 0.0048790\ttotal: 30.9s\tremaining: 2.04s\n",
            "938:\tlearn: 0.0048753\ttotal: 30.9s\tremaining: 2.01s\n",
            "939:\tlearn: 0.0048748\ttotal: 30.9s\tremaining: 1.97s\n",
            "940:\tlearn: 0.0048742\ttotal: 30.9s\tremaining: 1.94s\n",
            "941:\tlearn: 0.0048714\ttotal: 31s\tremaining: 1.91s\n",
            "942:\tlearn: 0.0048703\ttotal: 31s\tremaining: 1.87s\n",
            "943:\tlearn: 0.0048693\ttotal: 31s\tremaining: 1.84s\n",
            "944:\tlearn: 0.0048671\ttotal: 31s\tremaining: 1.8s\n",
            "945:\tlearn: 0.0048668\ttotal: 31s\tremaining: 1.77s\n",
            "946:\tlearn: 0.0048617\ttotal: 31.1s\tremaining: 1.74s\n",
            "947:\tlearn: 0.0048605\ttotal: 31.1s\tremaining: 1.71s\n",
            "948:\tlearn: 0.0048596\ttotal: 31.1s\tremaining: 1.67s\n",
            "949:\tlearn: 0.0048586\ttotal: 31.1s\tremaining: 1.64s\n",
            "950:\tlearn: 0.0048554\ttotal: 31.2s\tremaining: 1.6s\n",
            "951:\tlearn: 0.0048544\ttotal: 31.2s\tremaining: 1.57s\n",
            "952:\tlearn: 0.0048475\ttotal: 31.2s\tremaining: 1.54s\n",
            "953:\tlearn: 0.0048469\ttotal: 31.2s\tremaining: 1.51s\n",
            "954:\tlearn: 0.0048466\ttotal: 31.3s\tremaining: 1.47s\n",
            "955:\tlearn: 0.0048461\ttotal: 31.3s\tremaining: 1.44s\n",
            "956:\tlearn: 0.0048447\ttotal: 31.3s\tremaining: 1.41s\n",
            "957:\tlearn: 0.0048430\ttotal: 31.3s\tremaining: 1.37s\n",
            "958:\tlearn: 0.0048415\ttotal: 31.4s\tremaining: 1.34s\n",
            "959:\tlearn: 0.0048401\ttotal: 31.4s\tremaining: 1.31s\n",
            "960:\tlearn: 0.0048392\ttotal: 31.4s\tremaining: 1.27s\n",
            "961:\tlearn: 0.0048373\ttotal: 31.4s\tremaining: 1.24s\n",
            "962:\tlearn: 0.0048366\ttotal: 31.5s\tremaining: 1.21s\n",
            "963:\tlearn: 0.0048331\ttotal: 31.5s\tremaining: 1.18s\n",
            "964:\tlearn: 0.0048321\ttotal: 31.5s\tremaining: 1.14s\n",
            "965:\tlearn: 0.0048307\ttotal: 31.5s\tremaining: 1.11s\n",
            "966:\tlearn: 0.0048291\ttotal: 31.6s\tremaining: 1.08s\n",
            "967:\tlearn: 0.0048288\ttotal: 31.6s\tremaining: 1.04s\n",
            "968:\tlearn: 0.0048285\ttotal: 31.6s\tremaining: 1.01s\n",
            "969:\tlearn: 0.0048276\ttotal: 31.6s\tremaining: 978ms\n",
            "970:\tlearn: 0.0048274\ttotal: 31.6s\tremaining: 945ms\n",
            "971:\tlearn: 0.0048268\ttotal: 31.7s\tremaining: 912ms\n",
            "972:\tlearn: 0.0048252\ttotal: 31.7s\tremaining: 879ms\n",
            "973:\tlearn: 0.0048244\ttotal: 31.7s\tremaining: 847ms\n",
            "974:\tlearn: 0.0048240\ttotal: 31.7s\tremaining: 814ms\n",
            "975:\tlearn: 0.0048219\ttotal: 31.8s\tremaining: 781ms\n",
            "976:\tlearn: 0.0048205\ttotal: 31.8s\tremaining: 748ms\n",
            "977:\tlearn: 0.0048200\ttotal: 31.8s\tremaining: 716ms\n",
            "978:\tlearn: 0.0048196\ttotal: 31.8s\tremaining: 683ms\n",
            "979:\tlearn: 0.0048185\ttotal: 31.9s\tremaining: 650ms\n",
            "980:\tlearn: 0.0048177\ttotal: 31.9s\tremaining: 618ms\n",
            "981:\tlearn: 0.0048167\ttotal: 31.9s\tremaining: 585ms\n",
            "982:\tlearn: 0.0048160\ttotal: 31.9s\tremaining: 552ms\n",
            "983:\tlearn: 0.0048156\ttotal: 32s\tremaining: 520ms\n",
            "984:\tlearn: 0.0048150\ttotal: 32s\tremaining: 487ms\n",
            "985:\tlearn: 0.0048134\ttotal: 32s\tremaining: 455ms\n",
            "986:\tlearn: 0.0048124\ttotal: 32s\tremaining: 422ms\n",
            "987:\tlearn: 0.0048121\ttotal: 32.1s\tremaining: 389ms\n",
            "988:\tlearn: 0.0048109\ttotal: 32.1s\tremaining: 357ms\n",
            "989:\tlearn: 0.0048106\ttotal: 32.1s\tremaining: 324ms\n",
            "990:\tlearn: 0.0048100\ttotal: 32.1s\tremaining: 292ms\n",
            "991:\tlearn: 0.0048085\ttotal: 32.1s\tremaining: 259ms\n",
            "992:\tlearn: 0.0048068\ttotal: 32.2s\tremaining: 227ms\n",
            "993:\tlearn: 0.0048051\ttotal: 32.2s\tremaining: 194ms\n",
            "994:\tlearn: 0.0048044\ttotal: 32.2s\tremaining: 162ms\n",
            "995:\tlearn: 0.0048030\ttotal: 32.2s\tremaining: 129ms\n",
            "996:\tlearn: 0.0048026\ttotal: 32.3s\tremaining: 97.1ms\n",
            "997:\tlearn: 0.0048020\ttotal: 32.3s\tremaining: 64.7ms\n",
            "998:\tlearn: 0.0047992\ttotal: 32.3s\tremaining: 32.4ms\n",
            "999:\tlearn: 0.0047987\ttotal: 32.4s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c1baa54acb0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nan_mode': 'Min', 'gpu_ram_part': 0.95, 'eval_metric': 'MultiClass', 'combinations_ctr': ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1', 'FeatureFreq:CtrBorderCount=15:CtrBorderType=Median:Prior=0/1'], 'iterations': 1000, 'fold_permutation_block': 64, 'leaf_estimation_method': 'Newton', 'observations_to_bootstrap': 'TestOnly', 'random_score_type': 'NormalWithModelSizeDecrease', 'counter_calc_method': 'SkipTest', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'ctr_history_unit': 'Sample', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'one_hot_max_size': 2, 'devices': '-1', 'eval_fraction': 0, 'pinned_memory_bytes': '104857600', 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'gpu_cat_features_storage': 'GpuRam', 'fold_size_loss_normalization': False, 'max_ctr_complexity': 4, 'model_size_reg': 0.5, 'simple_ctr': ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1', 'FeatureFreq:CtrBorderCount=15:CtrBorderType=MinEntropy:Prior=0/1'], 'pool_metainfo_options': {'tags': {}}, 'use_best_model': False, 'meta_l2_frequency': 0, 'class_names': ['BENIGN', 'Bot', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS slowloris', 'FTP-Patator', 'Heartbleed', 'Infiltration', 'PortScan', 'SSH-Patator', 'Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ Sql Injection', 'Web Attack ÔøΩ XSS'], 'random_seed': 12345, 'depth': 6, 'ctr_target_border_count': 1, 'has_time': False, 'border_count': 128, 'min_fold_size': 100, 'data_partition': 'DocParallel', 'bagging_temperature': 1, 'classes_count': 0, 'auto_class_weights': 'None', 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'min_data_in_leaf': 1, 'add_ridge_penalty_to_loss_function': False, 'loss_function': 'MultiClass', 'learning_rate': 0.20834599435329437, 'meta_l2_exponent': 1, 'score_function': 'Cosine', 'task_type': 'GPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'Bayesian', 'max_leaves': 64, 'permutation_count': 1}\n"
          ]
        }
      ],
      "source": [
        "# —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–æ—Å—Ç–æ–π CatBoost\n",
        "model_bas_cb = CatBoostClassifier(cat_features=[30,31,32,33,43,44,45,46,47,48,49,50],\n",
        "                                  task_type=\"GPU\",\n",
        "                                  random_state=12345)\n",
        "\n",
        "model_bas_cb.fit(features_train, target_train)\n",
        "\n",
        "print(model_bas_cb.get_all_params())\n",
        "\n",
        "# –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é Google Colab –Ω–µ —Ä–∏—Å—É–µ—Ç, –∞ –æ—á–µ–Ω—å —Ö–æ—Ç–µ–ª–æ—Å—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b8016081",
      "metadata": {
        "id": "b8016081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630d4a20-f3d3-4909-918f-5a64cffa7355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9973682825411864\n",
            "F1_macro: 0.9175435844452597\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      1.00      1.00     37244\n",
            "                  PortScan       0.94      0.97      0.96       312\n",
            "                  DoS Hulk       1.00      1.00      1.00     10298\n",
            "                      DDoS       1.00      1.00      1.00      1646\n",
            "                       Bot       1.00      1.00      1.00     13960\n",
            "              Infiltration       1.00      0.99      0.99       836\n",
            "  Web Attack ÔøΩ Brute Force       1.00      0.99      0.99       862\n",
            "          Web Attack ÔøΩ XSS       1.00      1.00      1.00       949\n",
            "Web Attack ÔøΩ Sql Injection       1.00      1.00      1.00         2\n",
            "               FTP-Patator       1.00      1.00      1.00         6\n",
            "               SSH-Patator       1.00      1.00      1.00      9024\n",
            "             DoS slowloris       1.00      1.00      1.00       515\n",
            "          DoS Slowhttptest       0.72      0.80      0.76       235\n",
            "             DoS GoldenEye       0.60      1.00      0.75         3\n",
            "                Heartbleed       0.38      0.27      0.32       104\n",
            "\n",
            "                  accuracy                           1.00     75996\n",
            "                 macro avg       0.91      0.94      0.92     75996\n",
            "              weighted avg       1.00      1.00      1.00     75996\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c1baa54acb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "prediction(model_bas_cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–µ–±–æ–ª—å—à–æ–π –≤—ã–≤–æ–¥: –í —Ü–µ–ª–æ–º, –¥–∞–∂–µ –ø—Ä–æ—Å—Ç–æ–π CatBoost —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ª—É—á—à–µ Baseline.\n",
        "\n",
        "–ù–∞–¥–æ –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã: DoS Slowhttptest, DoS GoldenEye –∏ Heartbleed. –ò–º–µ–Ω–Ω–æ –∏—Ö –º–æ–¥–µ–ª—å —Å–∏–ª—å–Ω–æ –ø—É—Ç–∞–µ—Ç."
      ],
      "metadata": {
        "id": "VB72rk-Hy6HB"
      },
      "id": "VB72rk-Hy6HB"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d21010f5",
      "metadata": {
        "id": "d21010f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd6a0672-4698-4769-a036-c61ddd50b544"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         feature    importance\n",
              "28        Bwd Packet Length Mean  1.030737e+00\n",
              "29                   Bwd IAT Min  1.024658e+00\n",
              "30             Subflow Bwd Bytes  8.341108e-01\n",
              "31                URG Flag Count  7.683885e-01\n",
              "32                ACK Flag Count  7.245434e-01\n",
              "33         Bwd Packet Length Max  6.657735e-01\n",
              "34                   Fwd IAT Max  6.619831e-01\n",
              "35                  Fwd IAT Mean  6.048312e-01\n",
              "36                  Bwd IAT Mean  5.883093e-01\n",
              "37                   Bwd IAT Std  5.444477e-01\n",
              "38                     Idle Mean  4.927824e-01\n",
              "39          Avg Fwd Segment Size  3.909295e-01\n",
              "40              act_data_pkt_fwd  3.817975e-01\n",
              "41                      Idle Max  3.769778e-01\n",
              "42                 Down/Up Ratio  3.492234e-01\n",
              "43         Bwd Packet Length Min  3.435788e-01\n",
              "44                 Bwd IAT Total  2.946982e-01\n",
              "45             Total Fwd Packets  2.719453e-01\n",
              "46         Fwd Packet Length Min  2.409901e-01\n",
              "47                   Bwd IAT Max  2.221156e-01\n",
              "48   Total Length of Fwd Packets  2.030491e-01\n",
              "49           Subflow Bwd Packets  1.979730e-01\n",
              "50                FIN Flag Count  1.492130e-01\n",
              "51                    Active Std  1.479791e-01\n",
              "52          Avg Bwd Segment Size  1.323907e-01\n",
              "53                      Idle Std  1.292494e-01\n",
              "54             Min Packet Length  1.000472e-01\n",
              "55   Total Length of Bwd Packets  9.913574e-02\n",
              "56        Packet Length Variance  8.443897e-02\n",
              "57           Subflow Fwd Packets  6.571276e-02\n",
              "58                 Fwd PSH Flags  6.412795e-02\n",
              "59        Total Backward Packets  6.212322e-02\n",
              "60                      Idle Min  4.902773e-02\n",
              "61                    Active Min  1.854661e-02\n",
              "62                   Active Mean  1.207187e-02\n",
              "63                    Active Max  1.014668e-02\n",
              "64           Fwd Header Length.1  1.892895e-03\n",
              "65                CWE Flag Count  7.959077e-06\n",
              "66                 Fwd URG Flags  9.084184e-07\n",
              "67                 Bwd PSH Flags  0.000000e+00\n",
              "68                RST Flag Count  0.000000e+00\n",
              "69                SYN Flag Count  0.000000e+00\n",
              "70          Bwd Avg Packets/Bulk  0.000000e+00\n",
              "71            Bwd Avg Bytes/Bulk  0.000000e+00\n",
              "72             Fwd Avg Bulk Rate  0.000000e+00\n",
              "73          Fwd Avg Packets/Bulk  0.000000e+00\n",
              "74            Fwd Avg Bytes/Bulk  0.000000e+00\n",
              "75                 Bwd URG Flags  0.000000e+00\n",
              "76                ECE Flag Count  0.000000e+00\n",
              "77             Bwd Avg Bulk Rate  0.000000e+00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-709ec054-3a64-47fe-ab40-e099987eaab0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Bwd Packet Length Mean</td>\n",
              "      <td>1.030737e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Bwd IAT Min</td>\n",
              "      <td>1.024658e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Subflow Bwd Bytes</td>\n",
              "      <td>8.341108e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>URG Flag Count</td>\n",
              "      <td>7.683885e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>ACK Flag Count</td>\n",
              "      <td>7.245434e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Bwd Packet Length Max</td>\n",
              "      <td>6.657735e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Fwd IAT Max</td>\n",
              "      <td>6.619831e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Fwd IAT Mean</td>\n",
              "      <td>6.048312e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Bwd IAT Mean</td>\n",
              "      <td>5.883093e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Bwd IAT Std</td>\n",
              "      <td>5.444477e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Idle Mean</td>\n",
              "      <td>4.927824e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Avg Fwd Segment Size</td>\n",
              "      <td>3.909295e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>act_data_pkt_fwd</td>\n",
              "      <td>3.817975e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Idle Max</td>\n",
              "      <td>3.769778e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Down/Up Ratio</td>\n",
              "      <td>3.492234e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Bwd Packet Length Min</td>\n",
              "      <td>3.435788e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Bwd IAT Total</td>\n",
              "      <td>2.946982e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Total Fwd Packets</td>\n",
              "      <td>2.719453e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Fwd Packet Length Min</td>\n",
              "      <td>2.409901e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Bwd IAT Max</td>\n",
              "      <td>2.221156e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Total Length of Fwd Packets</td>\n",
              "      <td>2.030491e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Subflow Bwd Packets</td>\n",
              "      <td>1.979730e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>FIN Flag Count</td>\n",
              "      <td>1.492130e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Active Std</td>\n",
              "      <td>1.479791e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Avg Bwd Segment Size</td>\n",
              "      <td>1.323907e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Idle Std</td>\n",
              "      <td>1.292494e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Min Packet Length</td>\n",
              "      <td>1.000472e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Total Length of Bwd Packets</td>\n",
              "      <td>9.913574e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Packet Length Variance</td>\n",
              "      <td>8.443897e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Subflow Fwd Packets</td>\n",
              "      <td>6.571276e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Fwd PSH Flags</td>\n",
              "      <td>6.412795e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Total Backward Packets</td>\n",
              "      <td>6.212322e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Idle Min</td>\n",
              "      <td>4.902773e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Active Min</td>\n",
              "      <td>1.854661e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Active Mean</td>\n",
              "      <td>1.207187e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Active Max</td>\n",
              "      <td>1.014668e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Fwd Header Length.1</td>\n",
              "      <td>1.892895e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>CWE Flag Count</td>\n",
              "      <td>7.959077e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Fwd URG Flags</td>\n",
              "      <td>9.084184e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>Bwd PSH Flags</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>RST Flag Count</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>SYN Flag Count</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>Bwd Avg Packets/Bulk</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Bwd Avg Bytes/Bulk</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Fwd Avg Bulk Rate</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Fwd Avg Packets/Bulk</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Fwd Avg Bytes/Bulk</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Bwd URG Flags</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>ECE Flag Count</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Bwd Avg Bulk Rate</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-709ec054-3a64-47fe-ab40-e099987eaab0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-709ec054-3a64-47fe-ab40-e099987eaab0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-709ec054-3a64-47fe-ab40-e099987eaab0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48fd0ffa-4d8d-48fd-8360-482824944a9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48fd0ffa-4d8d-48fd-8360-482824944a9c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48fd0ffa-4d8d-48fd-8360-482824944a9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "importances = model_bas_cb.feature_importances_  # train_features is the dataframe of training features\n",
        "feature_list = list(features_val.columns)  # Extract the feature importances into a dataframe\n",
        "feature_results = pd.DataFrame({'feature': feature_list,'importance': importances})  # Show the top 10 most important\n",
        "feature_results = feature_results.sort_values('importance',ascending = False).reset_index(drop=True)\n",
        "feature_results.tail(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–ø—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å —Å—Ç–æ–ª–±–µ—Ü, –∫–æ—Ç–æ—Ä—ã–π –≤ –∫–æ–Ω—Ü–µ —Å–ø–∏—Å–∫–∞"
      ],
      "metadata": {
        "id": "9pDA7G2VzEvw"
      },
      "id": "9pDA7G2VzEvw"
    },
    {
      "cell_type": "code",
      "source": [
        "features_train_1 = features_train.drop(' RST Flag Count', axis=1)\n",
        "features_val_1 = features_val.drop(' RST Flag Count', axis=1)\n",
        "\n",
        "model_bas_cb = CatBoostClassifier(cat_features=[30,31,32,33,43,44,45,46,47,48,49],\n",
        "                                  task_type=\"GPU\",\n",
        "                                  random_state=12345)\n",
        "\n",
        "model_bas_cb.fit(features_train_1, target_train)\n",
        "\n",
        "preds = model_bas_cb.predict(features_val_1)\n",
        "print (\"Accuracy:\",accuracy_score(target_val, preds))\n",
        "print (\"F1_macro:\", f1_score(target_val, preds, average='macro'))\n",
        "target_names = ['BENIGN', 'PortScan', 'DoS Hulk', 'DDoS', 'Bot', 'Infiltration', 'Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ XSS',\n",
        "                'Web Attack ÔøΩ Sql Injection', 'FTP-Patator', 'SSH-Patator','DoS slowloris', 'DoS Slowhttptest', 'DoS GoldenEye', 'Heartbleed']\n",
        "\n",
        "print(classification_report(target_val, preds, target_names=target_names))"
      ],
      "metadata": {
        "id": "_6kWvGq8zLaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddecf28d-1a9f-4a55-f99c-c1c4d5f478d8"
      },
      "id": "_6kWvGq8zLaa",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.208346\n",
            "0:\tlearn: 0.7103990\ttotal: 51.4ms\tremaining: 51.3s\n",
            "1:\tlearn: 0.5330124\ttotal: 107ms\tremaining: 53.4s\n",
            "2:\tlearn: 0.4251299\ttotal: 152ms\tremaining: 50.6s\n",
            "3:\tlearn: 0.3508356\ttotal: 198ms\tremaining: 49.2s\n",
            "4:\tlearn: 0.2924897\ttotal: 238ms\tremaining: 47.3s\n",
            "5:\tlearn: 0.2478458\ttotal: 277ms\tremaining: 45.9s\n",
            "6:\tlearn: 0.2095375\ttotal: 312ms\tremaining: 44.2s\n",
            "7:\tlearn: 0.1809451\ttotal: 342ms\tremaining: 42.4s\n",
            "8:\tlearn: 0.1571204\ttotal: 366ms\tremaining: 40.3s\n",
            "9:\tlearn: 0.1388515\ttotal: 390ms\tremaining: 38.6s\n",
            "10:\tlearn: 0.1221289\ttotal: 427ms\tremaining: 38.4s\n",
            "11:\tlearn: 0.1093289\ttotal: 466ms\tremaining: 38.4s\n",
            "12:\tlearn: 0.0976665\ttotal: 490ms\tremaining: 37.2s\n",
            "13:\tlearn: 0.0869762\ttotal: 515ms\tremaining: 36.3s\n",
            "14:\tlearn: 0.0789329\ttotal: 543ms\tremaining: 35.6s\n",
            "15:\tlearn: 0.0718294\ttotal: 566ms\tremaining: 34.8s\n",
            "16:\tlearn: 0.0662951\ttotal: 589ms\tremaining: 34.1s\n",
            "17:\tlearn: 0.0616462\ttotal: 623ms\tremaining: 34s\n",
            "18:\tlearn: 0.0551420\ttotal: 645ms\tremaining: 33.3s\n",
            "19:\tlearn: 0.0520590\ttotal: 669ms\tremaining: 32.8s\n",
            "20:\tlearn: 0.0486751\ttotal: 692ms\tremaining: 32.2s\n",
            "21:\tlearn: 0.0454262\ttotal: 715ms\tremaining: 31.8s\n",
            "22:\tlearn: 0.0434212\ttotal: 736ms\tremaining: 31.3s\n",
            "23:\tlearn: 0.0409714\ttotal: 760ms\tremaining: 30.9s\n",
            "24:\tlearn: 0.0392083\ttotal: 783ms\tremaining: 30.5s\n",
            "25:\tlearn: 0.0368327\ttotal: 812ms\tremaining: 30.4s\n",
            "26:\tlearn: 0.0350407\ttotal: 842ms\tremaining: 30.4s\n",
            "27:\tlearn: 0.0338135\ttotal: 866ms\tremaining: 30s\n",
            "28:\tlearn: 0.0328842\ttotal: 889ms\tremaining: 29.8s\n",
            "29:\tlearn: 0.0314293\ttotal: 913ms\tremaining: 29.5s\n",
            "30:\tlearn: 0.0307448\ttotal: 935ms\tremaining: 29.2s\n",
            "31:\tlearn: 0.0291268\ttotal: 958ms\tremaining: 29s\n",
            "32:\tlearn: 0.0281445\ttotal: 982ms\tremaining: 28.8s\n",
            "33:\tlearn: 0.0269580\ttotal: 1s\tremaining: 28.6s\n",
            "34:\tlearn: 0.0263456\ttotal: 1.03s\tremaining: 28.3s\n",
            "35:\tlearn: 0.0256997\ttotal: 1.05s\tremaining: 28.1s\n",
            "36:\tlearn: 0.0249438\ttotal: 1.08s\tremaining: 28.2s\n",
            "37:\tlearn: 0.0238749\ttotal: 1.11s\tremaining: 28.1s\n",
            "38:\tlearn: 0.0235438\ttotal: 1.13s\tremaining: 27.8s\n",
            "39:\tlearn: 0.0230185\ttotal: 1.15s\tremaining: 27.6s\n",
            "40:\tlearn: 0.0217829\ttotal: 1.18s\tremaining: 27.6s\n",
            "41:\tlearn: 0.0212358\ttotal: 1.2s\tremaining: 27.3s\n",
            "42:\tlearn: 0.0207581\ttotal: 1.22s\tremaining: 27.2s\n",
            "43:\tlearn: 0.0200771\ttotal: 1.25s\tremaining: 27.1s\n",
            "44:\tlearn: 0.0197118\ttotal: 1.27s\tremaining: 26.9s\n",
            "45:\tlearn: 0.0195207\ttotal: 1.29s\tremaining: 26.8s\n",
            "46:\tlearn: 0.0193281\ttotal: 1.31s\tremaining: 26.6s\n",
            "47:\tlearn: 0.0191870\ttotal: 1.33s\tremaining: 26.4s\n",
            "48:\tlearn: 0.0189412\ttotal: 1.35s\tremaining: 26.3s\n",
            "49:\tlearn: 0.0183781\ttotal: 1.38s\tremaining: 26.2s\n",
            "50:\tlearn: 0.0179996\ttotal: 1.4s\tremaining: 26.1s\n",
            "51:\tlearn: 0.0177990\ttotal: 1.42s\tremaining: 26s\n",
            "52:\tlearn: 0.0176617\ttotal: 1.45s\tremaining: 25.8s\n",
            "53:\tlearn: 0.0173436\ttotal: 1.47s\tremaining: 25.7s\n",
            "54:\tlearn: 0.0170443\ttotal: 1.5s\tremaining: 25.7s\n",
            "55:\tlearn: 0.0168907\ttotal: 1.52s\tremaining: 25.6s\n",
            "56:\tlearn: 0.0165565\ttotal: 1.54s\tremaining: 25.5s\n",
            "57:\tlearn: 0.0163294\ttotal: 1.56s\tremaining: 25.4s\n",
            "58:\tlearn: 0.0159468\ttotal: 1.59s\tremaining: 25.4s\n",
            "59:\tlearn: 0.0157861\ttotal: 1.62s\tremaining: 25.3s\n",
            "60:\tlearn: 0.0155913\ttotal: 1.64s\tremaining: 25.2s\n",
            "61:\tlearn: 0.0152573\ttotal: 1.66s\tremaining: 25.1s\n",
            "62:\tlearn: 0.0149500\ttotal: 1.68s\tremaining: 25.1s\n",
            "63:\tlearn: 0.0148691\ttotal: 1.71s\tremaining: 25s\n",
            "64:\tlearn: 0.0146668\ttotal: 1.73s\tremaining: 24.9s\n",
            "65:\tlearn: 0.0144223\ttotal: 1.76s\tremaining: 24.9s\n",
            "66:\tlearn: 0.0141346\ttotal: 1.78s\tremaining: 24.8s\n",
            "67:\tlearn: 0.0140124\ttotal: 1.8s\tremaining: 24.7s\n",
            "68:\tlearn: 0.0139534\ttotal: 1.84s\tremaining: 24.8s\n",
            "69:\tlearn: 0.0138156\ttotal: 1.86s\tremaining: 24.7s\n",
            "70:\tlearn: 0.0136606\ttotal: 1.88s\tremaining: 24.7s\n",
            "71:\tlearn: 0.0136068\ttotal: 1.91s\tremaining: 24.6s\n",
            "72:\tlearn: 0.0135484\ttotal: 1.93s\tremaining: 24.5s\n",
            "73:\tlearn: 0.0133662\ttotal: 1.95s\tremaining: 24.4s\n",
            "74:\tlearn: 0.0131968\ttotal: 1.97s\tremaining: 24.3s\n",
            "75:\tlearn: 0.0131116\ttotal: 1.99s\tremaining: 24.3s\n",
            "76:\tlearn: 0.0130367\ttotal: 2.02s\tremaining: 24.3s\n",
            "77:\tlearn: 0.0129824\ttotal: 2.04s\tremaining: 24.2s\n",
            "78:\tlearn: 0.0128561\ttotal: 2.07s\tremaining: 24.1s\n",
            "79:\tlearn: 0.0126912\ttotal: 2.09s\tremaining: 24s\n",
            "80:\tlearn: 0.0125309\ttotal: 2.11s\tremaining: 24s\n",
            "81:\tlearn: 0.0122924\ttotal: 2.14s\tremaining: 24s\n",
            "82:\tlearn: 0.0122596\ttotal: 2.16s\tremaining: 23.9s\n",
            "83:\tlearn: 0.0121545\ttotal: 2.19s\tremaining: 23.8s\n",
            "84:\tlearn: 0.0120429\ttotal: 2.21s\tremaining: 23.8s\n",
            "85:\tlearn: 0.0120173\ttotal: 2.23s\tremaining: 23.7s\n",
            "86:\tlearn: 0.0119755\ttotal: 2.25s\tremaining: 23.6s\n",
            "87:\tlearn: 0.0118895\ttotal: 2.27s\tremaining: 23.5s\n",
            "88:\tlearn: 0.0118436\ttotal: 2.29s\tremaining: 23.5s\n",
            "89:\tlearn: 0.0117617\ttotal: 2.31s\tremaining: 23.4s\n",
            "90:\tlearn: 0.0117548\ttotal: 2.33s\tremaining: 23.3s\n",
            "91:\tlearn: 0.0116494\ttotal: 2.36s\tremaining: 23.3s\n",
            "92:\tlearn: 0.0115574\ttotal: 2.39s\tremaining: 23.3s\n",
            "93:\tlearn: 0.0112252\ttotal: 2.41s\tremaining: 23.2s\n",
            "94:\tlearn: 0.0111648\ttotal: 2.43s\tremaining: 23.2s\n",
            "95:\tlearn: 0.0110529\ttotal: 2.46s\tremaining: 23.2s\n",
            "96:\tlearn: 0.0110096\ttotal: 2.49s\tremaining: 23.2s\n",
            "97:\tlearn: 0.0109959\ttotal: 2.51s\tremaining: 23.1s\n",
            "98:\tlearn: 0.0109747\ttotal: 2.53s\tremaining: 23s\n",
            "99:\tlearn: 0.0109161\ttotal: 2.55s\tremaining: 23s\n",
            "100:\tlearn: 0.0108574\ttotal: 2.58s\tremaining: 23s\n",
            "101:\tlearn: 0.0107976\ttotal: 2.6s\tremaining: 22.9s\n",
            "102:\tlearn: 0.0107347\ttotal: 2.62s\tremaining: 22.9s\n",
            "103:\tlearn: 0.0106871\ttotal: 2.65s\tremaining: 22.8s\n",
            "104:\tlearn: 0.0106400\ttotal: 2.67s\tremaining: 22.8s\n",
            "105:\tlearn: 0.0104864\ttotal: 2.69s\tremaining: 22.7s\n",
            "106:\tlearn: 0.0104260\ttotal: 2.72s\tremaining: 22.7s\n",
            "107:\tlearn: 0.0103471\ttotal: 2.74s\tremaining: 22.7s\n",
            "108:\tlearn: 0.0102777\ttotal: 2.77s\tremaining: 22.6s\n",
            "109:\tlearn: 0.0102056\ttotal: 2.8s\tremaining: 22.6s\n",
            "110:\tlearn: 0.0101630\ttotal: 2.83s\tremaining: 22.6s\n",
            "111:\tlearn: 0.0101135\ttotal: 2.85s\tremaining: 22.6s\n",
            "112:\tlearn: 0.0100684\ttotal: 2.88s\tremaining: 22.6s\n",
            "113:\tlearn: 0.0100041\ttotal: 2.9s\tremaining: 22.6s\n",
            "114:\tlearn: 0.0099708\ttotal: 2.92s\tremaining: 22.5s\n",
            "115:\tlearn: 0.0099449\ttotal: 2.94s\tremaining: 22.4s\n",
            "116:\tlearn: 0.0099023\ttotal: 2.97s\tremaining: 22.4s\n",
            "117:\tlearn: 0.0098634\ttotal: 3s\tremaining: 22.4s\n",
            "118:\tlearn: 0.0098380\ttotal: 3.02s\tremaining: 22.4s\n",
            "119:\tlearn: 0.0098230\ttotal: 3.04s\tremaining: 22.3s\n",
            "120:\tlearn: 0.0098155\ttotal: 3.06s\tremaining: 22.3s\n",
            "121:\tlearn: 0.0098050\ttotal: 3.08s\tremaining: 22.2s\n",
            "122:\tlearn: 0.0097686\ttotal: 3.11s\tremaining: 22.1s\n",
            "123:\tlearn: 0.0097344\ttotal: 3.13s\tremaining: 22.1s\n",
            "124:\tlearn: 0.0096996\ttotal: 3.15s\tremaining: 22.1s\n",
            "125:\tlearn: 0.0096263\ttotal: 3.19s\tremaining: 22.1s\n",
            "126:\tlearn: 0.0095996\ttotal: 3.21s\tremaining: 22.1s\n",
            "127:\tlearn: 0.0095859\ttotal: 3.23s\tremaining: 22s\n",
            "128:\tlearn: 0.0095659\ttotal: 3.25s\tremaining: 22s\n",
            "129:\tlearn: 0.0095320\ttotal: 3.28s\tremaining: 21.9s\n",
            "130:\tlearn: 0.0094441\ttotal: 3.3s\tremaining: 21.9s\n",
            "131:\tlearn: 0.0094203\ttotal: 3.32s\tremaining: 21.9s\n",
            "132:\tlearn: 0.0093760\ttotal: 3.35s\tremaining: 21.8s\n",
            "133:\tlearn: 0.0093160\ttotal: 3.37s\tremaining: 21.8s\n",
            "134:\tlearn: 0.0092897\ttotal: 3.39s\tremaining: 21.7s\n",
            "135:\tlearn: 0.0092595\ttotal: 3.42s\tremaining: 21.7s\n",
            "136:\tlearn: 0.0092483\ttotal: 3.44s\tremaining: 21.7s\n",
            "137:\tlearn: 0.0092173\ttotal: 3.46s\tremaining: 21.6s\n",
            "138:\tlearn: 0.0091656\ttotal: 3.49s\tremaining: 21.6s\n",
            "139:\tlearn: 0.0091322\ttotal: 3.51s\tremaining: 21.6s\n",
            "140:\tlearn: 0.0091172\ttotal: 3.53s\tremaining: 21.5s\n",
            "141:\tlearn: 0.0091079\ttotal: 3.55s\tremaining: 21.5s\n",
            "142:\tlearn: 0.0090557\ttotal: 3.57s\tremaining: 21.4s\n",
            "143:\tlearn: 0.0090158\ttotal: 3.6s\tremaining: 21.4s\n",
            "144:\tlearn: 0.0089798\ttotal: 3.62s\tremaining: 21.4s\n",
            "145:\tlearn: 0.0089639\ttotal: 3.64s\tremaining: 21.3s\n",
            "146:\tlearn: 0.0089524\ttotal: 3.67s\tremaining: 21.3s\n",
            "147:\tlearn: 0.0089383\ttotal: 3.69s\tremaining: 21.2s\n",
            "148:\tlearn: 0.0089253\ttotal: 3.71s\tremaining: 21.2s\n",
            "149:\tlearn: 0.0089069\ttotal: 3.73s\tremaining: 21.1s\n",
            "150:\tlearn: 0.0088980\ttotal: 3.75s\tremaining: 21.1s\n",
            "151:\tlearn: 0.0088594\ttotal: 3.78s\tremaining: 21.1s\n",
            "152:\tlearn: 0.0088346\ttotal: 3.82s\tremaining: 21.1s\n",
            "153:\tlearn: 0.0087984\ttotal: 3.86s\tremaining: 21.2s\n",
            "154:\tlearn: 0.0087138\ttotal: 3.88s\tremaining: 21.2s\n",
            "155:\tlearn: 0.0086907\ttotal: 3.9s\tremaining: 21.1s\n",
            "156:\tlearn: 0.0086751\ttotal: 3.93s\tremaining: 21.1s\n",
            "157:\tlearn: 0.0086330\ttotal: 3.95s\tremaining: 21.1s\n",
            "158:\tlearn: 0.0085965\ttotal: 3.97s\tremaining: 21s\n",
            "159:\tlearn: 0.0085791\ttotal: 3.99s\tremaining: 21s\n",
            "160:\tlearn: 0.0085429\ttotal: 4.02s\tremaining: 20.9s\n",
            "161:\tlearn: 0.0085149\ttotal: 4.04s\tremaining: 20.9s\n",
            "162:\tlearn: 0.0084715\ttotal: 4.07s\tremaining: 20.9s\n",
            "163:\tlearn: 0.0084505\ttotal: 4.09s\tremaining: 20.9s\n",
            "164:\tlearn: 0.0084376\ttotal: 4.12s\tremaining: 20.8s\n",
            "165:\tlearn: 0.0084300\ttotal: 4.14s\tremaining: 20.8s\n",
            "166:\tlearn: 0.0084159\ttotal: 4.16s\tremaining: 20.8s\n",
            "167:\tlearn: 0.0083822\ttotal: 4.18s\tremaining: 20.7s\n",
            "168:\tlearn: 0.0083658\ttotal: 4.21s\tremaining: 20.7s\n",
            "169:\tlearn: 0.0083544\ttotal: 4.23s\tremaining: 20.6s\n",
            "170:\tlearn: 0.0083393\ttotal: 4.25s\tremaining: 20.6s\n",
            "171:\tlearn: 0.0083238\ttotal: 4.27s\tremaining: 20.6s\n",
            "172:\tlearn: 0.0083105\ttotal: 4.3s\tremaining: 20.5s\n",
            "173:\tlearn: 0.0082885\ttotal: 4.32s\tremaining: 20.5s\n",
            "174:\tlearn: 0.0082790\ttotal: 4.34s\tremaining: 20.5s\n",
            "175:\tlearn: 0.0082707\ttotal: 4.36s\tremaining: 20.4s\n",
            "176:\tlearn: 0.0082587\ttotal: 4.38s\tremaining: 20.4s\n",
            "177:\tlearn: 0.0082274\ttotal: 4.41s\tremaining: 20.3s\n",
            "178:\tlearn: 0.0082086\ttotal: 4.43s\tremaining: 20.3s\n",
            "179:\tlearn: 0.0081863\ttotal: 4.45s\tremaining: 20.3s\n",
            "180:\tlearn: 0.0081590\ttotal: 4.48s\tremaining: 20.3s\n",
            "181:\tlearn: 0.0081358\ttotal: 4.5s\tremaining: 20.2s\n",
            "182:\tlearn: 0.0081224\ttotal: 4.52s\tremaining: 20.2s\n",
            "183:\tlearn: 0.0081060\ttotal: 4.55s\tremaining: 20.2s\n",
            "184:\tlearn: 0.0080853\ttotal: 4.57s\tremaining: 20.1s\n",
            "185:\tlearn: 0.0080634\ttotal: 4.59s\tremaining: 20.1s\n",
            "186:\tlearn: 0.0080531\ttotal: 4.61s\tremaining: 20.1s\n",
            "187:\tlearn: 0.0080401\ttotal: 4.63s\tremaining: 20s\n",
            "188:\tlearn: 0.0080230\ttotal: 4.66s\tremaining: 20s\n",
            "189:\tlearn: 0.0080151\ttotal: 4.68s\tremaining: 20s\n",
            "190:\tlearn: 0.0080029\ttotal: 4.71s\tremaining: 20s\n",
            "191:\tlearn: 0.0079915\ttotal: 4.74s\tremaining: 19.9s\n",
            "192:\tlearn: 0.0079556\ttotal: 4.76s\tremaining: 19.9s\n",
            "193:\tlearn: 0.0079485\ttotal: 4.78s\tremaining: 19.9s\n",
            "194:\tlearn: 0.0079382\ttotal: 4.8s\tremaining: 19.8s\n",
            "195:\tlearn: 0.0079245\ttotal: 4.83s\tremaining: 19.8s\n",
            "196:\tlearn: 0.0079103\ttotal: 4.86s\tremaining: 19.8s\n",
            "197:\tlearn: 0.0079013\ttotal: 4.88s\tremaining: 19.8s\n",
            "198:\tlearn: 0.0078822\ttotal: 4.91s\tremaining: 19.8s\n",
            "199:\tlearn: 0.0078735\ttotal: 4.93s\tremaining: 19.7s\n",
            "200:\tlearn: 0.0078545\ttotal: 4.96s\tremaining: 19.7s\n",
            "201:\tlearn: 0.0078292\ttotal: 4.98s\tremaining: 19.7s\n",
            "202:\tlearn: 0.0077955\ttotal: 5s\tremaining: 19.6s\n",
            "203:\tlearn: 0.0077910\ttotal: 5.02s\tremaining: 19.6s\n",
            "204:\tlearn: 0.0077795\ttotal: 5.04s\tremaining: 19.6s\n",
            "205:\tlearn: 0.0077317\ttotal: 5.07s\tremaining: 19.5s\n",
            "206:\tlearn: 0.0077198\ttotal: 5.1s\tremaining: 19.5s\n",
            "207:\tlearn: 0.0077040\ttotal: 5.12s\tremaining: 19.5s\n",
            "208:\tlearn: 0.0076979\ttotal: 5.14s\tremaining: 19.5s\n",
            "209:\tlearn: 0.0076549\ttotal: 5.18s\tremaining: 19.5s\n",
            "210:\tlearn: 0.0076442\ttotal: 5.2s\tremaining: 19.4s\n",
            "211:\tlearn: 0.0076339\ttotal: 5.22s\tremaining: 19.4s\n",
            "212:\tlearn: 0.0076265\ttotal: 5.24s\tremaining: 19.4s\n",
            "213:\tlearn: 0.0076201\ttotal: 5.27s\tremaining: 19.3s\n",
            "214:\tlearn: 0.0076139\ttotal: 5.29s\tremaining: 19.3s\n",
            "215:\tlearn: 0.0075859\ttotal: 5.31s\tremaining: 19.3s\n",
            "216:\tlearn: 0.0075762\ttotal: 5.34s\tremaining: 19.3s\n",
            "217:\tlearn: 0.0075590\ttotal: 5.36s\tremaining: 19.2s\n",
            "218:\tlearn: 0.0075465\ttotal: 5.38s\tremaining: 19.2s\n",
            "219:\tlearn: 0.0074985\ttotal: 5.4s\tremaining: 19.2s\n",
            "220:\tlearn: 0.0074918\ttotal: 5.42s\tremaining: 19.1s\n",
            "221:\tlearn: 0.0074828\ttotal: 5.45s\tremaining: 19.1s\n",
            "222:\tlearn: 0.0074776\ttotal: 5.47s\tremaining: 19.1s\n",
            "223:\tlearn: 0.0074533\ttotal: 5.49s\tremaining: 19s\n",
            "224:\tlearn: 0.0074458\ttotal: 5.52s\tremaining: 19s\n",
            "225:\tlearn: 0.0074391\ttotal: 5.54s\tremaining: 19s\n",
            "226:\tlearn: 0.0074337\ttotal: 5.56s\tremaining: 18.9s\n",
            "227:\tlearn: 0.0074277\ttotal: 5.58s\tremaining: 18.9s\n",
            "228:\tlearn: 0.0074025\ttotal: 5.61s\tremaining: 18.9s\n",
            "229:\tlearn: 0.0073958\ttotal: 5.63s\tremaining: 18.9s\n",
            "230:\tlearn: 0.0073896\ttotal: 5.65s\tremaining: 18.8s\n",
            "231:\tlearn: 0.0073768\ttotal: 5.68s\tremaining: 18.8s\n",
            "232:\tlearn: 0.0073450\ttotal: 5.7s\tremaining: 18.8s\n",
            "233:\tlearn: 0.0073386\ttotal: 5.73s\tremaining: 18.8s\n",
            "234:\tlearn: 0.0073302\ttotal: 5.75s\tremaining: 18.7s\n",
            "235:\tlearn: 0.0073247\ttotal: 5.77s\tremaining: 18.7s\n",
            "236:\tlearn: 0.0073192\ttotal: 5.79s\tremaining: 18.7s\n",
            "237:\tlearn: 0.0073132\ttotal: 5.82s\tremaining: 18.6s\n",
            "238:\tlearn: 0.0073054\ttotal: 5.85s\tremaining: 18.6s\n",
            "239:\tlearn: 0.0072969\ttotal: 5.88s\tremaining: 18.6s\n",
            "240:\tlearn: 0.0072823\ttotal: 5.9s\tremaining: 18.6s\n",
            "241:\tlearn: 0.0072651\ttotal: 5.92s\tremaining: 18.5s\n",
            "242:\tlearn: 0.0072542\ttotal: 5.95s\tremaining: 18.5s\n",
            "243:\tlearn: 0.0072414\ttotal: 5.97s\tremaining: 18.5s\n",
            "244:\tlearn: 0.0072279\ttotal: 5.99s\tremaining: 18.5s\n",
            "245:\tlearn: 0.0072224\ttotal: 6.02s\tremaining: 18.4s\n",
            "246:\tlearn: 0.0072133\ttotal: 6.04s\tremaining: 18.4s\n",
            "247:\tlearn: 0.0072063\ttotal: 6.06s\tremaining: 18.4s\n",
            "248:\tlearn: 0.0071988\ttotal: 6.09s\tremaining: 18.4s\n",
            "249:\tlearn: 0.0071879\ttotal: 6.11s\tremaining: 18.3s\n",
            "250:\tlearn: 0.0071813\ttotal: 6.13s\tremaining: 18.3s\n",
            "251:\tlearn: 0.0071685\ttotal: 6.16s\tremaining: 18.3s\n",
            "252:\tlearn: 0.0071581\ttotal: 6.18s\tremaining: 18.2s\n",
            "253:\tlearn: 0.0071355\ttotal: 6.2s\tremaining: 18.2s\n",
            "254:\tlearn: 0.0071329\ttotal: 6.23s\tremaining: 18.2s\n",
            "255:\tlearn: 0.0071248\ttotal: 6.25s\tremaining: 18.2s\n",
            "256:\tlearn: 0.0071198\ttotal: 6.27s\tremaining: 18.1s\n",
            "257:\tlearn: 0.0071133\ttotal: 6.29s\tremaining: 18.1s\n",
            "258:\tlearn: 0.0070817\ttotal: 6.32s\tremaining: 18.1s\n",
            "259:\tlearn: 0.0070679\ttotal: 6.34s\tremaining: 18.1s\n",
            "260:\tlearn: 0.0070617\ttotal: 6.37s\tremaining: 18s\n",
            "261:\tlearn: 0.0070554\ttotal: 6.39s\tremaining: 18s\n",
            "262:\tlearn: 0.0070492\ttotal: 6.41s\tremaining: 18s\n",
            "263:\tlearn: 0.0070450\ttotal: 6.43s\tremaining: 17.9s\n",
            "264:\tlearn: 0.0070354\ttotal: 6.47s\tremaining: 17.9s\n",
            "265:\tlearn: 0.0070278\ttotal: 6.49s\tremaining: 17.9s\n",
            "266:\tlearn: 0.0070232\ttotal: 6.51s\tremaining: 17.9s\n",
            "267:\tlearn: 0.0069924\ttotal: 6.54s\tremaining: 17.9s\n",
            "268:\tlearn: 0.0069852\ttotal: 6.56s\tremaining: 17.8s\n",
            "269:\tlearn: 0.0069750\ttotal: 6.59s\tremaining: 17.8s\n",
            "270:\tlearn: 0.0069676\ttotal: 6.61s\tremaining: 17.8s\n",
            "271:\tlearn: 0.0069657\ttotal: 6.63s\tremaining: 17.7s\n",
            "272:\tlearn: 0.0069505\ttotal: 6.65s\tremaining: 17.7s\n",
            "273:\tlearn: 0.0069418\ttotal: 6.67s\tremaining: 17.7s\n",
            "274:\tlearn: 0.0069334\ttotal: 6.7s\tremaining: 17.7s\n",
            "275:\tlearn: 0.0069288\ttotal: 6.72s\tremaining: 17.6s\n",
            "276:\tlearn: 0.0069238\ttotal: 6.74s\tremaining: 17.6s\n",
            "277:\tlearn: 0.0069201\ttotal: 6.77s\tremaining: 17.6s\n",
            "278:\tlearn: 0.0069152\ttotal: 6.79s\tremaining: 17.5s\n",
            "279:\tlearn: 0.0069097\ttotal: 6.81s\tremaining: 17.5s\n",
            "280:\tlearn: 0.0068901\ttotal: 6.85s\tremaining: 17.5s\n",
            "281:\tlearn: 0.0068762\ttotal: 6.87s\tremaining: 17.5s\n",
            "282:\tlearn: 0.0068733\ttotal: 6.89s\tremaining: 17.5s\n",
            "283:\tlearn: 0.0068655\ttotal: 6.92s\tremaining: 17.4s\n",
            "284:\tlearn: 0.0068560\ttotal: 6.94s\tremaining: 17.4s\n",
            "285:\tlearn: 0.0068383\ttotal: 6.98s\tremaining: 17.4s\n",
            "286:\tlearn: 0.0068266\ttotal: 7s\tremaining: 17.4s\n",
            "287:\tlearn: 0.0068208\ttotal: 7.02s\tremaining: 17.4s\n",
            "288:\tlearn: 0.0068042\ttotal: 7.05s\tremaining: 17.3s\n",
            "289:\tlearn: 0.0067896\ttotal: 7.07s\tremaining: 17.3s\n",
            "290:\tlearn: 0.0067829\ttotal: 7.1s\tremaining: 17.3s\n",
            "291:\tlearn: 0.0067770\ttotal: 7.12s\tremaining: 17.3s\n",
            "292:\tlearn: 0.0067587\ttotal: 7.14s\tremaining: 17.2s\n",
            "293:\tlearn: 0.0067398\ttotal: 7.17s\tremaining: 17.2s\n",
            "294:\tlearn: 0.0067257\ttotal: 7.2s\tremaining: 17.2s\n",
            "295:\tlearn: 0.0067189\ttotal: 7.22s\tremaining: 17.2s\n",
            "296:\tlearn: 0.0067124\ttotal: 7.24s\tremaining: 17.1s\n",
            "297:\tlearn: 0.0067094\ttotal: 7.26s\tremaining: 17.1s\n",
            "298:\tlearn: 0.0067023\ttotal: 7.28s\tremaining: 17.1s\n",
            "299:\tlearn: 0.0066963\ttotal: 7.3s\tremaining: 17s\n",
            "300:\tlearn: 0.0066923\ttotal: 7.33s\tremaining: 17s\n",
            "301:\tlearn: 0.0066795\ttotal: 7.35s\tremaining: 17s\n",
            "302:\tlearn: 0.0066711\ttotal: 7.38s\tremaining: 17s\n",
            "303:\tlearn: 0.0066593\ttotal: 7.42s\tremaining: 17s\n",
            "304:\tlearn: 0.0066559\ttotal: 7.45s\tremaining: 17s\n",
            "305:\tlearn: 0.0066467\ttotal: 7.48s\tremaining: 17s\n",
            "306:\tlearn: 0.0066403\ttotal: 7.5s\tremaining: 16.9s\n",
            "307:\tlearn: 0.0066292\ttotal: 7.54s\tremaining: 16.9s\n",
            "308:\tlearn: 0.0066259\ttotal: 7.58s\tremaining: 17s\n",
            "309:\tlearn: 0.0066093\ttotal: 7.64s\tremaining: 17s\n",
            "310:\tlearn: 0.0066025\ttotal: 7.72s\tremaining: 17.1s\n",
            "311:\tlearn: 0.0065953\ttotal: 7.8s\tremaining: 17.2s\n",
            "312:\tlearn: 0.0065912\ttotal: 7.88s\tremaining: 17.3s\n",
            "313:\tlearn: 0.0065795\ttotal: 7.96s\tremaining: 17.4s\n",
            "314:\tlearn: 0.0065580\ttotal: 8.04s\tremaining: 17.5s\n",
            "315:\tlearn: 0.0065527\ttotal: 8.11s\tremaining: 17.6s\n",
            "316:\tlearn: 0.0065464\ttotal: 8.19s\tremaining: 17.6s\n",
            "317:\tlearn: 0.0065381\ttotal: 8.26s\tremaining: 17.7s\n",
            "318:\tlearn: 0.0065369\ttotal: 8.33s\tremaining: 17.8s\n",
            "319:\tlearn: 0.0065345\ttotal: 8.41s\tremaining: 17.9s\n",
            "320:\tlearn: 0.0065277\ttotal: 8.48s\tremaining: 17.9s\n",
            "321:\tlearn: 0.0065205\ttotal: 8.56s\tremaining: 18s\n",
            "322:\tlearn: 0.0065105\ttotal: 8.63s\tremaining: 18.1s\n",
            "323:\tlearn: 0.0065013\ttotal: 8.71s\tremaining: 18.2s\n",
            "324:\tlearn: 0.0064899\ttotal: 8.79s\tremaining: 18.3s\n",
            "325:\tlearn: 0.0064871\ttotal: 8.86s\tremaining: 18.3s\n",
            "326:\tlearn: 0.0064698\ttotal: 8.93s\tremaining: 18.4s\n",
            "327:\tlearn: 0.0064638\ttotal: 8.99s\tremaining: 18.4s\n",
            "328:\tlearn: 0.0064605\ttotal: 9.03s\tremaining: 18.4s\n",
            "329:\tlearn: 0.0064568\ttotal: 9.07s\tremaining: 18.4s\n",
            "330:\tlearn: 0.0064460\ttotal: 9.14s\tremaining: 18.5s\n",
            "331:\tlearn: 0.0064336\ttotal: 9.19s\tremaining: 18.5s\n",
            "332:\tlearn: 0.0064309\ttotal: 9.26s\tremaining: 18.5s\n",
            "333:\tlearn: 0.0064224\ttotal: 9.34s\tremaining: 18.6s\n",
            "334:\tlearn: 0.0064127\ttotal: 9.42s\tremaining: 18.7s\n",
            "335:\tlearn: 0.0064006\ttotal: 9.5s\tremaining: 18.8s\n",
            "336:\tlearn: 0.0063946\ttotal: 9.58s\tremaining: 18.9s\n",
            "337:\tlearn: 0.0063902\ttotal: 9.66s\tremaining: 18.9s\n",
            "338:\tlearn: 0.0063852\ttotal: 9.74s\tremaining: 19s\n",
            "339:\tlearn: 0.0063797\ttotal: 9.82s\tremaining: 19.1s\n",
            "340:\tlearn: 0.0063730\ttotal: 9.9s\tremaining: 19.1s\n",
            "341:\tlearn: 0.0063666\ttotal: 9.98s\tremaining: 19.2s\n",
            "342:\tlearn: 0.0063438\ttotal: 10.1s\tremaining: 19.3s\n",
            "343:\tlearn: 0.0063372\ttotal: 10.1s\tremaining: 19.3s\n",
            "344:\tlearn: 0.0063299\ttotal: 10.2s\tremaining: 19.4s\n",
            "345:\tlearn: 0.0063191\ttotal: 10.3s\tremaining: 19.5s\n",
            "346:\tlearn: 0.0063061\ttotal: 10.4s\tremaining: 19.5s\n",
            "347:\tlearn: 0.0063040\ttotal: 10.5s\tremaining: 19.6s\n",
            "348:\tlearn: 0.0062983\ttotal: 10.5s\tremaining: 19.7s\n",
            "349:\tlearn: 0.0062940\ttotal: 10.6s\tremaining: 19.7s\n",
            "350:\tlearn: 0.0062866\ttotal: 10.7s\tremaining: 19.8s\n",
            "351:\tlearn: 0.0062817\ttotal: 10.8s\tremaining: 19.9s\n",
            "352:\tlearn: 0.0062757\ttotal: 10.9s\tremaining: 19.9s\n",
            "353:\tlearn: 0.0062726\ttotal: 10.9s\tremaining: 20s\n",
            "354:\tlearn: 0.0062673\ttotal: 11s\tremaining: 20s\n",
            "355:\tlearn: 0.0062578\ttotal: 11.1s\tremaining: 20.1s\n",
            "356:\tlearn: 0.0062456\ttotal: 11.2s\tremaining: 20.2s\n",
            "357:\tlearn: 0.0062422\ttotal: 11.3s\tremaining: 20.2s\n",
            "358:\tlearn: 0.0062374\ttotal: 11.4s\tremaining: 20.3s\n",
            "359:\tlearn: 0.0062354\ttotal: 11.5s\tremaining: 20.4s\n",
            "360:\tlearn: 0.0062331\ttotal: 11.5s\tremaining: 20.4s\n",
            "361:\tlearn: 0.0062269\ttotal: 11.6s\tremaining: 20.5s\n",
            "362:\tlearn: 0.0062253\ttotal: 11.7s\tremaining: 20.5s\n",
            "363:\tlearn: 0.0062231\ttotal: 11.8s\tremaining: 20.6s\n",
            "364:\tlearn: 0.0062209\ttotal: 11.9s\tremaining: 20.7s\n",
            "365:\tlearn: 0.0062160\ttotal: 12s\tremaining: 20.7s\n",
            "366:\tlearn: 0.0062106\ttotal: 12s\tremaining: 20.8s\n",
            "367:\tlearn: 0.0062079\ttotal: 12.1s\tremaining: 20.8s\n",
            "368:\tlearn: 0.0062047\ttotal: 12.1s\tremaining: 20.7s\n",
            "369:\tlearn: 0.0062019\ttotal: 12.1s\tremaining: 20.7s\n",
            "370:\tlearn: 0.0061954\ttotal: 12.2s\tremaining: 20.6s\n",
            "371:\tlearn: 0.0061868\ttotal: 12.2s\tremaining: 20.6s\n",
            "372:\tlearn: 0.0061786\ttotal: 12.2s\tremaining: 20.6s\n",
            "373:\tlearn: 0.0061743\ttotal: 12.3s\tremaining: 20.5s\n",
            "374:\tlearn: 0.0061707\ttotal: 12.3s\tremaining: 20.5s\n",
            "375:\tlearn: 0.0061629\ttotal: 12.3s\tremaining: 20.4s\n",
            "376:\tlearn: 0.0061598\ttotal: 12.3s\tremaining: 20.4s\n",
            "377:\tlearn: 0.0061445\ttotal: 12.4s\tremaining: 20.3s\n",
            "378:\tlearn: 0.0061422\ttotal: 12.4s\tremaining: 20.3s\n",
            "379:\tlearn: 0.0061387\ttotal: 12.4s\tremaining: 20.3s\n",
            "380:\tlearn: 0.0061349\ttotal: 12.4s\tremaining: 20.2s\n",
            "381:\tlearn: 0.0061289\ttotal: 12.5s\tremaining: 20.2s\n",
            "382:\tlearn: 0.0061263\ttotal: 12.5s\tremaining: 20.1s\n",
            "383:\tlearn: 0.0061194\ttotal: 12.5s\tremaining: 20.1s\n",
            "384:\tlearn: 0.0061146\ttotal: 12.5s\tremaining: 20s\n",
            "385:\tlearn: 0.0061124\ttotal: 12.6s\tremaining: 20s\n",
            "386:\tlearn: 0.0061034\ttotal: 12.6s\tremaining: 19.9s\n",
            "387:\tlearn: 0.0061007\ttotal: 12.6s\tremaining: 19.9s\n",
            "388:\tlearn: 0.0060970\ttotal: 12.6s\tremaining: 19.8s\n",
            "389:\tlearn: 0.0060935\ttotal: 12.6s\tremaining: 19.8s\n",
            "390:\tlearn: 0.0060916\ttotal: 12.7s\tremaining: 19.7s\n",
            "391:\tlearn: 0.0060893\ttotal: 12.7s\tremaining: 19.7s\n",
            "392:\tlearn: 0.0060874\ttotal: 12.7s\tremaining: 19.6s\n",
            "393:\tlearn: 0.0060859\ttotal: 12.7s\tremaining: 19.6s\n",
            "394:\tlearn: 0.0060818\ttotal: 12.8s\tremaining: 19.5s\n",
            "395:\tlearn: 0.0060752\ttotal: 12.8s\tremaining: 19.5s\n",
            "396:\tlearn: 0.0060620\ttotal: 12.8s\tremaining: 19.5s\n",
            "397:\tlearn: 0.0060603\ttotal: 12.8s\tremaining: 19.4s\n",
            "398:\tlearn: 0.0060575\ttotal: 12.9s\tremaining: 19.4s\n",
            "399:\tlearn: 0.0060544\ttotal: 12.9s\tremaining: 19.3s\n",
            "400:\tlearn: 0.0060511\ttotal: 12.9s\tremaining: 19.3s\n",
            "401:\tlearn: 0.0060448\ttotal: 12.9s\tremaining: 19.2s\n",
            "402:\tlearn: 0.0060426\ttotal: 13s\tremaining: 19.2s\n",
            "403:\tlearn: 0.0060409\ttotal: 13s\tremaining: 19.2s\n",
            "404:\tlearn: 0.0060362\ttotal: 13s\tremaining: 19.1s\n",
            "405:\tlearn: 0.0060338\ttotal: 13s\tremaining: 19.1s\n",
            "406:\tlearn: 0.0060292\ttotal: 13.1s\tremaining: 19s\n",
            "407:\tlearn: 0.0060241\ttotal: 13.1s\tremaining: 19s\n",
            "408:\tlearn: 0.0060195\ttotal: 13.1s\tremaining: 18.9s\n",
            "409:\tlearn: 0.0060176\ttotal: 13.1s\tremaining: 18.9s\n",
            "410:\tlearn: 0.0060143\ttotal: 13.2s\tremaining: 18.9s\n",
            "411:\tlearn: 0.0060104\ttotal: 13.2s\tremaining: 18.8s\n",
            "412:\tlearn: 0.0060092\ttotal: 13.2s\tremaining: 18.8s\n",
            "413:\tlearn: 0.0060073\ttotal: 13.2s\tremaining: 18.7s\n",
            "414:\tlearn: 0.0060033\ttotal: 13.2s\tremaining: 18.7s\n",
            "415:\tlearn: 0.0060019\ttotal: 13.3s\tremaining: 18.6s\n",
            "416:\tlearn: 0.0060005\ttotal: 13.3s\tremaining: 18.6s\n",
            "417:\tlearn: 0.0059970\ttotal: 13.3s\tremaining: 18.6s\n",
            "418:\tlearn: 0.0059945\ttotal: 13.3s\tremaining: 18.5s\n",
            "419:\tlearn: 0.0059927\ttotal: 13.4s\tremaining: 18.5s\n",
            "420:\tlearn: 0.0059905\ttotal: 13.4s\tremaining: 18.4s\n",
            "421:\tlearn: 0.0059824\ttotal: 13.4s\tremaining: 18.4s\n",
            "422:\tlearn: 0.0059790\ttotal: 13.4s\tremaining: 18.3s\n",
            "423:\tlearn: 0.0059758\ttotal: 13.5s\tremaining: 18.3s\n",
            "424:\tlearn: 0.0059739\ttotal: 13.5s\tremaining: 18.2s\n",
            "425:\tlearn: 0.0059726\ttotal: 13.5s\tremaining: 18.2s\n",
            "426:\tlearn: 0.0059720\ttotal: 13.5s\tremaining: 18.2s\n",
            "427:\tlearn: 0.0059706\ttotal: 13.6s\tremaining: 18.1s\n",
            "428:\tlearn: 0.0059655\ttotal: 13.6s\tremaining: 18.1s\n",
            "429:\tlearn: 0.0059626\ttotal: 13.6s\tremaining: 18s\n",
            "430:\tlearn: 0.0059537\ttotal: 13.6s\tremaining: 18s\n",
            "431:\tlearn: 0.0059513\ttotal: 13.6s\tremaining: 17.9s\n",
            "432:\tlearn: 0.0059499\ttotal: 13.7s\tremaining: 17.9s\n",
            "433:\tlearn: 0.0059478\ttotal: 13.7s\tremaining: 17.9s\n",
            "434:\tlearn: 0.0059451\ttotal: 13.7s\tremaining: 17.8s\n",
            "435:\tlearn: 0.0059429\ttotal: 13.7s\tremaining: 17.8s\n",
            "436:\tlearn: 0.0059394\ttotal: 13.8s\tremaining: 17.7s\n",
            "437:\tlearn: 0.0059363\ttotal: 13.8s\tremaining: 17.7s\n",
            "438:\tlearn: 0.0059291\ttotal: 13.8s\tremaining: 17.6s\n",
            "439:\tlearn: 0.0059254\ttotal: 13.8s\tremaining: 17.6s\n",
            "440:\tlearn: 0.0059227\ttotal: 13.9s\tremaining: 17.6s\n",
            "441:\tlearn: 0.0059185\ttotal: 13.9s\tremaining: 17.5s\n",
            "442:\tlearn: 0.0059164\ttotal: 13.9s\tremaining: 17.5s\n",
            "443:\tlearn: 0.0059135\ttotal: 13.9s\tremaining: 17.4s\n",
            "444:\tlearn: 0.0059114\ttotal: 14s\tremaining: 17.4s\n",
            "445:\tlearn: 0.0059092\ttotal: 14s\tremaining: 17.4s\n",
            "446:\tlearn: 0.0059068\ttotal: 14s\tremaining: 17.3s\n",
            "447:\tlearn: 0.0059036\ttotal: 14s\tremaining: 17.3s\n",
            "448:\tlearn: 0.0058998\ttotal: 14.1s\tremaining: 17.2s\n",
            "449:\tlearn: 0.0058966\ttotal: 14.1s\tremaining: 17.2s\n",
            "450:\tlearn: 0.0058916\ttotal: 14.1s\tremaining: 17.2s\n",
            "451:\tlearn: 0.0058860\ttotal: 14.1s\tremaining: 17.1s\n",
            "452:\tlearn: 0.0058835\ttotal: 14.2s\tremaining: 17.1s\n",
            "453:\tlearn: 0.0058809\ttotal: 14.2s\tremaining: 17s\n",
            "454:\tlearn: 0.0058791\ttotal: 14.2s\tremaining: 17s\n",
            "455:\tlearn: 0.0058740\ttotal: 14.2s\tremaining: 17s\n",
            "456:\tlearn: 0.0058727\ttotal: 14.2s\tremaining: 16.9s\n",
            "457:\tlearn: 0.0058691\ttotal: 14.3s\tremaining: 16.9s\n",
            "458:\tlearn: 0.0058678\ttotal: 14.3s\tremaining: 16.8s\n",
            "459:\tlearn: 0.0058651\ttotal: 14.3s\tremaining: 16.8s\n",
            "460:\tlearn: 0.0058627\ttotal: 14.3s\tremaining: 16.8s\n",
            "461:\tlearn: 0.0058537\ttotal: 14.4s\tremaining: 16.7s\n",
            "462:\tlearn: 0.0058525\ttotal: 14.4s\tremaining: 16.7s\n",
            "463:\tlearn: 0.0058409\ttotal: 14.4s\tremaining: 16.6s\n",
            "464:\tlearn: 0.0058385\ttotal: 14.4s\tremaining: 16.6s\n",
            "465:\tlearn: 0.0058314\ttotal: 14.5s\tremaining: 16.6s\n",
            "466:\tlearn: 0.0058303\ttotal: 14.5s\tremaining: 16.5s\n",
            "467:\tlearn: 0.0058222\ttotal: 14.5s\tremaining: 16.5s\n",
            "468:\tlearn: 0.0058197\ttotal: 14.5s\tremaining: 16.5s\n",
            "469:\tlearn: 0.0058160\ttotal: 14.6s\tremaining: 16.4s\n",
            "470:\tlearn: 0.0058077\ttotal: 14.6s\tremaining: 16.4s\n",
            "471:\tlearn: 0.0058017\ttotal: 14.6s\tremaining: 16.3s\n",
            "472:\tlearn: 0.0057968\ttotal: 14.6s\tremaining: 16.3s\n",
            "473:\tlearn: 0.0057916\ttotal: 14.7s\tremaining: 16.3s\n",
            "474:\tlearn: 0.0057908\ttotal: 14.7s\tremaining: 16.2s\n",
            "475:\tlearn: 0.0057881\ttotal: 14.7s\tremaining: 16.2s\n",
            "476:\tlearn: 0.0057845\ttotal: 14.7s\tremaining: 16.1s\n",
            "477:\tlearn: 0.0057819\ttotal: 14.8s\tremaining: 16.1s\n",
            "478:\tlearn: 0.0057789\ttotal: 14.8s\tremaining: 16.1s\n",
            "479:\tlearn: 0.0057774\ttotal: 14.8s\tremaining: 16s\n",
            "480:\tlearn: 0.0057656\ttotal: 14.8s\tremaining: 16s\n",
            "481:\tlearn: 0.0057629\ttotal: 14.8s\tremaining: 16s\n",
            "482:\tlearn: 0.0057605\ttotal: 14.9s\tremaining: 15.9s\n",
            "483:\tlearn: 0.0057586\ttotal: 14.9s\tremaining: 15.9s\n",
            "484:\tlearn: 0.0057546\ttotal: 14.9s\tremaining: 15.8s\n",
            "485:\tlearn: 0.0057534\ttotal: 14.9s\tremaining: 15.8s\n",
            "486:\tlearn: 0.0057520\ttotal: 15s\tremaining: 15.8s\n",
            "487:\tlearn: 0.0057510\ttotal: 15s\tremaining: 15.7s\n",
            "488:\tlearn: 0.0057414\ttotal: 15s\tremaining: 15.7s\n",
            "489:\tlearn: 0.0057401\ttotal: 15s\tremaining: 15.6s\n",
            "490:\tlearn: 0.0057346\ttotal: 15.1s\tremaining: 15.6s\n",
            "491:\tlearn: 0.0057292\ttotal: 15.1s\tremaining: 15.6s\n",
            "492:\tlearn: 0.0057245\ttotal: 15.1s\tremaining: 15.5s\n",
            "493:\tlearn: 0.0057231\ttotal: 15.1s\tremaining: 15.5s\n",
            "494:\tlearn: 0.0057205\ttotal: 15.2s\tremaining: 15.5s\n",
            "495:\tlearn: 0.0057180\ttotal: 15.2s\tremaining: 15.4s\n",
            "496:\tlearn: 0.0057034\ttotal: 15.2s\tremaining: 15.4s\n",
            "497:\tlearn: 0.0057013\ttotal: 15.2s\tremaining: 15.3s\n",
            "498:\tlearn: 0.0057005\ttotal: 15.2s\tremaining: 15.3s\n",
            "499:\tlearn: 0.0056916\ttotal: 15.3s\tremaining: 15.3s\n",
            "500:\tlearn: 0.0056893\ttotal: 15.3s\tremaining: 15.2s\n",
            "501:\tlearn: 0.0056862\ttotal: 15.3s\tremaining: 15.2s\n",
            "502:\tlearn: 0.0056846\ttotal: 15.3s\tremaining: 15.2s\n",
            "503:\tlearn: 0.0056825\ttotal: 15.4s\tremaining: 15.1s\n",
            "504:\tlearn: 0.0056808\ttotal: 15.4s\tremaining: 15.1s\n",
            "505:\tlearn: 0.0056755\ttotal: 15.4s\tremaining: 15.1s\n",
            "506:\tlearn: 0.0056719\ttotal: 15.5s\tremaining: 15s\n",
            "507:\tlearn: 0.0056702\ttotal: 15.5s\tremaining: 15s\n",
            "508:\tlearn: 0.0056694\ttotal: 15.5s\tremaining: 14.9s\n",
            "509:\tlearn: 0.0056679\ttotal: 15.5s\tremaining: 14.9s\n",
            "510:\tlearn: 0.0056656\ttotal: 15.5s\tremaining: 14.9s\n",
            "511:\tlearn: 0.0056610\ttotal: 15.6s\tremaining: 14.8s\n",
            "512:\tlearn: 0.0056598\ttotal: 15.6s\tremaining: 14.8s\n",
            "513:\tlearn: 0.0056580\ttotal: 15.6s\tremaining: 14.8s\n",
            "514:\tlearn: 0.0056568\ttotal: 15.6s\tremaining: 14.7s\n",
            "515:\tlearn: 0.0056557\ttotal: 15.7s\tremaining: 14.7s\n",
            "516:\tlearn: 0.0056542\ttotal: 15.7s\tremaining: 14.7s\n",
            "517:\tlearn: 0.0056521\ttotal: 15.7s\tremaining: 14.6s\n",
            "518:\tlearn: 0.0056514\ttotal: 15.7s\tremaining: 14.6s\n",
            "519:\tlearn: 0.0056493\ttotal: 15.8s\tremaining: 14.5s\n",
            "520:\tlearn: 0.0056399\ttotal: 15.8s\tremaining: 14.5s\n",
            "521:\tlearn: 0.0056361\ttotal: 15.8s\tremaining: 14.5s\n",
            "522:\tlearn: 0.0056342\ttotal: 15.8s\tremaining: 14.4s\n",
            "523:\tlearn: 0.0056330\ttotal: 15.9s\tremaining: 14.4s\n",
            "524:\tlearn: 0.0056313\ttotal: 15.9s\tremaining: 14.4s\n",
            "525:\tlearn: 0.0056297\ttotal: 15.9s\tremaining: 14.3s\n",
            "526:\tlearn: 0.0056272\ttotal: 15.9s\tremaining: 14.3s\n",
            "527:\tlearn: 0.0056239\ttotal: 15.9s\tremaining: 14.3s\n",
            "528:\tlearn: 0.0056209\ttotal: 16s\tremaining: 14.2s\n",
            "529:\tlearn: 0.0056113\ttotal: 16s\tremaining: 14.2s\n",
            "530:\tlearn: 0.0056088\ttotal: 16s\tremaining: 14.1s\n",
            "531:\tlearn: 0.0056050\ttotal: 16s\tremaining: 14.1s\n",
            "532:\tlearn: 0.0056018\ttotal: 16.1s\tremaining: 14.1s\n",
            "533:\tlearn: 0.0055996\ttotal: 16.1s\tremaining: 14s\n",
            "534:\tlearn: 0.0055985\ttotal: 16.1s\tremaining: 14s\n",
            "535:\tlearn: 0.0055959\ttotal: 16.1s\tremaining: 14s\n",
            "536:\tlearn: 0.0055910\ttotal: 16.2s\tremaining: 13.9s\n",
            "537:\tlearn: 0.0055893\ttotal: 16.2s\tremaining: 13.9s\n",
            "538:\tlearn: 0.0055873\ttotal: 16.2s\tremaining: 13.9s\n",
            "539:\tlearn: 0.0055850\ttotal: 16.2s\tremaining: 13.8s\n",
            "540:\tlearn: 0.0055811\ttotal: 16.3s\tremaining: 13.8s\n",
            "541:\tlearn: 0.0055789\ttotal: 16.3s\tremaining: 13.8s\n",
            "542:\tlearn: 0.0055761\ttotal: 16.3s\tremaining: 13.7s\n",
            "543:\tlearn: 0.0055744\ttotal: 16.3s\tremaining: 13.7s\n",
            "544:\tlearn: 0.0055730\ttotal: 16.4s\tremaining: 13.7s\n",
            "545:\tlearn: 0.0055721\ttotal: 16.4s\tremaining: 13.6s\n",
            "546:\tlearn: 0.0055683\ttotal: 16.4s\tremaining: 13.6s\n",
            "547:\tlearn: 0.0055571\ttotal: 16.4s\tremaining: 13.5s\n",
            "548:\tlearn: 0.0055532\ttotal: 16.4s\tremaining: 13.5s\n",
            "549:\tlearn: 0.0055526\ttotal: 16.5s\tremaining: 13.5s\n",
            "550:\tlearn: 0.0055494\ttotal: 16.5s\tremaining: 13.4s\n",
            "551:\tlearn: 0.0055481\ttotal: 16.5s\tremaining: 13.4s\n",
            "552:\tlearn: 0.0055472\ttotal: 16.5s\tremaining: 13.4s\n",
            "553:\tlearn: 0.0055451\ttotal: 16.6s\tremaining: 13.3s\n",
            "554:\tlearn: 0.0055439\ttotal: 16.6s\tremaining: 13.3s\n",
            "555:\tlearn: 0.0055409\ttotal: 16.6s\tremaining: 13.3s\n",
            "556:\tlearn: 0.0055380\ttotal: 16.6s\tremaining: 13.2s\n",
            "557:\tlearn: 0.0055366\ttotal: 16.7s\tremaining: 13.2s\n",
            "558:\tlearn: 0.0055353\ttotal: 16.7s\tremaining: 13.2s\n",
            "559:\tlearn: 0.0055328\ttotal: 16.7s\tremaining: 13.1s\n",
            "560:\tlearn: 0.0055295\ttotal: 16.7s\tremaining: 13.1s\n",
            "561:\tlearn: 0.0055268\ttotal: 16.8s\tremaining: 13.1s\n",
            "562:\tlearn: 0.0055261\ttotal: 16.8s\tremaining: 13s\n",
            "563:\tlearn: 0.0055250\ttotal: 16.8s\tremaining: 13s\n",
            "564:\tlearn: 0.0055217\ttotal: 16.8s\tremaining: 13s\n",
            "565:\tlearn: 0.0055196\ttotal: 16.9s\tremaining: 12.9s\n",
            "566:\tlearn: 0.0055183\ttotal: 16.9s\tremaining: 12.9s\n",
            "567:\tlearn: 0.0055167\ttotal: 16.9s\tremaining: 12.9s\n",
            "568:\tlearn: 0.0055151\ttotal: 16.9s\tremaining: 12.8s\n",
            "569:\tlearn: 0.0055113\ttotal: 17s\tremaining: 12.8s\n",
            "570:\tlearn: 0.0055091\ttotal: 17s\tremaining: 12.8s\n",
            "571:\tlearn: 0.0054949\ttotal: 17s\tremaining: 12.7s\n",
            "572:\tlearn: 0.0054903\ttotal: 17s\tremaining: 12.7s\n",
            "573:\tlearn: 0.0054891\ttotal: 17.1s\tremaining: 12.7s\n",
            "574:\tlearn: 0.0054875\ttotal: 17.1s\tremaining: 12.6s\n",
            "575:\tlearn: 0.0054808\ttotal: 17.1s\tremaining: 12.6s\n",
            "576:\tlearn: 0.0054795\ttotal: 17.1s\tremaining: 12.6s\n",
            "577:\tlearn: 0.0054766\ttotal: 17.2s\tremaining: 12.5s\n",
            "578:\tlearn: 0.0054735\ttotal: 17.2s\tremaining: 12.5s\n",
            "579:\tlearn: 0.0054724\ttotal: 17.2s\tremaining: 12.5s\n",
            "580:\tlearn: 0.0054703\ttotal: 17.2s\tremaining: 12.4s\n",
            "581:\tlearn: 0.0054678\ttotal: 17.2s\tremaining: 12.4s\n",
            "582:\tlearn: 0.0054626\ttotal: 17.3s\tremaining: 12.4s\n",
            "583:\tlearn: 0.0054617\ttotal: 17.3s\tremaining: 12.3s\n",
            "584:\tlearn: 0.0054604\ttotal: 17.3s\tremaining: 12.3s\n",
            "585:\tlearn: 0.0054591\ttotal: 17.3s\tremaining: 12.3s\n",
            "586:\tlearn: 0.0054583\ttotal: 17.4s\tremaining: 12.2s\n",
            "587:\tlearn: 0.0054565\ttotal: 17.4s\tremaining: 12.2s\n",
            "588:\tlearn: 0.0054556\ttotal: 17.4s\tremaining: 12.2s\n",
            "589:\tlearn: 0.0054545\ttotal: 17.4s\tremaining: 12.1s\n",
            "590:\tlearn: 0.0054536\ttotal: 17.5s\tremaining: 12.1s\n",
            "591:\tlearn: 0.0054519\ttotal: 17.5s\tremaining: 12s\n",
            "592:\tlearn: 0.0054511\ttotal: 17.5s\tremaining: 12s\n",
            "593:\tlearn: 0.0054501\ttotal: 17.5s\tremaining: 12s\n",
            "594:\tlearn: 0.0054485\ttotal: 17.6s\tremaining: 12s\n",
            "595:\tlearn: 0.0054452\ttotal: 17.6s\tremaining: 11.9s\n",
            "596:\tlearn: 0.0054419\ttotal: 17.6s\tremaining: 11.9s\n",
            "597:\tlearn: 0.0054398\ttotal: 17.6s\tremaining: 11.9s\n",
            "598:\tlearn: 0.0054372\ttotal: 17.7s\tremaining: 11.8s\n",
            "599:\tlearn: 0.0054359\ttotal: 17.7s\tremaining: 11.8s\n",
            "600:\tlearn: 0.0054342\ttotal: 17.7s\tremaining: 11.8s\n",
            "601:\tlearn: 0.0054291\ttotal: 17.7s\tremaining: 11.7s\n",
            "602:\tlearn: 0.0054274\ttotal: 17.8s\tremaining: 11.7s\n",
            "603:\tlearn: 0.0054208\ttotal: 17.8s\tremaining: 11.7s\n",
            "604:\tlearn: 0.0054193\ttotal: 17.8s\tremaining: 11.6s\n",
            "605:\tlearn: 0.0054180\ttotal: 17.8s\tremaining: 11.6s\n",
            "606:\tlearn: 0.0054167\ttotal: 17.9s\tremaining: 11.6s\n",
            "607:\tlearn: 0.0054160\ttotal: 17.9s\tremaining: 11.5s\n",
            "608:\tlearn: 0.0054147\ttotal: 17.9s\tremaining: 11.5s\n",
            "609:\tlearn: 0.0054127\ttotal: 17.9s\tremaining: 11.5s\n",
            "610:\tlearn: 0.0054117\ttotal: 17.9s\tremaining: 11.4s\n",
            "611:\tlearn: 0.0054077\ttotal: 18s\tremaining: 11.4s\n",
            "612:\tlearn: 0.0054028\ttotal: 18s\tremaining: 11.4s\n",
            "613:\tlearn: 0.0054024\ttotal: 18s\tremaining: 11.3s\n",
            "614:\tlearn: 0.0054015\ttotal: 18s\tremaining: 11.3s\n",
            "615:\tlearn: 0.0053969\ttotal: 18.1s\tremaining: 11.3s\n",
            "616:\tlearn: 0.0053949\ttotal: 18.1s\tremaining: 11.2s\n",
            "617:\tlearn: 0.0053944\ttotal: 18.1s\tremaining: 11.2s\n",
            "618:\tlearn: 0.0053915\ttotal: 18.2s\tremaining: 11.2s\n",
            "619:\tlearn: 0.0053907\ttotal: 18.2s\tremaining: 11.1s\n",
            "620:\tlearn: 0.0053894\ttotal: 18.2s\tremaining: 11.1s\n",
            "621:\tlearn: 0.0053880\ttotal: 18.2s\tremaining: 11.1s\n",
            "622:\tlearn: 0.0053867\ttotal: 18.2s\tremaining: 11s\n",
            "623:\tlearn: 0.0053852\ttotal: 18.3s\tremaining: 11s\n",
            "624:\tlearn: 0.0053830\ttotal: 18.3s\tremaining: 11s\n",
            "625:\tlearn: 0.0053818\ttotal: 18.3s\tremaining: 10.9s\n",
            "626:\tlearn: 0.0053790\ttotal: 18.3s\tremaining: 10.9s\n",
            "627:\tlearn: 0.0053762\ttotal: 18.4s\tremaining: 10.9s\n",
            "628:\tlearn: 0.0053710\ttotal: 18.4s\tremaining: 10.8s\n",
            "629:\tlearn: 0.0053687\ttotal: 18.4s\tremaining: 10.8s\n",
            "630:\tlearn: 0.0053608\ttotal: 18.4s\tremaining: 10.8s\n",
            "631:\tlearn: 0.0053590\ttotal: 18.5s\tremaining: 10.7s\n",
            "632:\tlearn: 0.0053587\ttotal: 18.5s\tremaining: 10.7s\n",
            "633:\tlearn: 0.0053582\ttotal: 18.5s\tremaining: 10.7s\n",
            "634:\tlearn: 0.0053568\ttotal: 18.5s\tremaining: 10.7s\n",
            "635:\tlearn: 0.0053499\ttotal: 18.6s\tremaining: 10.6s\n",
            "636:\tlearn: 0.0053482\ttotal: 18.6s\tremaining: 10.6s\n",
            "637:\tlearn: 0.0053454\ttotal: 18.6s\tremaining: 10.6s\n",
            "638:\tlearn: 0.0053437\ttotal: 18.6s\tremaining: 10.5s\n",
            "639:\tlearn: 0.0053429\ttotal: 18.7s\tremaining: 10.5s\n",
            "640:\tlearn: 0.0053421\ttotal: 18.7s\tremaining: 10.5s\n",
            "641:\tlearn: 0.0053388\ttotal: 18.7s\tremaining: 10.4s\n",
            "642:\tlearn: 0.0053333\ttotal: 18.7s\tremaining: 10.4s\n",
            "643:\tlearn: 0.0053322\ttotal: 18.7s\tremaining: 10.4s\n",
            "644:\tlearn: 0.0053318\ttotal: 18.8s\tremaining: 10.3s\n",
            "645:\tlearn: 0.0053287\ttotal: 18.8s\tremaining: 10.3s\n",
            "646:\tlearn: 0.0053262\ttotal: 18.8s\tremaining: 10.3s\n",
            "647:\tlearn: 0.0053231\ttotal: 18.8s\tremaining: 10.2s\n",
            "648:\tlearn: 0.0053215\ttotal: 18.9s\tremaining: 10.2s\n",
            "649:\tlearn: 0.0053144\ttotal: 18.9s\tremaining: 10.2s\n",
            "650:\tlearn: 0.0053126\ttotal: 18.9s\tremaining: 10.1s\n",
            "651:\tlearn: 0.0053109\ttotal: 18.9s\tremaining: 10.1s\n",
            "652:\tlearn: 0.0053091\ttotal: 19s\tremaining: 10.1s\n",
            "653:\tlearn: 0.0053069\ttotal: 19s\tremaining: 10s\n",
            "654:\tlearn: 0.0053013\ttotal: 19s\tremaining: 10s\n",
            "655:\tlearn: 0.0052997\ttotal: 19s\tremaining: 9.98s\n",
            "656:\tlearn: 0.0052972\ttotal: 19.1s\tremaining: 9.96s\n",
            "657:\tlearn: 0.0052947\ttotal: 19.1s\tremaining: 9.93s\n",
            "658:\tlearn: 0.0052893\ttotal: 19.1s\tremaining: 9.89s\n",
            "659:\tlearn: 0.0052883\ttotal: 19.1s\tremaining: 9.86s\n",
            "660:\tlearn: 0.0052869\ttotal: 19.2s\tremaining: 9.83s\n",
            "661:\tlearn: 0.0052863\ttotal: 19.2s\tremaining: 9.8s\n",
            "662:\tlearn: 0.0052852\ttotal: 19.2s\tremaining: 9.77s\n",
            "663:\tlearn: 0.0052829\ttotal: 19.2s\tremaining: 9.74s\n",
            "664:\tlearn: 0.0052809\ttotal: 19.3s\tremaining: 9.71s\n",
            "665:\tlearn: 0.0052783\ttotal: 19.3s\tremaining: 9.67s\n",
            "666:\tlearn: 0.0052770\ttotal: 19.3s\tremaining: 9.64s\n",
            "667:\tlearn: 0.0052762\ttotal: 19.3s\tremaining: 9.61s\n",
            "668:\tlearn: 0.0052753\ttotal: 19.4s\tremaining: 9.58s\n",
            "669:\tlearn: 0.0052736\ttotal: 19.4s\tremaining: 9.55s\n",
            "670:\tlearn: 0.0052726\ttotal: 19.4s\tremaining: 9.52s\n",
            "671:\tlearn: 0.0052721\ttotal: 19.4s\tremaining: 9.48s\n",
            "672:\tlearn: 0.0052714\ttotal: 19.5s\tremaining: 9.46s\n",
            "673:\tlearn: 0.0052639\ttotal: 19.5s\tremaining: 9.43s\n",
            "674:\tlearn: 0.0052620\ttotal: 19.5s\tremaining: 9.39s\n",
            "675:\tlearn: 0.0052603\ttotal: 19.5s\tremaining: 9.36s\n",
            "676:\tlearn: 0.0052561\ttotal: 19.6s\tremaining: 9.33s\n",
            "677:\tlearn: 0.0052556\ttotal: 19.6s\tremaining: 9.3s\n",
            "678:\tlearn: 0.0052533\ttotal: 19.6s\tremaining: 9.27s\n",
            "679:\tlearn: 0.0052470\ttotal: 19.6s\tremaining: 9.24s\n",
            "680:\tlearn: 0.0052457\ttotal: 19.7s\tremaining: 9.21s\n",
            "681:\tlearn: 0.0052445\ttotal: 19.7s\tremaining: 9.18s\n",
            "682:\tlearn: 0.0052423\ttotal: 19.7s\tremaining: 9.15s\n",
            "683:\tlearn: 0.0052416\ttotal: 19.7s\tremaining: 9.12s\n",
            "684:\tlearn: 0.0052380\ttotal: 19.8s\tremaining: 9.09s\n",
            "685:\tlearn: 0.0052352\ttotal: 19.8s\tremaining: 9.06s\n",
            "686:\tlearn: 0.0052343\ttotal: 19.8s\tremaining: 9.02s\n",
            "687:\tlearn: 0.0052331\ttotal: 19.8s\tremaining: 8.99s\n",
            "688:\tlearn: 0.0052315\ttotal: 19.9s\tremaining: 8.96s\n",
            "689:\tlearn: 0.0052306\ttotal: 19.9s\tremaining: 8.93s\n",
            "690:\tlearn: 0.0052295\ttotal: 19.9s\tremaining: 8.9s\n",
            "691:\tlearn: 0.0052282\ttotal: 19.9s\tremaining: 8.87s\n",
            "692:\tlearn: 0.0052273\ttotal: 19.9s\tremaining: 8.84s\n",
            "693:\tlearn: 0.0052264\ttotal: 20s\tremaining: 8.81s\n",
            "694:\tlearn: 0.0052255\ttotal: 20s\tremaining: 8.77s\n",
            "695:\tlearn: 0.0052235\ttotal: 20s\tremaining: 8.74s\n",
            "696:\tlearn: 0.0052208\ttotal: 20s\tremaining: 8.71s\n",
            "697:\tlearn: 0.0052202\ttotal: 20.1s\tremaining: 8.68s\n",
            "698:\tlearn: 0.0052197\ttotal: 20.1s\tremaining: 8.66s\n",
            "699:\tlearn: 0.0052188\ttotal: 20.1s\tremaining: 8.62s\n",
            "700:\tlearn: 0.0052183\ttotal: 20.1s\tremaining: 8.59s\n",
            "701:\tlearn: 0.0052163\ttotal: 20.2s\tremaining: 8.56s\n",
            "702:\tlearn: 0.0052148\ttotal: 20.2s\tremaining: 8.53s\n",
            "703:\tlearn: 0.0052139\ttotal: 20.2s\tremaining: 8.5s\n",
            "704:\tlearn: 0.0052117\ttotal: 20.2s\tremaining: 8.47s\n",
            "705:\tlearn: 0.0052112\ttotal: 20.3s\tremaining: 8.44s\n",
            "706:\tlearn: 0.0052090\ttotal: 20.3s\tremaining: 8.41s\n",
            "707:\tlearn: 0.0052074\ttotal: 20.3s\tremaining: 8.38s\n",
            "708:\tlearn: 0.0052053\ttotal: 20.3s\tremaining: 8.35s\n",
            "709:\tlearn: 0.0052038\ttotal: 20.4s\tremaining: 8.32s\n",
            "710:\tlearn: 0.0052021\ttotal: 20.4s\tremaining: 8.29s\n",
            "711:\tlearn: 0.0052013\ttotal: 20.4s\tremaining: 8.26s\n",
            "712:\tlearn: 0.0051998\ttotal: 20.4s\tremaining: 8.23s\n",
            "713:\tlearn: 0.0051982\ttotal: 20.5s\tremaining: 8.2s\n",
            "714:\tlearn: 0.0051963\ttotal: 20.5s\tremaining: 8.16s\n",
            "715:\tlearn: 0.0051957\ttotal: 20.5s\tremaining: 8.13s\n",
            "716:\tlearn: 0.0051947\ttotal: 20.5s\tremaining: 8.11s\n",
            "717:\tlearn: 0.0051923\ttotal: 20.6s\tremaining: 8.07s\n",
            "718:\tlearn: 0.0051919\ttotal: 20.6s\tremaining: 8.04s\n",
            "719:\tlearn: 0.0051900\ttotal: 20.6s\tremaining: 8.01s\n",
            "720:\tlearn: 0.0051868\ttotal: 20.6s\tremaining: 7.98s\n",
            "721:\tlearn: 0.0051849\ttotal: 20.6s\tremaining: 7.95s\n",
            "722:\tlearn: 0.0051826\ttotal: 20.7s\tremaining: 7.92s\n",
            "723:\tlearn: 0.0051789\ttotal: 20.7s\tremaining: 7.89s\n",
            "724:\tlearn: 0.0051785\ttotal: 20.7s\tremaining: 7.86s\n",
            "725:\tlearn: 0.0051777\ttotal: 20.8s\tremaining: 7.83s\n",
            "726:\tlearn: 0.0051769\ttotal: 20.8s\tremaining: 7.8s\n",
            "727:\tlearn: 0.0051748\ttotal: 20.8s\tremaining: 7.77s\n",
            "728:\tlearn: 0.0051744\ttotal: 20.8s\tremaining: 7.74s\n",
            "729:\tlearn: 0.0051736\ttotal: 20.8s\tremaining: 7.71s\n",
            "730:\tlearn: 0.0051721\ttotal: 20.9s\tremaining: 7.68s\n",
            "731:\tlearn: 0.0051708\ttotal: 20.9s\tremaining: 7.65s\n",
            "732:\tlearn: 0.0051692\ttotal: 20.9s\tremaining: 7.62s\n",
            "733:\tlearn: 0.0051682\ttotal: 20.9s\tremaining: 7.59s\n",
            "734:\tlearn: 0.0051667\ttotal: 21s\tremaining: 7.56s\n",
            "735:\tlearn: 0.0051660\ttotal: 21s\tremaining: 7.53s\n",
            "736:\tlearn: 0.0051655\ttotal: 21s\tremaining: 7.5s\n",
            "737:\tlearn: 0.0051653\ttotal: 21s\tremaining: 7.46s\n",
            "738:\tlearn: 0.0051642\ttotal: 21s\tremaining: 7.43s\n",
            "739:\tlearn: 0.0051634\ttotal: 21.1s\tremaining: 7.4s\n",
            "740:\tlearn: 0.0051620\ttotal: 21.1s\tremaining: 7.38s\n",
            "741:\tlearn: 0.0051612\ttotal: 21.1s\tremaining: 7.35s\n",
            "742:\tlearn: 0.0051593\ttotal: 21.2s\tremaining: 7.32s\n",
            "743:\tlearn: 0.0051580\ttotal: 21.2s\tremaining: 7.29s\n",
            "744:\tlearn: 0.0051570\ttotal: 21.2s\tremaining: 7.26s\n",
            "745:\tlearn: 0.0051498\ttotal: 21.2s\tremaining: 7.23s\n",
            "746:\tlearn: 0.0051491\ttotal: 21.3s\tremaining: 7.2s\n",
            "747:\tlearn: 0.0051485\ttotal: 21.3s\tremaining: 7.17s\n",
            "748:\tlearn: 0.0051476\ttotal: 21.3s\tremaining: 7.14s\n",
            "749:\tlearn: 0.0051441\ttotal: 21.3s\tremaining: 7.11s\n",
            "750:\tlearn: 0.0051438\ttotal: 21.4s\tremaining: 7.08s\n",
            "751:\tlearn: 0.0051432\ttotal: 21.4s\tremaining: 7.05s\n",
            "752:\tlearn: 0.0051429\ttotal: 21.4s\tremaining: 7.02s\n",
            "753:\tlearn: 0.0051418\ttotal: 21.4s\tremaining: 6.99s\n",
            "754:\tlearn: 0.0051405\ttotal: 21.5s\tremaining: 6.96s\n",
            "755:\tlearn: 0.0051397\ttotal: 21.5s\tremaining: 6.93s\n",
            "756:\tlearn: 0.0051389\ttotal: 21.5s\tremaining: 6.9s\n",
            "757:\tlearn: 0.0051360\ttotal: 21.5s\tremaining: 6.87s\n",
            "758:\tlearn: 0.0051343\ttotal: 21.5s\tremaining: 6.84s\n",
            "759:\tlearn: 0.0051334\ttotal: 21.6s\tremaining: 6.81s\n",
            "760:\tlearn: 0.0051323\ttotal: 21.6s\tremaining: 6.78s\n",
            "761:\tlearn: 0.0051306\ttotal: 21.6s\tremaining: 6.75s\n",
            "762:\tlearn: 0.0051267\ttotal: 21.6s\tremaining: 6.72s\n",
            "763:\tlearn: 0.0051252\ttotal: 21.7s\tremaining: 6.69s\n",
            "764:\tlearn: 0.0051250\ttotal: 21.7s\tremaining: 6.66s\n",
            "765:\tlearn: 0.0051216\ttotal: 21.7s\tremaining: 6.63s\n",
            "766:\tlearn: 0.0051206\ttotal: 21.7s\tremaining: 6.6s\n",
            "767:\tlearn: 0.0051185\ttotal: 21.8s\tremaining: 6.57s\n",
            "768:\tlearn: 0.0051151\ttotal: 21.8s\tremaining: 6.54s\n",
            "769:\tlearn: 0.0051146\ttotal: 21.8s\tremaining: 6.52s\n",
            "770:\tlearn: 0.0051128\ttotal: 21.8s\tremaining: 6.49s\n",
            "771:\tlearn: 0.0051117\ttotal: 21.9s\tremaining: 6.46s\n",
            "772:\tlearn: 0.0051106\ttotal: 21.9s\tremaining: 6.43s\n",
            "773:\tlearn: 0.0051074\ttotal: 21.9s\tremaining: 6.41s\n",
            "774:\tlearn: 0.0051062\ttotal: 22s\tremaining: 6.38s\n",
            "775:\tlearn: 0.0051009\ttotal: 22s\tremaining: 6.36s\n",
            "776:\tlearn: 0.0050989\ttotal: 22.1s\tremaining: 6.34s\n",
            "777:\tlearn: 0.0050984\ttotal: 22.2s\tremaining: 6.33s\n",
            "778:\tlearn: 0.0050970\ttotal: 22.3s\tremaining: 6.31s\n",
            "779:\tlearn: 0.0050962\ttotal: 22.3s\tremaining: 6.3s\n",
            "780:\tlearn: 0.0050942\ttotal: 22.4s\tremaining: 6.28s\n",
            "781:\tlearn: 0.0050927\ttotal: 22.5s\tremaining: 6.27s\n",
            "782:\tlearn: 0.0050923\ttotal: 22.6s\tremaining: 6.25s\n",
            "783:\tlearn: 0.0050910\ttotal: 22.6s\tremaining: 6.24s\n",
            "784:\tlearn: 0.0050896\ttotal: 22.7s\tremaining: 6.22s\n",
            "785:\tlearn: 0.0050889\ttotal: 22.8s\tremaining: 6.2s\n",
            "786:\tlearn: 0.0050880\ttotal: 22.9s\tremaining: 6.19s\n",
            "787:\tlearn: 0.0050866\ttotal: 22.9s\tremaining: 6.17s\n",
            "788:\tlearn: 0.0050841\ttotal: 23s\tremaining: 6.16s\n",
            "789:\tlearn: 0.0050833\ttotal: 23.1s\tremaining: 6.14s\n",
            "790:\tlearn: 0.0050828\ttotal: 23.2s\tremaining: 6.12s\n",
            "791:\tlearn: 0.0050810\ttotal: 23.2s\tremaining: 6.1s\n",
            "792:\tlearn: 0.0050794\ttotal: 23.3s\tremaining: 6.09s\n",
            "793:\tlearn: 0.0050781\ttotal: 23.4s\tremaining: 6.07s\n",
            "794:\tlearn: 0.0050762\ttotal: 23.5s\tremaining: 6.05s\n",
            "795:\tlearn: 0.0050740\ttotal: 23.6s\tremaining: 6.04s\n",
            "796:\tlearn: 0.0050693\ttotal: 23.6s\tremaining: 6.02s\n",
            "797:\tlearn: 0.0050683\ttotal: 23.7s\tremaining: 6s\n",
            "798:\tlearn: 0.0050673\ttotal: 23.8s\tremaining: 5.99s\n",
            "799:\tlearn: 0.0050646\ttotal: 23.9s\tremaining: 5.97s\n",
            "800:\tlearn: 0.0050641\ttotal: 24s\tremaining: 5.95s\n",
            "801:\tlearn: 0.0050627\ttotal: 24s\tremaining: 5.93s\n",
            "802:\tlearn: 0.0050617\ttotal: 24.1s\tremaining: 5.92s\n",
            "803:\tlearn: 0.0050610\ttotal: 24.2s\tremaining: 5.9s\n",
            "804:\tlearn: 0.0050606\ttotal: 24.3s\tremaining: 5.89s\n",
            "805:\tlearn: 0.0050592\ttotal: 24.4s\tremaining: 5.87s\n",
            "806:\tlearn: 0.0050574\ttotal: 24.5s\tremaining: 5.85s\n",
            "807:\tlearn: 0.0050565\ttotal: 24.6s\tremaining: 5.83s\n",
            "808:\tlearn: 0.0050558\ttotal: 24.6s\tremaining: 5.82s\n",
            "809:\tlearn: 0.0050543\ttotal: 24.7s\tremaining: 5.8s\n",
            "810:\tlearn: 0.0050520\ttotal: 24.8s\tremaining: 5.78s\n",
            "811:\tlearn: 0.0050502\ttotal: 24.9s\tremaining: 5.77s\n",
            "812:\tlearn: 0.0050487\ttotal: 25s\tremaining: 5.75s\n",
            "813:\tlearn: 0.0050482\ttotal: 25.1s\tremaining: 5.73s\n",
            "814:\tlearn: 0.0050414\ttotal: 25.2s\tremaining: 5.71s\n",
            "815:\tlearn: 0.0050398\ttotal: 25.3s\tremaining: 5.7s\n",
            "816:\tlearn: 0.0050373\ttotal: 25.3s\tremaining: 5.68s\n",
            "817:\tlearn: 0.0050365\ttotal: 25.4s\tremaining: 5.66s\n",
            "818:\tlearn: 0.0050332\ttotal: 25.5s\tremaining: 5.64s\n",
            "819:\tlearn: 0.0050314\ttotal: 25.6s\tremaining: 5.62s\n",
            "820:\tlearn: 0.0050279\ttotal: 25.7s\tremaining: 5.61s\n",
            "821:\tlearn: 0.0050263\ttotal: 25.8s\tremaining: 5.59s\n",
            "822:\tlearn: 0.0050253\ttotal: 25.9s\tremaining: 5.57s\n",
            "823:\tlearn: 0.0050242\ttotal: 26s\tremaining: 5.55s\n",
            "824:\tlearn: 0.0050233\ttotal: 26.1s\tremaining: 5.53s\n",
            "825:\tlearn: 0.0050208\ttotal: 26.1s\tremaining: 5.5s\n",
            "826:\tlearn: 0.0050201\ttotal: 26.1s\tremaining: 5.47s\n",
            "827:\tlearn: 0.0050185\ttotal: 26.2s\tremaining: 5.44s\n",
            "828:\tlearn: 0.0050178\ttotal: 26.2s\tremaining: 5.41s\n",
            "829:\tlearn: 0.0050166\ttotal: 26.2s\tremaining: 5.37s\n",
            "830:\tlearn: 0.0050127\ttotal: 26.3s\tremaining: 5.34s\n",
            "831:\tlearn: 0.0050124\ttotal: 26.3s\tremaining: 5.31s\n",
            "832:\tlearn: 0.0050109\ttotal: 26.3s\tremaining: 5.28s\n",
            "833:\tlearn: 0.0050100\ttotal: 26.3s\tremaining: 5.24s\n",
            "834:\tlearn: 0.0050086\ttotal: 26.4s\tremaining: 5.21s\n",
            "835:\tlearn: 0.0050078\ttotal: 26.4s\tremaining: 5.18s\n",
            "836:\tlearn: 0.0050074\ttotal: 26.4s\tremaining: 5.14s\n",
            "837:\tlearn: 0.0050064\ttotal: 26.4s\tremaining: 5.11s\n",
            "838:\tlearn: 0.0050053\ttotal: 26.5s\tremaining: 5.08s\n",
            "839:\tlearn: 0.0049998\ttotal: 26.5s\tremaining: 5.04s\n",
            "840:\tlearn: 0.0049995\ttotal: 26.5s\tremaining: 5.01s\n",
            "841:\tlearn: 0.0049993\ttotal: 26.5s\tremaining: 4.98s\n",
            "842:\tlearn: 0.0049983\ttotal: 26.6s\tremaining: 4.95s\n",
            "843:\tlearn: 0.0049974\ttotal: 26.6s\tremaining: 4.91s\n",
            "844:\tlearn: 0.0049958\ttotal: 26.6s\tremaining: 4.88s\n",
            "845:\tlearn: 0.0049939\ttotal: 26.6s\tremaining: 4.85s\n",
            "846:\tlearn: 0.0049920\ttotal: 26.7s\tremaining: 4.82s\n",
            "847:\tlearn: 0.0049900\ttotal: 26.7s\tremaining: 4.78s\n",
            "848:\tlearn: 0.0049886\ttotal: 26.7s\tremaining: 4.75s\n",
            "849:\tlearn: 0.0049880\ttotal: 26.7s\tremaining: 4.72s\n",
            "850:\tlearn: 0.0049873\ttotal: 26.8s\tremaining: 4.68s\n",
            "851:\tlearn: 0.0049870\ttotal: 26.8s\tremaining: 4.65s\n",
            "852:\tlearn: 0.0049862\ttotal: 26.8s\tremaining: 4.62s\n",
            "853:\tlearn: 0.0049857\ttotal: 26.8s\tremaining: 4.58s\n",
            "854:\tlearn: 0.0049851\ttotal: 26.9s\tremaining: 4.55s\n",
            "855:\tlearn: 0.0049844\ttotal: 26.9s\tremaining: 4.52s\n",
            "856:\tlearn: 0.0049836\ttotal: 26.9s\tremaining: 4.49s\n",
            "857:\tlearn: 0.0049824\ttotal: 26.9s\tremaining: 4.46s\n",
            "858:\tlearn: 0.0049801\ttotal: 26.9s\tremaining: 4.42s\n",
            "859:\tlearn: 0.0049787\ttotal: 27s\tremaining: 4.39s\n",
            "860:\tlearn: 0.0049783\ttotal: 27s\tremaining: 4.36s\n",
            "861:\tlearn: 0.0049766\ttotal: 27s\tremaining: 4.33s\n",
            "862:\tlearn: 0.0049759\ttotal: 27s\tremaining: 4.29s\n",
            "863:\tlearn: 0.0049745\ttotal: 27.1s\tremaining: 4.26s\n",
            "864:\tlearn: 0.0049737\ttotal: 27.1s\tremaining: 4.23s\n",
            "865:\tlearn: 0.0049708\ttotal: 27.1s\tremaining: 4.2s\n",
            "866:\tlearn: 0.0049698\ttotal: 27.1s\tremaining: 4.16s\n",
            "867:\tlearn: 0.0049692\ttotal: 27.2s\tremaining: 4.13s\n",
            "868:\tlearn: 0.0049689\ttotal: 27.2s\tremaining: 4.1s\n",
            "869:\tlearn: 0.0049683\ttotal: 27.2s\tremaining: 4.07s\n",
            "870:\tlearn: 0.0049675\ttotal: 27.2s\tremaining: 4.03s\n",
            "871:\tlearn: 0.0049668\ttotal: 27.3s\tremaining: 4s\n",
            "872:\tlearn: 0.0049649\ttotal: 27.3s\tremaining: 3.97s\n",
            "873:\tlearn: 0.0049628\ttotal: 27.3s\tremaining: 3.94s\n",
            "874:\tlearn: 0.0049622\ttotal: 27.3s\tremaining: 3.91s\n",
            "875:\tlearn: 0.0049617\ttotal: 27.4s\tremaining: 3.87s\n",
            "876:\tlearn: 0.0049606\ttotal: 27.4s\tremaining: 3.84s\n",
            "877:\tlearn: 0.0049595\ttotal: 27.4s\tremaining: 3.81s\n",
            "878:\tlearn: 0.0049563\ttotal: 27.4s\tremaining: 3.78s\n",
            "879:\tlearn: 0.0049558\ttotal: 27.5s\tremaining: 3.75s\n",
            "880:\tlearn: 0.0049550\ttotal: 27.5s\tremaining: 3.71s\n",
            "881:\tlearn: 0.0049533\ttotal: 27.5s\tremaining: 3.68s\n",
            "882:\tlearn: 0.0049522\ttotal: 27.5s\tremaining: 3.65s\n",
            "883:\tlearn: 0.0049506\ttotal: 27.6s\tremaining: 3.62s\n",
            "884:\tlearn: 0.0049490\ttotal: 27.6s\tremaining: 3.58s\n",
            "885:\tlearn: 0.0049478\ttotal: 27.6s\tremaining: 3.55s\n",
            "886:\tlearn: 0.0049469\ttotal: 27.6s\tremaining: 3.52s\n",
            "887:\tlearn: 0.0049460\ttotal: 27.7s\tremaining: 3.49s\n",
            "888:\tlearn: 0.0049454\ttotal: 27.7s\tremaining: 3.46s\n",
            "889:\tlearn: 0.0049448\ttotal: 27.7s\tremaining: 3.42s\n",
            "890:\tlearn: 0.0049439\ttotal: 27.7s\tremaining: 3.39s\n",
            "891:\tlearn: 0.0049429\ttotal: 27.8s\tremaining: 3.36s\n",
            "892:\tlearn: 0.0049413\ttotal: 27.8s\tremaining: 3.33s\n",
            "893:\tlearn: 0.0049402\ttotal: 27.8s\tremaining: 3.3s\n",
            "894:\tlearn: 0.0049346\ttotal: 27.8s\tremaining: 3.27s\n",
            "895:\tlearn: 0.0049337\ttotal: 27.9s\tremaining: 3.23s\n",
            "896:\tlearn: 0.0049326\ttotal: 27.9s\tremaining: 3.2s\n",
            "897:\tlearn: 0.0049318\ttotal: 27.9s\tremaining: 3.17s\n",
            "898:\tlearn: 0.0049308\ttotal: 27.9s\tremaining: 3.14s\n",
            "899:\tlearn: 0.0049299\ttotal: 28s\tremaining: 3.1s\n",
            "900:\tlearn: 0.0049293\ttotal: 28s\tremaining: 3.07s\n",
            "901:\tlearn: 0.0049237\ttotal: 28s\tremaining: 3.04s\n",
            "902:\tlearn: 0.0049225\ttotal: 28s\tremaining: 3.01s\n",
            "903:\tlearn: 0.0049220\ttotal: 28.1s\tremaining: 2.98s\n",
            "904:\tlearn: 0.0049207\ttotal: 28.1s\tremaining: 2.95s\n",
            "905:\tlearn: 0.0049200\ttotal: 28.1s\tremaining: 2.92s\n",
            "906:\tlearn: 0.0049184\ttotal: 28.1s\tremaining: 2.88s\n",
            "907:\tlearn: 0.0049165\ttotal: 28.1s\tremaining: 2.85s\n",
            "908:\tlearn: 0.0049135\ttotal: 28.2s\tremaining: 2.82s\n",
            "909:\tlearn: 0.0049125\ttotal: 28.2s\tremaining: 2.79s\n",
            "910:\tlearn: 0.0049093\ttotal: 28.2s\tremaining: 2.76s\n",
            "911:\tlearn: 0.0049081\ttotal: 28.2s\tremaining: 2.73s\n",
            "912:\tlearn: 0.0049076\ttotal: 28.3s\tremaining: 2.69s\n",
            "913:\tlearn: 0.0049069\ttotal: 28.3s\tremaining: 2.66s\n",
            "914:\tlearn: 0.0049063\ttotal: 28.3s\tremaining: 2.63s\n",
            "915:\tlearn: 0.0049055\ttotal: 28.4s\tremaining: 2.6s\n",
            "916:\tlearn: 0.0049053\ttotal: 28.4s\tremaining: 2.57s\n",
            "917:\tlearn: 0.0048988\ttotal: 28.4s\tremaining: 2.54s\n",
            "918:\tlearn: 0.0048986\ttotal: 28.4s\tremaining: 2.5s\n",
            "919:\tlearn: 0.0048975\ttotal: 28.4s\tremaining: 2.47s\n",
            "920:\tlearn: 0.0048950\ttotal: 28.5s\tremaining: 2.44s\n",
            "921:\tlearn: 0.0048943\ttotal: 28.5s\tremaining: 2.41s\n",
            "922:\tlearn: 0.0048932\ttotal: 28.5s\tremaining: 2.38s\n",
            "923:\tlearn: 0.0048928\ttotal: 28.5s\tremaining: 2.35s\n",
            "924:\tlearn: 0.0048920\ttotal: 28.6s\tremaining: 2.32s\n",
            "925:\tlearn: 0.0048918\ttotal: 28.6s\tremaining: 2.28s\n",
            "926:\tlearn: 0.0048914\ttotal: 28.6s\tremaining: 2.25s\n",
            "927:\tlearn: 0.0048910\ttotal: 28.6s\tremaining: 2.22s\n",
            "928:\tlearn: 0.0048895\ttotal: 28.7s\tremaining: 2.19s\n",
            "929:\tlearn: 0.0048884\ttotal: 28.7s\tremaining: 2.16s\n",
            "930:\tlearn: 0.0048866\ttotal: 28.7s\tremaining: 2.13s\n",
            "931:\tlearn: 0.0048855\ttotal: 28.7s\tremaining: 2.1s\n",
            "932:\tlearn: 0.0048840\ttotal: 28.8s\tremaining: 2.06s\n",
            "933:\tlearn: 0.0048819\ttotal: 28.8s\tremaining: 2.03s\n",
            "934:\tlearn: 0.0048809\ttotal: 28.8s\tremaining: 2s\n",
            "935:\tlearn: 0.0048797\ttotal: 28.8s\tremaining: 1.97s\n",
            "936:\tlearn: 0.0048792\ttotal: 28.8s\tremaining: 1.94s\n",
            "937:\tlearn: 0.0048790\ttotal: 28.9s\tremaining: 1.91s\n",
            "938:\tlearn: 0.0048753\ttotal: 28.9s\tremaining: 1.88s\n",
            "939:\tlearn: 0.0048747\ttotal: 28.9s\tremaining: 1.84s\n",
            "940:\tlearn: 0.0048742\ttotal: 28.9s\tremaining: 1.81s\n",
            "941:\tlearn: 0.0048714\ttotal: 29s\tremaining: 1.78s\n",
            "942:\tlearn: 0.0048703\ttotal: 29s\tremaining: 1.75s\n",
            "943:\tlearn: 0.0048692\ttotal: 29s\tremaining: 1.72s\n",
            "944:\tlearn: 0.0048671\ttotal: 29s\tremaining: 1.69s\n",
            "945:\tlearn: 0.0048668\ttotal: 29.1s\tremaining: 1.66s\n",
            "946:\tlearn: 0.0048616\ttotal: 29.1s\tremaining: 1.63s\n",
            "947:\tlearn: 0.0048605\ttotal: 29.1s\tremaining: 1.6s\n",
            "948:\tlearn: 0.0048596\ttotal: 29.1s\tremaining: 1.56s\n",
            "949:\tlearn: 0.0048586\ttotal: 29.2s\tremaining: 1.53s\n",
            "950:\tlearn: 0.0048553\ttotal: 29.2s\tremaining: 1.5s\n",
            "951:\tlearn: 0.0048544\ttotal: 29.2s\tremaining: 1.47s\n",
            "952:\tlearn: 0.0048475\ttotal: 29.2s\tremaining: 1.44s\n",
            "953:\tlearn: 0.0048468\ttotal: 29.3s\tremaining: 1.41s\n",
            "954:\tlearn: 0.0048466\ttotal: 29.3s\tremaining: 1.38s\n",
            "955:\tlearn: 0.0048461\ttotal: 29.3s\tremaining: 1.35s\n",
            "956:\tlearn: 0.0048447\ttotal: 29.3s\tremaining: 1.32s\n",
            "957:\tlearn: 0.0048430\ttotal: 29.4s\tremaining: 1.29s\n",
            "958:\tlearn: 0.0048415\ttotal: 29.4s\tremaining: 1.26s\n",
            "959:\tlearn: 0.0048401\ttotal: 29.4s\tremaining: 1.23s\n",
            "960:\tlearn: 0.0048392\ttotal: 29.4s\tremaining: 1.19s\n",
            "961:\tlearn: 0.0048373\ttotal: 29.5s\tremaining: 1.16s\n",
            "962:\tlearn: 0.0048366\ttotal: 29.5s\tremaining: 1.13s\n",
            "963:\tlearn: 0.0048331\ttotal: 29.5s\tremaining: 1.1s\n",
            "964:\tlearn: 0.0048321\ttotal: 29.5s\tremaining: 1.07s\n",
            "965:\tlearn: 0.0048307\ttotal: 29.5s\tremaining: 1.04s\n",
            "966:\tlearn: 0.0048291\ttotal: 29.6s\tremaining: 1.01s\n",
            "967:\tlearn: 0.0048288\ttotal: 29.6s\tremaining: 978ms\n",
            "968:\tlearn: 0.0048285\ttotal: 29.6s\tremaining: 948ms\n",
            "969:\tlearn: 0.0048276\ttotal: 29.7s\tremaining: 917ms\n",
            "970:\tlearn: 0.0048273\ttotal: 29.7s\tremaining: 887ms\n",
            "971:\tlearn: 0.0048268\ttotal: 29.7s\tremaining: 856ms\n",
            "972:\tlearn: 0.0048252\ttotal: 29.7s\tremaining: 825ms\n",
            "973:\tlearn: 0.0048243\ttotal: 29.8s\tremaining: 794ms\n",
            "974:\tlearn: 0.0048240\ttotal: 29.8s\tremaining: 764ms\n",
            "975:\tlearn: 0.0048219\ttotal: 29.8s\tremaining: 733ms\n",
            "976:\tlearn: 0.0048205\ttotal: 29.8s\tremaining: 702ms\n",
            "977:\tlearn: 0.0048199\ttotal: 29.9s\tremaining: 672ms\n",
            "978:\tlearn: 0.0048196\ttotal: 29.9s\tremaining: 641ms\n",
            "979:\tlearn: 0.0048184\ttotal: 29.9s\tremaining: 610ms\n",
            "980:\tlearn: 0.0048176\ttotal: 29.9s\tremaining: 580ms\n",
            "981:\tlearn: 0.0048167\ttotal: 29.9s\tremaining: 549ms\n",
            "982:\tlearn: 0.0048160\ttotal: 30s\tremaining: 518ms\n",
            "983:\tlearn: 0.0048155\ttotal: 30s\tremaining: 488ms\n",
            "984:\tlearn: 0.0048150\ttotal: 30s\tremaining: 457ms\n",
            "985:\tlearn: 0.0048134\ttotal: 30s\tremaining: 427ms\n",
            "986:\tlearn: 0.0048123\ttotal: 30.1s\tremaining: 396ms\n",
            "987:\tlearn: 0.0048120\ttotal: 30.1s\tremaining: 365ms\n",
            "988:\tlearn: 0.0048108\ttotal: 30.1s\tremaining: 335ms\n",
            "989:\tlearn: 0.0048106\ttotal: 30.1s\tremaining: 304ms\n",
            "990:\tlearn: 0.0048100\ttotal: 30.2s\tremaining: 274ms\n",
            "991:\tlearn: 0.0048085\ttotal: 30.2s\tremaining: 243ms\n",
            "992:\tlearn: 0.0048067\ttotal: 30.2s\tremaining: 213ms\n",
            "993:\tlearn: 0.0048051\ttotal: 30.2s\tremaining: 182ms\n",
            "994:\tlearn: 0.0048044\ttotal: 30.2s\tremaining: 152ms\n",
            "995:\tlearn: 0.0048030\ttotal: 30.3s\tremaining: 122ms\n",
            "996:\tlearn: 0.0048026\ttotal: 30.3s\tremaining: 91.2ms\n",
            "997:\tlearn: 0.0048020\ttotal: 30.3s\tremaining: 60.8ms\n",
            "998:\tlearn: 0.0047992\ttotal: 30.4s\tremaining: 30.4ms\n",
            "999:\tlearn: 0.0047987\ttotal: 30.4s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c1b4c0db400>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9973682825411864\n",
            "F1_macro: 0.9175435844452597\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      1.00      1.00     37244\n",
            "                  PortScan       0.94      0.97      0.96       312\n",
            "                  DoS Hulk       1.00      1.00      1.00     10298\n",
            "                      DDoS       1.00      1.00      1.00      1646\n",
            "                       Bot       1.00      1.00      1.00     13960\n",
            "              Infiltration       1.00      0.99      0.99       836\n",
            "  Web Attack ÔøΩ Brute Force       1.00      0.99      0.99       862\n",
            "          Web Attack ÔøΩ XSS       1.00      1.00      1.00       949\n",
            "Web Attack ÔøΩ Sql Injection       1.00      1.00      1.00         2\n",
            "               FTP-Patator       1.00      1.00      1.00         6\n",
            "               SSH-Patator       1.00      1.00      1.00      9024\n",
            "             DoS slowloris       1.00      1.00      1.00       515\n",
            "          DoS Slowhttptest       0.72      0.80      0.76       235\n",
            "             DoS GoldenEye       0.60      1.00      0.75         3\n",
            "                Heartbleed       0.38      0.27      0.32       104\n",
            "\n",
            "                  accuracy                           1.00     75996\n",
            "                 macro avg       0.91      0.94      0.92     75996\n",
            "              weighted avg       1.00      1.00      1.00     75996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£–¥–∞–ª–∏–º –µ—â–µ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü –∏–∑ –∫–æ–Ω—Ü–∞ —Å–ø–∏—Å–∫–∞"
      ],
      "metadata": {
        "id": "FsRh2X2azXd3"
      },
      "id": "FsRh2X2azXd3"
    },
    {
      "cell_type": "code",
      "source": [
        "features_train_2 = features_train_1.drop(' SYN Flag Count', axis=1)\n",
        "features_val_2 = features_val_1.drop(' SYN Flag Count', axis=1)\n",
        "\n",
        "model_bas_cb = CatBoostClassifier(cat_features=[30,31,32,33,43,44,45,46,47,48],\n",
        "                                  task_type=\"GPU\",\n",
        "                                  random_state=12345)\n",
        "\n",
        "model_bas_cb.fit(features_train_2, target_train)\n",
        "\n",
        "preds = model_bas_cb.predict(features_val_2)\n",
        "print (\"Accuracy:\",accuracy_score(target_val, preds))\n",
        "print (\"F1_macro:\", f1_score(target_val, preds, average='macro'))\n",
        "target_names = ['BENIGN', 'PortScan', 'DoS Hulk', 'DDoS', 'Bot', 'Infiltration', 'Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ XSS',\n",
        "                'Web Attack ÔøΩ Sql Injection', 'FTP-Patator', 'SSH-Patator','DoS slowloris', 'DoS Slowhttptest', 'DoS GoldenEye', 'Heartbleed']\n",
        "\n",
        "print(classification_report(target_val, preds, target_names=target_names))"
      ],
      "metadata": {
        "id": "6YFSorYYzXqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e196d4-cae0-42e6-d7b9-e5597810aa40"
      },
      "id": "6YFSorYYzXqg",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.208346\n",
            "0:\tlearn: 0.7103989\ttotal: 99.1ms\tremaining: 1m 38s\n",
            "1:\tlearn: 0.5330125\ttotal: 207ms\tremaining: 1m 43s\n",
            "2:\tlearn: 0.4251299\ttotal: 317ms\tremaining: 1m 45s\n",
            "3:\tlearn: 0.3508356\ttotal: 442ms\tremaining: 1m 49s\n",
            "4:\tlearn: 0.2924896\ttotal: 550ms\tremaining: 1m 49s\n",
            "5:\tlearn: 0.2478457\ttotal: 659ms\tremaining: 1m 49s\n",
            "6:\tlearn: 0.2095375\ttotal: 752ms\tremaining: 1m 46s\n",
            "7:\tlearn: 0.1809451\ttotal: 844ms\tremaining: 1m 44s\n",
            "8:\tlearn: 0.1571204\ttotal: 944ms\tremaining: 1m 43s\n",
            "9:\tlearn: 0.1388515\ttotal: 1.03s\tremaining: 1m 42s\n",
            "10:\tlearn: 0.1221289\ttotal: 1.14s\tremaining: 1m 42s\n",
            "11:\tlearn: 0.1093289\ttotal: 1.24s\tremaining: 1m 41s\n",
            "12:\tlearn: 0.0976665\ttotal: 1.33s\tremaining: 1m 41s\n",
            "13:\tlearn: 0.0869762\ttotal: 1.43s\tremaining: 1m 40s\n",
            "14:\tlearn: 0.0789329\ttotal: 1.53s\tremaining: 1m 40s\n",
            "15:\tlearn: 0.0718294\ttotal: 1.62s\tremaining: 1m 39s\n",
            "16:\tlearn: 0.0662951\ttotal: 1.71s\tremaining: 1m 38s\n",
            "17:\tlearn: 0.0616462\ttotal: 1.8s\tremaining: 1m 38s\n",
            "18:\tlearn: 0.0551420\ttotal: 1.89s\tremaining: 1m 37s\n",
            "19:\tlearn: 0.0520590\ttotal: 1.98s\tremaining: 1m 36s\n",
            "20:\tlearn: 0.0486751\ttotal: 2.07s\tremaining: 1m 36s\n",
            "21:\tlearn: 0.0454262\ttotal: 2.17s\tremaining: 1m 36s\n",
            "22:\tlearn: 0.0434212\ttotal: 2.25s\tremaining: 1m 35s\n",
            "23:\tlearn: 0.0409714\ttotal: 2.35s\tremaining: 1m 35s\n",
            "24:\tlearn: 0.0392083\ttotal: 2.42s\tremaining: 1m 34s\n",
            "25:\tlearn: 0.0368327\ttotal: 2.51s\tremaining: 1m 34s\n",
            "26:\tlearn: 0.0350407\ttotal: 2.61s\tremaining: 1m 34s\n",
            "27:\tlearn: 0.0338135\ttotal: 2.68s\tremaining: 1m 33s\n",
            "28:\tlearn: 0.0328842\ttotal: 2.76s\tremaining: 1m 32s\n",
            "29:\tlearn: 0.0314293\ttotal: 2.85s\tremaining: 1m 32s\n",
            "30:\tlearn: 0.0307448\ttotal: 2.9s\tremaining: 1m 30s\n",
            "31:\tlearn: 0.0291268\ttotal: 2.94s\tremaining: 1m 28s\n",
            "32:\tlearn: 0.0281445\ttotal: 2.98s\tremaining: 1m 27s\n",
            "33:\tlearn: 0.0269580\ttotal: 3.01s\tremaining: 1m 25s\n",
            "34:\tlearn: 0.0263456\ttotal: 3.04s\tremaining: 1m 23s\n",
            "35:\tlearn: 0.0256997\ttotal: 3.08s\tremaining: 1m 22s\n",
            "36:\tlearn: 0.0249438\ttotal: 3.1s\tremaining: 1m 20s\n",
            "37:\tlearn: 0.0238749\ttotal: 3.13s\tremaining: 1m 19s\n",
            "38:\tlearn: 0.0235438\ttotal: 3.15s\tremaining: 1m 17s\n",
            "39:\tlearn: 0.0230185\ttotal: 3.18s\tremaining: 1m 16s\n",
            "40:\tlearn: 0.0217829\ttotal: 3.21s\tremaining: 1m 15s\n",
            "41:\tlearn: 0.0212357\ttotal: 3.23s\tremaining: 1m 13s\n",
            "42:\tlearn: 0.0207581\ttotal: 3.25s\tremaining: 1m 12s\n",
            "43:\tlearn: 0.0200771\ttotal: 3.27s\tremaining: 1m 11s\n",
            "44:\tlearn: 0.0197118\ttotal: 3.3s\tremaining: 1m 10s\n",
            "45:\tlearn: 0.0195207\ttotal: 3.32s\tremaining: 1m 8s\n",
            "46:\tlearn: 0.0193281\ttotal: 3.34s\tremaining: 1m 7s\n",
            "47:\tlearn: 0.0191870\ttotal: 3.36s\tremaining: 1m 6s\n",
            "48:\tlearn: 0.0189412\ttotal: 3.38s\tremaining: 1m 5s\n",
            "49:\tlearn: 0.0183781\ttotal: 3.42s\tremaining: 1m 4s\n",
            "50:\tlearn: 0.0179996\ttotal: 3.44s\tremaining: 1m 3s\n",
            "51:\tlearn: 0.0177990\ttotal: 3.47s\tremaining: 1m 3s\n",
            "52:\tlearn: 0.0176617\ttotal: 3.49s\tremaining: 1m 2s\n",
            "53:\tlearn: 0.0173436\ttotal: 3.52s\tremaining: 1m 1s\n",
            "54:\tlearn: 0.0170443\ttotal: 3.54s\tremaining: 1m\n",
            "55:\tlearn: 0.0168907\ttotal: 3.57s\tremaining: 1m\n",
            "56:\tlearn: 0.0165565\ttotal: 3.59s\tremaining: 59.4s\n",
            "57:\tlearn: 0.0163294\ttotal: 3.61s\tremaining: 58.6s\n",
            "58:\tlearn: 0.0159468\ttotal: 3.63s\tremaining: 57.9s\n",
            "59:\tlearn: 0.0157861\ttotal: 3.66s\tremaining: 57.3s\n",
            "60:\tlearn: 0.0155913\ttotal: 3.68s\tremaining: 56.6s\n",
            "61:\tlearn: 0.0152573\ttotal: 3.7s\tremaining: 56s\n",
            "62:\tlearn: 0.0149500\ttotal: 3.73s\tremaining: 55.4s\n",
            "63:\tlearn: 0.0148691\ttotal: 3.75s\tremaining: 54.8s\n",
            "64:\tlearn: 0.0146668\ttotal: 3.77s\tremaining: 54.2s\n",
            "65:\tlearn: 0.0144223\ttotal: 3.79s\tremaining: 53.7s\n",
            "66:\tlearn: 0.0141347\ttotal: 3.82s\tremaining: 53.2s\n",
            "67:\tlearn: 0.0140124\ttotal: 3.84s\tremaining: 52.7s\n",
            "68:\tlearn: 0.0139534\ttotal: 3.87s\tremaining: 52.2s\n",
            "69:\tlearn: 0.0138156\ttotal: 3.89s\tremaining: 51.7s\n",
            "70:\tlearn: 0.0136606\ttotal: 3.91s\tremaining: 51.2s\n",
            "71:\tlearn: 0.0136068\ttotal: 3.94s\tremaining: 50.8s\n",
            "72:\tlearn: 0.0135484\ttotal: 3.96s\tremaining: 50.4s\n",
            "73:\tlearn: 0.0133662\ttotal: 3.99s\tremaining: 49.9s\n",
            "74:\tlearn: 0.0131968\ttotal: 4.01s\tremaining: 49.5s\n",
            "75:\tlearn: 0.0131116\ttotal: 4.03s\tremaining: 49s\n",
            "76:\tlearn: 0.0130367\ttotal: 4.05s\tremaining: 48.6s\n",
            "77:\tlearn: 0.0129824\ttotal: 4.08s\tremaining: 48.2s\n",
            "78:\tlearn: 0.0128561\ttotal: 4.1s\tremaining: 47.8s\n",
            "79:\tlearn: 0.0126912\ttotal: 4.12s\tremaining: 47.4s\n",
            "80:\tlearn: 0.0125309\ttotal: 4.15s\tremaining: 47.1s\n",
            "81:\tlearn: 0.0122924\ttotal: 4.17s\tremaining: 46.7s\n",
            "82:\tlearn: 0.0122596\ttotal: 4.19s\tremaining: 46.3s\n",
            "83:\tlearn: 0.0121545\ttotal: 4.22s\tremaining: 46s\n",
            "84:\tlearn: 0.0120429\ttotal: 4.24s\tremaining: 45.6s\n",
            "85:\tlearn: 0.0120173\ttotal: 4.26s\tremaining: 45.3s\n",
            "86:\tlearn: 0.0119755\ttotal: 4.29s\tremaining: 45s\n",
            "87:\tlearn: 0.0118895\ttotal: 4.31s\tremaining: 44.6s\n",
            "88:\tlearn: 0.0118436\ttotal: 4.33s\tremaining: 44.3s\n",
            "89:\tlearn: 0.0117617\ttotal: 4.36s\tremaining: 44s\n",
            "90:\tlearn: 0.0117548\ttotal: 4.38s\tremaining: 43.7s\n",
            "91:\tlearn: 0.0116494\ttotal: 4.4s\tremaining: 43.4s\n",
            "92:\tlearn: 0.0115574\ttotal: 4.42s\tremaining: 43.1s\n",
            "93:\tlearn: 0.0112252\ttotal: 4.45s\tremaining: 42.9s\n",
            "94:\tlearn: 0.0111648\ttotal: 4.5s\tremaining: 42.8s\n",
            "95:\tlearn: 0.0110529\ttotal: 4.52s\tremaining: 42.6s\n",
            "96:\tlearn: 0.0110096\ttotal: 4.54s\tremaining: 42.3s\n",
            "97:\tlearn: 0.0109959\ttotal: 4.57s\tremaining: 42s\n",
            "98:\tlearn: 0.0109747\ttotal: 4.59s\tremaining: 41.8s\n",
            "99:\tlearn: 0.0109161\ttotal: 4.61s\tremaining: 41.5s\n",
            "100:\tlearn: 0.0108574\ttotal: 4.63s\tremaining: 41.2s\n",
            "101:\tlearn: 0.0107976\ttotal: 4.66s\tremaining: 41s\n",
            "102:\tlearn: 0.0107347\ttotal: 4.68s\tremaining: 40.7s\n",
            "103:\tlearn: 0.0106871\ttotal: 4.7s\tremaining: 40.5s\n",
            "104:\tlearn: 0.0106400\ttotal: 4.72s\tremaining: 40.3s\n",
            "105:\tlearn: 0.0104864\ttotal: 4.75s\tremaining: 40.1s\n",
            "106:\tlearn: 0.0104260\ttotal: 4.78s\tremaining: 39.9s\n",
            "107:\tlearn: 0.0103471\ttotal: 4.8s\tremaining: 39.7s\n",
            "108:\tlearn: 0.0102777\ttotal: 4.83s\tremaining: 39.5s\n",
            "109:\tlearn: 0.0102056\ttotal: 4.85s\tremaining: 39.3s\n",
            "110:\tlearn: 0.0101630\ttotal: 4.88s\tremaining: 39.1s\n",
            "111:\tlearn: 0.0101135\ttotal: 4.9s\tremaining: 38.8s\n",
            "112:\tlearn: 0.0100684\ttotal: 4.92s\tremaining: 38.6s\n",
            "113:\tlearn: 0.0100041\ttotal: 4.95s\tremaining: 38.4s\n",
            "114:\tlearn: 0.0099708\ttotal: 4.97s\tremaining: 38.2s\n",
            "115:\tlearn: 0.0099449\ttotal: 4.99s\tremaining: 38.1s\n",
            "116:\tlearn: 0.0099023\ttotal: 5.02s\tremaining: 37.9s\n",
            "117:\tlearn: 0.0098634\ttotal: 5.05s\tremaining: 37.7s\n",
            "118:\tlearn: 0.0098380\ttotal: 5.07s\tremaining: 37.5s\n",
            "119:\tlearn: 0.0098230\ttotal: 5.09s\tremaining: 37.3s\n",
            "120:\tlearn: 0.0098155\ttotal: 5.11s\tremaining: 37.1s\n",
            "121:\tlearn: 0.0098050\ttotal: 5.13s\tremaining: 36.9s\n",
            "122:\tlearn: 0.0097686\ttotal: 5.16s\tremaining: 36.8s\n",
            "123:\tlearn: 0.0097344\ttotal: 5.18s\tremaining: 36.6s\n",
            "124:\tlearn: 0.0096996\ttotal: 5.21s\tremaining: 36.5s\n",
            "125:\tlearn: 0.0096263\ttotal: 5.23s\tremaining: 36.3s\n",
            "126:\tlearn: 0.0095996\ttotal: 5.26s\tremaining: 36.1s\n",
            "127:\tlearn: 0.0095859\ttotal: 5.28s\tremaining: 35.9s\n",
            "128:\tlearn: 0.0095659\ttotal: 5.3s\tremaining: 35.8s\n",
            "129:\tlearn: 0.0095320\ttotal: 5.32s\tremaining: 35.6s\n",
            "130:\tlearn: 0.0094441\ttotal: 5.34s\tremaining: 35.5s\n",
            "131:\tlearn: 0.0094203\ttotal: 5.37s\tremaining: 35.3s\n",
            "132:\tlearn: 0.0093760\ttotal: 5.39s\tremaining: 35.1s\n",
            "133:\tlearn: 0.0093160\ttotal: 5.42s\tremaining: 35s\n",
            "134:\tlearn: 0.0092897\ttotal: 5.44s\tremaining: 34.9s\n",
            "135:\tlearn: 0.0092595\ttotal: 5.48s\tremaining: 34.8s\n",
            "136:\tlearn: 0.0092483\ttotal: 5.51s\tremaining: 34.7s\n",
            "137:\tlearn: 0.0092173\ttotal: 5.53s\tremaining: 34.5s\n",
            "138:\tlearn: 0.0091656\ttotal: 5.55s\tremaining: 34.4s\n",
            "139:\tlearn: 0.0091322\ttotal: 5.57s\tremaining: 34.2s\n",
            "140:\tlearn: 0.0091172\ttotal: 5.59s\tremaining: 34.1s\n",
            "141:\tlearn: 0.0091079\ttotal: 5.61s\tremaining: 33.9s\n",
            "142:\tlearn: 0.0090557\ttotal: 5.64s\tremaining: 33.8s\n",
            "143:\tlearn: 0.0090158\ttotal: 5.66s\tremaining: 33.7s\n",
            "144:\tlearn: 0.0089798\ttotal: 5.69s\tremaining: 33.5s\n",
            "145:\tlearn: 0.0089639\ttotal: 5.71s\tremaining: 33.4s\n",
            "146:\tlearn: 0.0089524\ttotal: 5.73s\tremaining: 33.3s\n",
            "147:\tlearn: 0.0089383\ttotal: 5.75s\tremaining: 33.1s\n",
            "148:\tlearn: 0.0089253\ttotal: 5.78s\tremaining: 33s\n",
            "149:\tlearn: 0.0089069\ttotal: 5.8s\tremaining: 32.8s\n",
            "150:\tlearn: 0.0088980\ttotal: 5.82s\tremaining: 32.7s\n",
            "151:\tlearn: 0.0088594\ttotal: 5.85s\tremaining: 32.6s\n",
            "152:\tlearn: 0.0088346\ttotal: 5.87s\tremaining: 32.5s\n",
            "153:\tlearn: 0.0087984\ttotal: 5.91s\tremaining: 32.5s\n",
            "154:\tlearn: 0.0087138\ttotal: 5.93s\tremaining: 32.3s\n",
            "155:\tlearn: 0.0086907\ttotal: 5.95s\tremaining: 32.2s\n",
            "156:\tlearn: 0.0086751\ttotal: 5.97s\tremaining: 32.1s\n",
            "157:\tlearn: 0.0086330\ttotal: 6s\tremaining: 32s\n",
            "158:\tlearn: 0.0085965\ttotal: 6.03s\tremaining: 31.9s\n",
            "159:\tlearn: 0.0085791\ttotal: 6.05s\tremaining: 31.8s\n",
            "160:\tlearn: 0.0085429\ttotal: 6.07s\tremaining: 31.7s\n",
            "161:\tlearn: 0.0085149\ttotal: 6.1s\tremaining: 31.6s\n",
            "162:\tlearn: 0.0084715\ttotal: 6.12s\tremaining: 31.4s\n",
            "163:\tlearn: 0.0084506\ttotal: 6.15s\tremaining: 31.3s\n",
            "164:\tlearn: 0.0084377\ttotal: 6.17s\tremaining: 31.2s\n",
            "165:\tlearn: 0.0084301\ttotal: 6.19s\tremaining: 31.1s\n",
            "166:\tlearn: 0.0084160\ttotal: 6.21s\tremaining: 31s\n",
            "167:\tlearn: 0.0083823\ttotal: 6.23s\tremaining: 30.9s\n",
            "168:\tlearn: 0.0083659\ttotal: 6.26s\tremaining: 30.8s\n",
            "169:\tlearn: 0.0083545\ttotal: 6.28s\tremaining: 30.7s\n",
            "170:\tlearn: 0.0083394\ttotal: 6.3s\tremaining: 30.6s\n",
            "171:\tlearn: 0.0083239\ttotal: 6.33s\tremaining: 30.5s\n",
            "172:\tlearn: 0.0083106\ttotal: 6.35s\tremaining: 30.4s\n",
            "173:\tlearn: 0.0082886\ttotal: 6.37s\tremaining: 30.3s\n",
            "174:\tlearn: 0.0082791\ttotal: 6.41s\tremaining: 30.2s\n",
            "175:\tlearn: 0.0082708\ttotal: 6.43s\tremaining: 30.1s\n",
            "176:\tlearn: 0.0082588\ttotal: 6.45s\tremaining: 30s\n",
            "177:\tlearn: 0.0082274\ttotal: 6.49s\tremaining: 30s\n",
            "178:\tlearn: 0.0082087\ttotal: 6.51s\tremaining: 29.9s\n",
            "179:\tlearn: 0.0081864\ttotal: 6.54s\tremaining: 29.8s\n",
            "180:\tlearn: 0.0081591\ttotal: 6.56s\tremaining: 29.7s\n",
            "181:\tlearn: 0.0081359\ttotal: 6.58s\tremaining: 29.6s\n",
            "182:\tlearn: 0.0081225\ttotal: 6.61s\tremaining: 29.5s\n",
            "183:\tlearn: 0.0081061\ttotal: 6.63s\tremaining: 29.4s\n",
            "184:\tlearn: 0.0080854\ttotal: 6.65s\tremaining: 29.3s\n",
            "185:\tlearn: 0.0080634\ttotal: 6.68s\tremaining: 29.2s\n",
            "186:\tlearn: 0.0080532\ttotal: 6.7s\tremaining: 29.1s\n",
            "187:\tlearn: 0.0080402\ttotal: 6.72s\tremaining: 29s\n",
            "188:\tlearn: 0.0080231\ttotal: 6.75s\tremaining: 29s\n",
            "189:\tlearn: 0.0080152\ttotal: 6.77s\tremaining: 28.9s\n",
            "190:\tlearn: 0.0080030\ttotal: 6.79s\tremaining: 28.8s\n",
            "191:\tlearn: 0.0079916\ttotal: 6.82s\tremaining: 28.7s\n",
            "192:\tlearn: 0.0079557\ttotal: 6.84s\tremaining: 28.6s\n",
            "193:\tlearn: 0.0079486\ttotal: 6.87s\tremaining: 28.5s\n",
            "194:\tlearn: 0.0079383\ttotal: 6.89s\tremaining: 28.5s\n",
            "195:\tlearn: 0.0079246\ttotal: 6.92s\tremaining: 28.4s\n",
            "196:\tlearn: 0.0079104\ttotal: 6.94s\tremaining: 28.3s\n",
            "197:\tlearn: 0.0079013\ttotal: 6.96s\tremaining: 28.2s\n",
            "198:\tlearn: 0.0078823\ttotal: 6.99s\tremaining: 28.1s\n",
            "199:\tlearn: 0.0078736\ttotal: 7.01s\tremaining: 28s\n",
            "200:\tlearn: 0.0078546\ttotal: 7.03s\tremaining: 28s\n",
            "201:\tlearn: 0.0078292\ttotal: 7.05s\tremaining: 27.9s\n",
            "202:\tlearn: 0.0077955\ttotal: 7.08s\tremaining: 27.8s\n",
            "203:\tlearn: 0.0077911\ttotal: 7.1s\tremaining: 27.7s\n",
            "204:\tlearn: 0.0077796\ttotal: 7.13s\tremaining: 27.6s\n",
            "205:\tlearn: 0.0077318\ttotal: 7.15s\tremaining: 27.6s\n",
            "206:\tlearn: 0.0077199\ttotal: 7.18s\tremaining: 27.5s\n",
            "207:\tlearn: 0.0077041\ttotal: 7.2s\tremaining: 27.4s\n",
            "208:\tlearn: 0.0076980\ttotal: 7.22s\tremaining: 27.3s\n",
            "209:\tlearn: 0.0076550\ttotal: 7.25s\tremaining: 27.3s\n",
            "210:\tlearn: 0.0076442\ttotal: 7.27s\tremaining: 27.2s\n",
            "211:\tlearn: 0.0076339\ttotal: 7.3s\tremaining: 27.1s\n",
            "212:\tlearn: 0.0076266\ttotal: 7.34s\tremaining: 27.1s\n",
            "213:\tlearn: 0.0076202\ttotal: 7.36s\tremaining: 27s\n",
            "214:\tlearn: 0.0076139\ttotal: 7.38s\tremaining: 27s\n",
            "215:\tlearn: 0.0075860\ttotal: 7.41s\tremaining: 26.9s\n",
            "216:\tlearn: 0.0075763\ttotal: 7.43s\tremaining: 26.8s\n",
            "217:\tlearn: 0.0075591\ttotal: 7.45s\tremaining: 26.7s\n",
            "218:\tlearn: 0.0075466\ttotal: 7.47s\tremaining: 26.7s\n",
            "219:\tlearn: 0.0074985\ttotal: 7.51s\tremaining: 26.6s\n",
            "220:\tlearn: 0.0074919\ttotal: 7.53s\tremaining: 26.5s\n",
            "221:\tlearn: 0.0074829\ttotal: 7.56s\tremaining: 26.5s\n",
            "222:\tlearn: 0.0074777\ttotal: 7.58s\tremaining: 26.4s\n",
            "223:\tlearn: 0.0074533\ttotal: 7.6s\tremaining: 26.3s\n",
            "224:\tlearn: 0.0074459\ttotal: 7.62s\tremaining: 26.3s\n",
            "225:\tlearn: 0.0074392\ttotal: 7.64s\tremaining: 26.2s\n",
            "226:\tlearn: 0.0074337\ttotal: 7.67s\tremaining: 26.1s\n",
            "227:\tlearn: 0.0074278\ttotal: 7.69s\tremaining: 26s\n",
            "228:\tlearn: 0.0074026\ttotal: 7.71s\tremaining: 26s\n",
            "229:\tlearn: 0.0073958\ttotal: 7.74s\tremaining: 25.9s\n",
            "230:\tlearn: 0.0073896\ttotal: 7.77s\tremaining: 25.9s\n",
            "231:\tlearn: 0.0073769\ttotal: 7.79s\tremaining: 25.8s\n",
            "232:\tlearn: 0.0073451\ttotal: 7.81s\tremaining: 25.7s\n",
            "233:\tlearn: 0.0073386\ttotal: 7.83s\tremaining: 25.6s\n",
            "234:\tlearn: 0.0073303\ttotal: 7.86s\tremaining: 25.6s\n",
            "235:\tlearn: 0.0073247\ttotal: 7.88s\tremaining: 25.5s\n",
            "236:\tlearn: 0.0073192\ttotal: 7.9s\tremaining: 25.4s\n",
            "237:\tlearn: 0.0073132\ttotal: 7.92s\tremaining: 25.4s\n",
            "238:\tlearn: 0.0073055\ttotal: 7.95s\tremaining: 25.3s\n",
            "239:\tlearn: 0.0072970\ttotal: 7.97s\tremaining: 25.2s\n",
            "240:\tlearn: 0.0072824\ttotal: 8s\tremaining: 25.2s\n",
            "241:\tlearn: 0.0072651\ttotal: 8.02s\tremaining: 25.1s\n",
            "242:\tlearn: 0.0072542\ttotal: 8.04s\tremaining: 25.1s\n",
            "243:\tlearn: 0.0072415\ttotal: 8.07s\tremaining: 25s\n",
            "244:\tlearn: 0.0072280\ttotal: 8.09s\tremaining: 24.9s\n",
            "245:\tlearn: 0.0072224\ttotal: 8.11s\tremaining: 24.9s\n",
            "246:\tlearn: 0.0072134\ttotal: 8.14s\tremaining: 24.8s\n",
            "247:\tlearn: 0.0072064\ttotal: 8.16s\tremaining: 24.7s\n",
            "248:\tlearn: 0.0071988\ttotal: 8.19s\tremaining: 24.7s\n",
            "249:\tlearn: 0.0071879\ttotal: 8.21s\tremaining: 24.6s\n",
            "250:\tlearn: 0.0071814\ttotal: 8.23s\tremaining: 24.6s\n",
            "251:\tlearn: 0.0071686\ttotal: 8.27s\tremaining: 24.5s\n",
            "252:\tlearn: 0.0071581\ttotal: 8.29s\tremaining: 24.5s\n",
            "253:\tlearn: 0.0071356\ttotal: 8.31s\tremaining: 24.4s\n",
            "254:\tlearn: 0.0071329\ttotal: 8.34s\tremaining: 24.4s\n",
            "255:\tlearn: 0.0071249\ttotal: 8.36s\tremaining: 24.3s\n",
            "256:\tlearn: 0.0071198\ttotal: 8.38s\tremaining: 24.2s\n",
            "257:\tlearn: 0.0071134\ttotal: 8.41s\tremaining: 24.2s\n",
            "258:\tlearn: 0.0070818\ttotal: 8.43s\tremaining: 24.1s\n",
            "259:\tlearn: 0.0070680\ttotal: 8.46s\tremaining: 24.1s\n",
            "260:\tlearn: 0.0070617\ttotal: 8.48s\tremaining: 24s\n",
            "261:\tlearn: 0.0070554\ttotal: 8.52s\tremaining: 24s\n",
            "262:\tlearn: 0.0070492\ttotal: 8.54s\tremaining: 23.9s\n",
            "263:\tlearn: 0.0070451\ttotal: 8.56s\tremaining: 23.9s\n",
            "264:\tlearn: 0.0070354\ttotal: 8.58s\tremaining: 23.8s\n",
            "265:\tlearn: 0.0070279\ttotal: 8.6s\tremaining: 23.7s\n",
            "266:\tlearn: 0.0070233\ttotal: 8.63s\tremaining: 23.7s\n",
            "267:\tlearn: 0.0069925\ttotal: 8.65s\tremaining: 23.6s\n",
            "268:\tlearn: 0.0069852\ttotal: 8.68s\tremaining: 23.6s\n",
            "269:\tlearn: 0.0069750\ttotal: 8.7s\tremaining: 23.5s\n",
            "270:\tlearn: 0.0069677\ttotal: 8.74s\tremaining: 23.5s\n",
            "271:\tlearn: 0.0069657\ttotal: 8.76s\tremaining: 23.4s\n",
            "272:\tlearn: 0.0069505\ttotal: 8.78s\tremaining: 23.4s\n",
            "273:\tlearn: 0.0069419\ttotal: 8.8s\tremaining: 23.3s\n",
            "274:\tlearn: 0.0069334\ttotal: 8.82s\tremaining: 23.3s\n",
            "275:\tlearn: 0.0069289\ttotal: 8.85s\tremaining: 23.2s\n",
            "276:\tlearn: 0.0069239\ttotal: 8.87s\tremaining: 23.2s\n",
            "277:\tlearn: 0.0069201\ttotal: 8.9s\tremaining: 23.1s\n",
            "278:\tlearn: 0.0069153\ttotal: 8.93s\tremaining: 23.1s\n",
            "279:\tlearn: 0.0069098\ttotal: 8.95s\tremaining: 23s\n",
            "280:\tlearn: 0.0068902\ttotal: 8.98s\tremaining: 23s\n",
            "281:\tlearn: 0.0068763\ttotal: 9s\tremaining: 22.9s\n",
            "282:\tlearn: 0.0068733\ttotal: 9.02s\tremaining: 22.9s\n",
            "283:\tlearn: 0.0068655\ttotal: 9.04s\tremaining: 22.8s\n",
            "284:\tlearn: 0.0068561\ttotal: 9.07s\tremaining: 22.8s\n",
            "285:\tlearn: 0.0068383\ttotal: 9.1s\tremaining: 22.7s\n",
            "286:\tlearn: 0.0068266\ttotal: 9.13s\tremaining: 22.7s\n",
            "287:\tlearn: 0.0068208\ttotal: 9.15s\tremaining: 22.6s\n",
            "288:\tlearn: 0.0068042\ttotal: 9.17s\tremaining: 22.6s\n",
            "289:\tlearn: 0.0067897\ttotal: 9.2s\tremaining: 22.5s\n",
            "290:\tlearn: 0.0067830\ttotal: 9.22s\tremaining: 22.5s\n",
            "291:\tlearn: 0.0067770\ttotal: 9.24s\tremaining: 22.4s\n",
            "292:\tlearn: 0.0067588\ttotal: 9.27s\tremaining: 22.4s\n",
            "293:\tlearn: 0.0067398\ttotal: 9.29s\tremaining: 22.3s\n",
            "294:\tlearn: 0.0067258\ttotal: 9.32s\tremaining: 22.3s\n",
            "295:\tlearn: 0.0067189\ttotal: 9.34s\tremaining: 22.2s\n",
            "296:\tlearn: 0.0067124\ttotal: 9.36s\tremaining: 22.2s\n",
            "297:\tlearn: 0.0067094\ttotal: 9.39s\tremaining: 22.1s\n",
            "298:\tlearn: 0.0067023\ttotal: 9.41s\tremaining: 22.1s\n",
            "299:\tlearn: 0.0066964\ttotal: 9.43s\tremaining: 22s\n",
            "300:\tlearn: 0.0066923\ttotal: 9.46s\tremaining: 22s\n",
            "301:\tlearn: 0.0066795\ttotal: 9.48s\tremaining: 21.9s\n",
            "302:\tlearn: 0.0066711\ttotal: 9.52s\tremaining: 21.9s\n",
            "303:\tlearn: 0.0066593\ttotal: 9.54s\tremaining: 21.9s\n",
            "304:\tlearn: 0.0066560\ttotal: 9.57s\tremaining: 21.8s\n",
            "305:\tlearn: 0.0066468\ttotal: 9.59s\tremaining: 21.7s\n",
            "306:\tlearn: 0.0066404\ttotal: 9.61s\tremaining: 21.7s\n",
            "307:\tlearn: 0.0066292\ttotal: 9.64s\tremaining: 21.7s\n",
            "308:\tlearn: 0.0066259\ttotal: 9.66s\tremaining: 21.6s\n",
            "309:\tlearn: 0.0066094\ttotal: 9.69s\tremaining: 21.6s\n",
            "310:\tlearn: 0.0066025\ttotal: 9.71s\tremaining: 21.5s\n",
            "311:\tlearn: 0.0065953\ttotal: 9.74s\tremaining: 21.5s\n",
            "312:\tlearn: 0.0065913\ttotal: 9.76s\tremaining: 21.4s\n",
            "313:\tlearn: 0.0065795\ttotal: 9.79s\tremaining: 21.4s\n",
            "314:\tlearn: 0.0065580\ttotal: 9.81s\tremaining: 21.3s\n",
            "315:\tlearn: 0.0065527\ttotal: 9.83s\tremaining: 21.3s\n",
            "316:\tlearn: 0.0065465\ttotal: 9.86s\tremaining: 21.2s\n",
            "317:\tlearn: 0.0065381\ttotal: 9.89s\tremaining: 21.2s\n",
            "318:\tlearn: 0.0065370\ttotal: 9.91s\tremaining: 21.2s\n",
            "319:\tlearn: 0.0065346\ttotal: 9.93s\tremaining: 21.1s\n",
            "320:\tlearn: 0.0065278\ttotal: 9.96s\tremaining: 21.1s\n",
            "321:\tlearn: 0.0065205\ttotal: 9.98s\tremaining: 21s\n",
            "322:\tlearn: 0.0065106\ttotal: 10s\tremaining: 21s\n",
            "323:\tlearn: 0.0065013\ttotal: 10s\tremaining: 20.9s\n",
            "324:\tlearn: 0.0064899\ttotal: 10.1s\tremaining: 20.9s\n",
            "325:\tlearn: 0.0064872\ttotal: 10.1s\tremaining: 20.8s\n",
            "326:\tlearn: 0.0064698\ttotal: 10.1s\tremaining: 20.8s\n",
            "327:\tlearn: 0.0064639\ttotal: 10.1s\tremaining: 20.7s\n",
            "328:\tlearn: 0.0064606\ttotal: 10.2s\tremaining: 20.7s\n",
            "329:\tlearn: 0.0064568\ttotal: 10.2s\tremaining: 20.7s\n",
            "330:\tlearn: 0.0064460\ttotal: 10.2s\tremaining: 20.6s\n",
            "331:\tlearn: 0.0064336\ttotal: 10.2s\tremaining: 20.6s\n",
            "332:\tlearn: 0.0064309\ttotal: 10.2s\tremaining: 20.5s\n",
            "333:\tlearn: 0.0064224\ttotal: 10.3s\tremaining: 20.5s\n",
            "334:\tlearn: 0.0064127\ttotal: 10.3s\tremaining: 20.4s\n",
            "335:\tlearn: 0.0064006\ttotal: 10.3s\tremaining: 20.4s\n",
            "336:\tlearn: 0.0063946\ttotal: 10.3s\tremaining: 20.4s\n",
            "337:\tlearn: 0.0063903\ttotal: 10.4s\tremaining: 20.3s\n",
            "338:\tlearn: 0.0063853\ttotal: 10.4s\tremaining: 20.3s\n",
            "339:\tlearn: 0.0063797\ttotal: 10.4s\tremaining: 20.2s\n",
            "340:\tlearn: 0.0063731\ttotal: 10.4s\tremaining: 20.2s\n",
            "341:\tlearn: 0.0063666\ttotal: 10.5s\tremaining: 20.1s\n",
            "342:\tlearn: 0.0063438\ttotal: 10.5s\tremaining: 20.1s\n",
            "343:\tlearn: 0.0063373\ttotal: 10.5s\tremaining: 20.1s\n",
            "344:\tlearn: 0.0063299\ttotal: 10.6s\tremaining: 20s\n",
            "345:\tlearn: 0.0063192\ttotal: 10.6s\tremaining: 20s\n",
            "346:\tlearn: 0.0063062\ttotal: 10.6s\tremaining: 20s\n",
            "347:\tlearn: 0.0063040\ttotal: 10.6s\tremaining: 19.9s\n",
            "348:\tlearn: 0.0062984\ttotal: 10.6s\tremaining: 19.9s\n",
            "349:\tlearn: 0.0062940\ttotal: 10.7s\tremaining: 19.8s\n",
            "350:\tlearn: 0.0062866\ttotal: 10.7s\tremaining: 19.8s\n",
            "351:\tlearn: 0.0062817\ttotal: 10.7s\tremaining: 19.7s\n",
            "352:\tlearn: 0.0062757\ttotal: 10.7s\tremaining: 19.7s\n",
            "353:\tlearn: 0.0062726\ttotal: 10.8s\tremaining: 19.6s\n",
            "354:\tlearn: 0.0062673\ttotal: 10.8s\tremaining: 19.6s\n",
            "355:\tlearn: 0.0062579\ttotal: 10.8s\tremaining: 19.6s\n",
            "356:\tlearn: 0.0062456\ttotal: 10.8s\tremaining: 19.5s\n",
            "357:\tlearn: 0.0062423\ttotal: 10.9s\tremaining: 19.5s\n",
            "358:\tlearn: 0.0062374\ttotal: 10.9s\tremaining: 19.4s\n",
            "359:\tlearn: 0.0062354\ttotal: 10.9s\tremaining: 19.4s\n",
            "360:\tlearn: 0.0062331\ttotal: 10.9s\tremaining: 19.4s\n",
            "361:\tlearn: 0.0062269\ttotal: 11s\tremaining: 19.3s\n",
            "362:\tlearn: 0.0062254\ttotal: 11s\tremaining: 19.3s\n",
            "363:\tlearn: 0.0062231\ttotal: 11s\tremaining: 19.2s\n",
            "364:\tlearn: 0.0062209\ttotal: 11s\tremaining: 19.2s\n",
            "365:\tlearn: 0.0062160\ttotal: 11.1s\tremaining: 19.2s\n",
            "366:\tlearn: 0.0062106\ttotal: 11.1s\tremaining: 19.1s\n",
            "367:\tlearn: 0.0062080\ttotal: 11.1s\tremaining: 19.1s\n",
            "368:\tlearn: 0.0062048\ttotal: 11.1s\tremaining: 19s\n",
            "369:\tlearn: 0.0062019\ttotal: 11.2s\tremaining: 19s\n",
            "370:\tlearn: 0.0061954\ttotal: 11.2s\tremaining: 19s\n",
            "371:\tlearn: 0.0061869\ttotal: 11.2s\tremaining: 18.9s\n",
            "372:\tlearn: 0.0061786\ttotal: 11.2s\tremaining: 18.9s\n",
            "373:\tlearn: 0.0061743\ttotal: 11.3s\tremaining: 18.8s\n",
            "374:\tlearn: 0.0061707\ttotal: 11.3s\tremaining: 18.8s\n",
            "375:\tlearn: 0.0061629\ttotal: 11.3s\tremaining: 18.8s\n",
            "376:\tlearn: 0.0061598\ttotal: 11.3s\tremaining: 18.7s\n",
            "377:\tlearn: 0.0061445\ttotal: 11.4s\tremaining: 18.7s\n",
            "378:\tlearn: 0.0061422\ttotal: 11.4s\tremaining: 18.6s\n",
            "379:\tlearn: 0.0061387\ttotal: 11.4s\tremaining: 18.6s\n",
            "380:\tlearn: 0.0061349\ttotal: 11.4s\tremaining: 18.6s\n",
            "381:\tlearn: 0.0061289\ttotal: 11.5s\tremaining: 18.5s\n",
            "382:\tlearn: 0.0061263\ttotal: 11.5s\tremaining: 18.5s\n",
            "383:\tlearn: 0.0061195\ttotal: 11.5s\tremaining: 18.4s\n",
            "384:\tlearn: 0.0061146\ttotal: 11.5s\tremaining: 18.4s\n",
            "385:\tlearn: 0.0061124\ttotal: 11.6s\tremaining: 18.4s\n",
            "386:\tlearn: 0.0061034\ttotal: 11.6s\tremaining: 18.3s\n",
            "387:\tlearn: 0.0061007\ttotal: 11.6s\tremaining: 18.3s\n",
            "388:\tlearn: 0.0060971\ttotal: 11.6s\tremaining: 18.3s\n",
            "389:\tlearn: 0.0060936\ttotal: 11.7s\tremaining: 18.2s\n",
            "390:\tlearn: 0.0060916\ttotal: 11.7s\tremaining: 18.2s\n",
            "391:\tlearn: 0.0060893\ttotal: 11.7s\tremaining: 18.1s\n",
            "392:\tlearn: 0.0060875\ttotal: 11.7s\tremaining: 18.1s\n",
            "393:\tlearn: 0.0060859\ttotal: 11.8s\tremaining: 18.1s\n",
            "394:\tlearn: 0.0060819\ttotal: 11.8s\tremaining: 18s\n",
            "395:\tlearn: 0.0060753\ttotal: 11.8s\tremaining: 18s\n",
            "396:\tlearn: 0.0060621\ttotal: 11.8s\tremaining: 18s\n",
            "397:\tlearn: 0.0060603\ttotal: 11.8s\tremaining: 17.9s\n",
            "398:\tlearn: 0.0060576\ttotal: 11.9s\tremaining: 17.9s\n",
            "399:\tlearn: 0.0060544\ttotal: 11.9s\tremaining: 17.9s\n",
            "400:\tlearn: 0.0060511\ttotal: 11.9s\tremaining: 17.8s\n",
            "401:\tlearn: 0.0060448\ttotal: 11.9s\tremaining: 17.8s\n",
            "402:\tlearn: 0.0060426\ttotal: 12s\tremaining: 17.7s\n",
            "403:\tlearn: 0.0060409\ttotal: 12s\tremaining: 17.7s\n",
            "404:\tlearn: 0.0060362\ttotal: 12s\tremaining: 17.7s\n",
            "405:\tlearn: 0.0060338\ttotal: 12s\tremaining: 17.6s\n",
            "406:\tlearn: 0.0060292\ttotal: 12.1s\tremaining: 17.6s\n",
            "407:\tlearn: 0.0060241\ttotal: 12.1s\tremaining: 17.5s\n",
            "408:\tlearn: 0.0060195\ttotal: 12.1s\tremaining: 17.5s\n",
            "409:\tlearn: 0.0060177\ttotal: 12.1s\tremaining: 17.5s\n",
            "410:\tlearn: 0.0060144\ttotal: 12.2s\tremaining: 17.4s\n",
            "411:\tlearn: 0.0060105\ttotal: 12.2s\tremaining: 17.4s\n",
            "412:\tlearn: 0.0060093\ttotal: 12.2s\tremaining: 17.4s\n",
            "413:\tlearn: 0.0060073\ttotal: 12.2s\tremaining: 17.3s\n",
            "414:\tlearn: 0.0060033\ttotal: 12.3s\tremaining: 17.3s\n",
            "415:\tlearn: 0.0060019\ttotal: 12.3s\tremaining: 17.2s\n",
            "416:\tlearn: 0.0060006\ttotal: 12.3s\tremaining: 17.2s\n",
            "417:\tlearn: 0.0059971\ttotal: 12.3s\tremaining: 17.2s\n",
            "418:\tlearn: 0.0059945\ttotal: 12.4s\tremaining: 17.1s\n",
            "419:\tlearn: 0.0059927\ttotal: 12.4s\tremaining: 17.1s\n",
            "420:\tlearn: 0.0059905\ttotal: 12.4s\tremaining: 17.1s\n",
            "421:\tlearn: 0.0059825\ttotal: 12.4s\tremaining: 17s\n",
            "422:\tlearn: 0.0059791\ttotal: 12.4s\tremaining: 17s\n",
            "423:\tlearn: 0.0059759\ttotal: 12.5s\tremaining: 16.9s\n",
            "424:\tlearn: 0.0059740\ttotal: 12.5s\tremaining: 16.9s\n",
            "425:\tlearn: 0.0059727\ttotal: 12.5s\tremaining: 16.9s\n",
            "426:\tlearn: 0.0059721\ttotal: 12.6s\tremaining: 16.9s\n",
            "427:\tlearn: 0.0059707\ttotal: 12.6s\tremaining: 16.8s\n",
            "428:\tlearn: 0.0059655\ttotal: 12.6s\tremaining: 16.8s\n",
            "429:\tlearn: 0.0059626\ttotal: 12.6s\tremaining: 16.7s\n",
            "430:\tlearn: 0.0059538\ttotal: 12.7s\tremaining: 16.7s\n",
            "431:\tlearn: 0.0059513\ttotal: 12.7s\tremaining: 16.7s\n",
            "432:\tlearn: 0.0059499\ttotal: 12.7s\tremaining: 16.6s\n",
            "433:\tlearn: 0.0059478\ttotal: 12.7s\tremaining: 16.6s\n",
            "434:\tlearn: 0.0059452\ttotal: 12.8s\tremaining: 16.6s\n",
            "435:\tlearn: 0.0059429\ttotal: 12.8s\tremaining: 16.6s\n",
            "436:\tlearn: 0.0059395\ttotal: 12.8s\tremaining: 16.5s\n",
            "437:\tlearn: 0.0059363\ttotal: 12.9s\tremaining: 16.5s\n",
            "438:\tlearn: 0.0059291\ttotal: 12.9s\tremaining: 16.5s\n",
            "439:\tlearn: 0.0059254\ttotal: 13s\tremaining: 16.5s\n",
            "440:\tlearn: 0.0059228\ttotal: 13s\tremaining: 16.5s\n",
            "441:\tlearn: 0.0059185\ttotal: 13.1s\tremaining: 16.5s\n",
            "442:\tlearn: 0.0059165\ttotal: 13.2s\tremaining: 16.5s\n",
            "443:\tlearn: 0.0059135\ttotal: 13.2s\tremaining: 16.6s\n",
            "444:\tlearn: 0.0059114\ttotal: 13.3s\tremaining: 16.6s\n",
            "445:\tlearn: 0.0059093\ttotal: 13.3s\tremaining: 16.6s\n",
            "446:\tlearn: 0.0059069\ttotal: 13.4s\tremaining: 16.6s\n",
            "447:\tlearn: 0.0059036\ttotal: 13.5s\tremaining: 16.6s\n",
            "448:\tlearn: 0.0058999\ttotal: 13.6s\tremaining: 16.6s\n",
            "449:\tlearn: 0.0058966\ttotal: 13.6s\tremaining: 16.7s\n",
            "450:\tlearn: 0.0058916\ttotal: 13.7s\tremaining: 16.7s\n",
            "451:\tlearn: 0.0058861\ttotal: 13.8s\tremaining: 16.7s\n",
            "452:\tlearn: 0.0058835\ttotal: 13.9s\tremaining: 16.7s\n",
            "453:\tlearn: 0.0058810\ttotal: 13.9s\tremaining: 16.8s\n",
            "454:\tlearn: 0.0058792\ttotal: 14s\tremaining: 16.8s\n",
            "455:\tlearn: 0.0058741\ttotal: 14.1s\tremaining: 16.8s\n",
            "456:\tlearn: 0.0058728\ttotal: 14.2s\tremaining: 16.8s\n",
            "457:\tlearn: 0.0058691\ttotal: 14.2s\tremaining: 16.9s\n",
            "458:\tlearn: 0.0058679\ttotal: 14.3s\tremaining: 16.9s\n",
            "459:\tlearn: 0.0058651\ttotal: 14.4s\tremaining: 16.9s\n",
            "460:\tlearn: 0.0058628\ttotal: 14.5s\tremaining: 16.9s\n",
            "461:\tlearn: 0.0058538\ttotal: 14.5s\tremaining: 16.9s\n",
            "462:\tlearn: 0.0058525\ttotal: 14.6s\tremaining: 16.9s\n",
            "463:\tlearn: 0.0058410\ttotal: 14.7s\tremaining: 17s\n",
            "464:\tlearn: 0.0058385\ttotal: 14.7s\tremaining: 17s\n",
            "465:\tlearn: 0.0058314\ttotal: 14.8s\tremaining: 17s\n",
            "466:\tlearn: 0.0058304\ttotal: 14.9s\tremaining: 17s\n",
            "467:\tlearn: 0.0058223\ttotal: 15s\tremaining: 17s\n",
            "468:\tlearn: 0.0058197\ttotal: 15.1s\tremaining: 17.1s\n",
            "469:\tlearn: 0.0058161\ttotal: 15.1s\tremaining: 17.1s\n",
            "470:\tlearn: 0.0058078\ttotal: 15.2s\tremaining: 17.1s\n",
            "471:\tlearn: 0.0058017\ttotal: 15.3s\tremaining: 17.1s\n",
            "472:\tlearn: 0.0057968\ttotal: 15.4s\tremaining: 17.2s\n",
            "473:\tlearn: 0.0057916\ttotal: 15.5s\tremaining: 17.2s\n",
            "474:\tlearn: 0.0057908\ttotal: 15.5s\tremaining: 17.2s\n",
            "475:\tlearn: 0.0057882\ttotal: 15.6s\tremaining: 17.2s\n",
            "476:\tlearn: 0.0057846\ttotal: 15.7s\tremaining: 17.2s\n",
            "477:\tlearn: 0.0057819\ttotal: 15.7s\tremaining: 17.2s\n",
            "478:\tlearn: 0.0057790\ttotal: 15.8s\tremaining: 17.2s\n",
            "479:\tlearn: 0.0057775\ttotal: 15.9s\tremaining: 17.2s\n",
            "480:\tlearn: 0.0057656\ttotal: 16s\tremaining: 17.2s\n",
            "481:\tlearn: 0.0057629\ttotal: 16s\tremaining: 17.2s\n",
            "482:\tlearn: 0.0057605\ttotal: 16.1s\tremaining: 17.2s\n",
            "483:\tlearn: 0.0057586\ttotal: 16.2s\tremaining: 17.2s\n",
            "484:\tlearn: 0.0057546\ttotal: 16.3s\tremaining: 17.3s\n",
            "485:\tlearn: 0.0057535\ttotal: 16.3s\tremaining: 17.3s\n",
            "486:\tlearn: 0.0057520\ttotal: 16.4s\tremaining: 17.3s\n",
            "487:\tlearn: 0.0057510\ttotal: 16.5s\tremaining: 17.3s\n",
            "488:\tlearn: 0.0057414\ttotal: 16.5s\tremaining: 17.3s\n",
            "489:\tlearn: 0.0057401\ttotal: 16.6s\tremaining: 17.3s\n",
            "490:\tlearn: 0.0057346\ttotal: 16.7s\tremaining: 17.3s\n",
            "491:\tlearn: 0.0057292\ttotal: 16.8s\tremaining: 17.3s\n",
            "492:\tlearn: 0.0057245\ttotal: 16.8s\tremaining: 17.3s\n",
            "493:\tlearn: 0.0057231\ttotal: 16.9s\tremaining: 17.3s\n",
            "494:\tlearn: 0.0057206\ttotal: 16.9s\tremaining: 17.2s\n",
            "495:\tlearn: 0.0057180\ttotal: 16.9s\tremaining: 17.2s\n",
            "496:\tlearn: 0.0057034\ttotal: 16.9s\tremaining: 17.1s\n",
            "497:\tlearn: 0.0057014\ttotal: 17s\tremaining: 17.1s\n",
            "498:\tlearn: 0.0057005\ttotal: 17s\tremaining: 17.1s\n",
            "499:\tlearn: 0.0056916\ttotal: 17s\tremaining: 17s\n",
            "500:\tlearn: 0.0056893\ttotal: 17.1s\tremaining: 17s\n",
            "501:\tlearn: 0.0056862\ttotal: 17.1s\tremaining: 16.9s\n",
            "502:\tlearn: 0.0056846\ttotal: 17.1s\tremaining: 16.9s\n",
            "503:\tlearn: 0.0056825\ttotal: 17.1s\tremaining: 16.8s\n",
            "504:\tlearn: 0.0056809\ttotal: 17.1s\tremaining: 16.8s\n",
            "505:\tlearn: 0.0056755\ttotal: 17.2s\tremaining: 16.8s\n",
            "506:\tlearn: 0.0056719\ttotal: 17.2s\tremaining: 16.7s\n",
            "507:\tlearn: 0.0056702\ttotal: 17.2s\tremaining: 16.7s\n",
            "508:\tlearn: 0.0056694\ttotal: 17.2s\tremaining: 16.6s\n",
            "509:\tlearn: 0.0056680\ttotal: 17.3s\tremaining: 16.6s\n",
            "510:\tlearn: 0.0056656\ttotal: 17.3s\tremaining: 16.5s\n",
            "511:\tlearn: 0.0056610\ttotal: 17.3s\tremaining: 16.5s\n",
            "512:\tlearn: 0.0056598\ttotal: 17.3s\tremaining: 16.5s\n",
            "513:\tlearn: 0.0056580\ttotal: 17.4s\tremaining: 16.4s\n",
            "514:\tlearn: 0.0056569\ttotal: 17.4s\tremaining: 16.4s\n",
            "515:\tlearn: 0.0056558\ttotal: 17.4s\tremaining: 16.3s\n",
            "516:\tlearn: 0.0056543\ttotal: 17.4s\tremaining: 16.3s\n",
            "517:\tlearn: 0.0056521\ttotal: 17.5s\tremaining: 16.2s\n",
            "518:\tlearn: 0.0056514\ttotal: 17.5s\tremaining: 16.2s\n",
            "519:\tlearn: 0.0056493\ttotal: 17.5s\tremaining: 16.2s\n",
            "520:\tlearn: 0.0056399\ttotal: 17.5s\tremaining: 16.1s\n",
            "521:\tlearn: 0.0056362\ttotal: 17.6s\tremaining: 16.1s\n",
            "522:\tlearn: 0.0056342\ttotal: 17.6s\tremaining: 16s\n",
            "523:\tlearn: 0.0056330\ttotal: 17.6s\tremaining: 16s\n",
            "524:\tlearn: 0.0056313\ttotal: 17.6s\tremaining: 15.9s\n",
            "525:\tlearn: 0.0056297\ttotal: 17.7s\tremaining: 15.9s\n",
            "526:\tlearn: 0.0056272\ttotal: 17.7s\tremaining: 15.9s\n",
            "527:\tlearn: 0.0056240\ttotal: 17.7s\tremaining: 15.8s\n",
            "528:\tlearn: 0.0056209\ttotal: 17.7s\tremaining: 15.8s\n",
            "529:\tlearn: 0.0056114\ttotal: 17.7s\tremaining: 15.7s\n",
            "530:\tlearn: 0.0056088\ttotal: 17.8s\tremaining: 15.7s\n",
            "531:\tlearn: 0.0056051\ttotal: 17.8s\tremaining: 15.7s\n",
            "532:\tlearn: 0.0056019\ttotal: 17.8s\tremaining: 15.6s\n",
            "533:\tlearn: 0.0055997\ttotal: 17.8s\tremaining: 15.6s\n",
            "534:\tlearn: 0.0055986\ttotal: 17.9s\tremaining: 15.5s\n",
            "535:\tlearn: 0.0055960\ttotal: 17.9s\tremaining: 15.5s\n",
            "536:\tlearn: 0.0055910\ttotal: 17.9s\tremaining: 15.4s\n",
            "537:\tlearn: 0.0055893\ttotal: 17.9s\tremaining: 15.4s\n",
            "538:\tlearn: 0.0055873\ttotal: 18s\tremaining: 15.4s\n",
            "539:\tlearn: 0.0055851\ttotal: 18s\tremaining: 15.3s\n",
            "540:\tlearn: 0.0055811\ttotal: 18s\tremaining: 15.3s\n",
            "541:\tlearn: 0.0055789\ttotal: 18s\tremaining: 15.2s\n",
            "542:\tlearn: 0.0055762\ttotal: 18.1s\tremaining: 15.2s\n",
            "543:\tlearn: 0.0055744\ttotal: 18.1s\tremaining: 15.2s\n",
            "544:\tlearn: 0.0055730\ttotal: 18.1s\tremaining: 15.1s\n",
            "545:\tlearn: 0.0055722\ttotal: 18.1s\tremaining: 15.1s\n",
            "546:\tlearn: 0.0055683\ttotal: 18.2s\tremaining: 15s\n",
            "547:\tlearn: 0.0055571\ttotal: 18.2s\tremaining: 15s\n",
            "548:\tlearn: 0.0055533\ttotal: 18.2s\tremaining: 14.9s\n",
            "549:\tlearn: 0.0055527\ttotal: 18.2s\tremaining: 14.9s\n",
            "550:\tlearn: 0.0055494\ttotal: 18.2s\tremaining: 14.9s\n",
            "551:\tlearn: 0.0055482\ttotal: 18.3s\tremaining: 14.8s\n",
            "552:\tlearn: 0.0055472\ttotal: 18.3s\tremaining: 14.8s\n",
            "553:\tlearn: 0.0055452\ttotal: 18.3s\tremaining: 14.7s\n",
            "554:\tlearn: 0.0055439\ttotal: 18.3s\tremaining: 14.7s\n",
            "555:\tlearn: 0.0055409\ttotal: 18.4s\tremaining: 14.7s\n",
            "556:\tlearn: 0.0055381\ttotal: 18.4s\tremaining: 14.6s\n",
            "557:\tlearn: 0.0055366\ttotal: 18.4s\tremaining: 14.6s\n",
            "558:\tlearn: 0.0055354\ttotal: 18.4s\tremaining: 14.5s\n",
            "559:\tlearn: 0.0055328\ttotal: 18.5s\tremaining: 14.5s\n",
            "560:\tlearn: 0.0055295\ttotal: 18.5s\tremaining: 14.5s\n",
            "561:\tlearn: 0.0055268\ttotal: 18.5s\tremaining: 14.4s\n",
            "562:\tlearn: 0.0055262\ttotal: 18.5s\tremaining: 14.4s\n",
            "563:\tlearn: 0.0055251\ttotal: 18.6s\tremaining: 14.3s\n",
            "564:\tlearn: 0.0055217\ttotal: 18.6s\tremaining: 14.3s\n",
            "565:\tlearn: 0.0055196\ttotal: 18.6s\tremaining: 14.3s\n",
            "566:\tlearn: 0.0055183\ttotal: 18.6s\tremaining: 14.2s\n",
            "567:\tlearn: 0.0055167\ttotal: 18.6s\tremaining: 14.2s\n",
            "568:\tlearn: 0.0055151\ttotal: 18.7s\tremaining: 14.2s\n",
            "569:\tlearn: 0.0055113\ttotal: 18.7s\tremaining: 14.1s\n",
            "570:\tlearn: 0.0055091\ttotal: 18.7s\tremaining: 14.1s\n",
            "571:\tlearn: 0.0054950\ttotal: 18.8s\tremaining: 14s\n",
            "572:\tlearn: 0.0054903\ttotal: 18.8s\tremaining: 14s\n",
            "573:\tlearn: 0.0054892\ttotal: 18.8s\tremaining: 14s\n",
            "574:\tlearn: 0.0054875\ttotal: 18.8s\tremaining: 13.9s\n",
            "575:\tlearn: 0.0054808\ttotal: 18.8s\tremaining: 13.9s\n",
            "576:\tlearn: 0.0054795\ttotal: 18.9s\tremaining: 13.8s\n",
            "577:\tlearn: 0.0054766\ttotal: 18.9s\tremaining: 13.8s\n",
            "578:\tlearn: 0.0054736\ttotal: 18.9s\tremaining: 13.8s\n",
            "579:\tlearn: 0.0054725\ttotal: 18.9s\tremaining: 13.7s\n",
            "580:\tlearn: 0.0054703\ttotal: 19s\tremaining: 13.7s\n",
            "581:\tlearn: 0.0054679\ttotal: 19s\tremaining: 13.6s\n",
            "582:\tlearn: 0.0054626\ttotal: 19s\tremaining: 13.6s\n",
            "583:\tlearn: 0.0054617\ttotal: 19s\tremaining: 13.6s\n",
            "584:\tlearn: 0.0054604\ttotal: 19.1s\tremaining: 13.5s\n",
            "585:\tlearn: 0.0054591\ttotal: 19.1s\tremaining: 13.5s\n",
            "586:\tlearn: 0.0054583\ttotal: 19.1s\tremaining: 13.4s\n",
            "587:\tlearn: 0.0054565\ttotal: 19.1s\tremaining: 13.4s\n",
            "588:\tlearn: 0.0054556\ttotal: 19.2s\tremaining: 13.4s\n",
            "589:\tlearn: 0.0054545\ttotal: 19.2s\tremaining: 13.3s\n",
            "590:\tlearn: 0.0054536\ttotal: 19.2s\tremaining: 13.3s\n",
            "591:\tlearn: 0.0054519\ttotal: 19.2s\tremaining: 13.3s\n",
            "592:\tlearn: 0.0054512\ttotal: 19.3s\tremaining: 13.2s\n",
            "593:\tlearn: 0.0054502\ttotal: 19.3s\tremaining: 13.2s\n",
            "594:\tlearn: 0.0054486\ttotal: 19.3s\tremaining: 13.1s\n",
            "595:\tlearn: 0.0054452\ttotal: 19.3s\tremaining: 13.1s\n",
            "596:\tlearn: 0.0054419\ttotal: 19.4s\tremaining: 13.1s\n",
            "597:\tlearn: 0.0054399\ttotal: 19.4s\tremaining: 13s\n",
            "598:\tlearn: 0.0054372\ttotal: 19.4s\tremaining: 13s\n",
            "599:\tlearn: 0.0054359\ttotal: 19.4s\tremaining: 13s\n",
            "600:\tlearn: 0.0054342\ttotal: 19.5s\tremaining: 12.9s\n",
            "601:\tlearn: 0.0054292\ttotal: 19.5s\tremaining: 12.9s\n",
            "602:\tlearn: 0.0054274\ttotal: 19.5s\tremaining: 12.8s\n",
            "603:\tlearn: 0.0054208\ttotal: 19.5s\tremaining: 12.8s\n",
            "604:\tlearn: 0.0054193\ttotal: 19.6s\tremaining: 12.8s\n",
            "605:\tlearn: 0.0054180\ttotal: 19.6s\tremaining: 12.7s\n",
            "606:\tlearn: 0.0054167\ttotal: 19.6s\tremaining: 12.7s\n",
            "607:\tlearn: 0.0054160\ttotal: 19.6s\tremaining: 12.6s\n",
            "608:\tlearn: 0.0054147\ttotal: 19.6s\tremaining: 12.6s\n",
            "609:\tlearn: 0.0054127\ttotal: 19.7s\tremaining: 12.6s\n",
            "610:\tlearn: 0.0054117\ttotal: 19.7s\tremaining: 12.5s\n",
            "611:\tlearn: 0.0054077\ttotal: 19.7s\tremaining: 12.5s\n",
            "612:\tlearn: 0.0054028\ttotal: 19.8s\tremaining: 12.5s\n",
            "613:\tlearn: 0.0054024\ttotal: 19.8s\tremaining: 12.4s\n",
            "614:\tlearn: 0.0054015\ttotal: 19.8s\tremaining: 12.4s\n",
            "615:\tlearn: 0.0053969\ttotal: 19.8s\tremaining: 12.4s\n",
            "616:\tlearn: 0.0053949\ttotal: 19.9s\tremaining: 12.3s\n",
            "617:\tlearn: 0.0053945\ttotal: 19.9s\tremaining: 12.3s\n",
            "618:\tlearn: 0.0053915\ttotal: 19.9s\tremaining: 12.3s\n",
            "619:\tlearn: 0.0053908\ttotal: 19.9s\tremaining: 12.2s\n",
            "620:\tlearn: 0.0053894\ttotal: 19.9s\tremaining: 12.2s\n",
            "621:\tlearn: 0.0053880\ttotal: 20s\tremaining: 12.1s\n",
            "622:\tlearn: 0.0053867\ttotal: 20s\tremaining: 12.1s\n",
            "623:\tlearn: 0.0053853\ttotal: 20s\tremaining: 12.1s\n",
            "624:\tlearn: 0.0053830\ttotal: 20s\tremaining: 12s\n",
            "625:\tlearn: 0.0053819\ttotal: 20.1s\tremaining: 12s\n",
            "626:\tlearn: 0.0053791\ttotal: 20.1s\tremaining: 12s\n",
            "627:\tlearn: 0.0053763\ttotal: 20.1s\tremaining: 11.9s\n",
            "628:\tlearn: 0.0053710\ttotal: 20.1s\tremaining: 11.9s\n",
            "629:\tlearn: 0.0053687\ttotal: 20.2s\tremaining: 11.8s\n",
            "630:\tlearn: 0.0053608\ttotal: 20.2s\tremaining: 11.8s\n",
            "631:\tlearn: 0.0053591\ttotal: 20.2s\tremaining: 11.8s\n",
            "632:\tlearn: 0.0053587\ttotal: 20.2s\tremaining: 11.7s\n",
            "633:\tlearn: 0.0053583\ttotal: 20.3s\tremaining: 11.7s\n",
            "634:\tlearn: 0.0053569\ttotal: 20.3s\tremaining: 11.7s\n",
            "635:\tlearn: 0.0053499\ttotal: 20.3s\tremaining: 11.6s\n",
            "636:\tlearn: 0.0053482\ttotal: 20.3s\tremaining: 11.6s\n",
            "637:\tlearn: 0.0053454\ttotal: 20.4s\tremaining: 11.6s\n",
            "638:\tlearn: 0.0053437\ttotal: 20.4s\tremaining: 11.5s\n",
            "639:\tlearn: 0.0053430\ttotal: 20.4s\tremaining: 11.5s\n",
            "640:\tlearn: 0.0053421\ttotal: 20.4s\tremaining: 11.4s\n",
            "641:\tlearn: 0.0053388\ttotal: 20.5s\tremaining: 11.4s\n",
            "642:\tlearn: 0.0053333\ttotal: 20.5s\tremaining: 11.4s\n",
            "643:\tlearn: 0.0053323\ttotal: 20.5s\tremaining: 11.3s\n",
            "644:\tlearn: 0.0053318\ttotal: 20.5s\tremaining: 11.3s\n",
            "645:\tlearn: 0.0053287\ttotal: 20.6s\tremaining: 11.3s\n",
            "646:\tlearn: 0.0053262\ttotal: 20.6s\tremaining: 11.2s\n",
            "647:\tlearn: 0.0053231\ttotal: 20.6s\tremaining: 11.2s\n",
            "648:\tlearn: 0.0053216\ttotal: 20.6s\tremaining: 11.2s\n",
            "649:\tlearn: 0.0053144\ttotal: 20.7s\tremaining: 11.1s\n",
            "650:\tlearn: 0.0053126\ttotal: 20.7s\tremaining: 11.1s\n",
            "651:\tlearn: 0.0053109\ttotal: 20.7s\tremaining: 11.1s\n",
            "652:\tlearn: 0.0053091\ttotal: 20.7s\tremaining: 11s\n",
            "653:\tlearn: 0.0053069\ttotal: 20.8s\tremaining: 11s\n",
            "654:\tlearn: 0.0053013\ttotal: 20.8s\tremaining: 10.9s\n",
            "655:\tlearn: 0.0052997\ttotal: 20.8s\tremaining: 10.9s\n",
            "656:\tlearn: 0.0052972\ttotal: 20.8s\tremaining: 10.9s\n",
            "657:\tlearn: 0.0052947\ttotal: 20.9s\tremaining: 10.8s\n",
            "658:\tlearn: 0.0052894\ttotal: 20.9s\tremaining: 10.8s\n",
            "659:\tlearn: 0.0052883\ttotal: 20.9s\tremaining: 10.8s\n",
            "660:\tlearn: 0.0052870\ttotal: 20.9s\tremaining: 10.7s\n",
            "661:\tlearn: 0.0052864\ttotal: 21s\tremaining: 10.7s\n",
            "662:\tlearn: 0.0052853\ttotal: 21s\tremaining: 10.7s\n",
            "663:\tlearn: 0.0052829\ttotal: 21s\tremaining: 10.6s\n",
            "664:\tlearn: 0.0052810\ttotal: 21s\tremaining: 10.6s\n",
            "665:\tlearn: 0.0052784\ttotal: 21.1s\tremaining: 10.6s\n",
            "666:\tlearn: 0.0052771\ttotal: 21.1s\tremaining: 10.5s\n",
            "667:\tlearn: 0.0052762\ttotal: 21.1s\tremaining: 10.5s\n",
            "668:\tlearn: 0.0052753\ttotal: 21.1s\tremaining: 10.5s\n",
            "669:\tlearn: 0.0052736\ttotal: 21.2s\tremaining: 10.4s\n",
            "670:\tlearn: 0.0052726\ttotal: 21.2s\tremaining: 10.4s\n",
            "671:\tlearn: 0.0052722\ttotal: 21.2s\tremaining: 10.3s\n",
            "672:\tlearn: 0.0052714\ttotal: 21.2s\tremaining: 10.3s\n",
            "673:\tlearn: 0.0052639\ttotal: 21.3s\tremaining: 10.3s\n",
            "674:\tlearn: 0.0052620\ttotal: 21.3s\tremaining: 10.2s\n",
            "675:\tlearn: 0.0052604\ttotal: 21.3s\tremaining: 10.2s\n",
            "676:\tlearn: 0.0052561\ttotal: 21.3s\tremaining: 10.2s\n",
            "677:\tlearn: 0.0052557\ttotal: 21.4s\tremaining: 10.1s\n",
            "678:\tlearn: 0.0052533\ttotal: 21.4s\tremaining: 10.1s\n",
            "679:\tlearn: 0.0052470\ttotal: 21.4s\tremaining: 10.1s\n",
            "680:\tlearn: 0.0052457\ttotal: 21.4s\tremaining: 10s\n",
            "681:\tlearn: 0.0052445\ttotal: 21.5s\tremaining: 10s\n",
            "682:\tlearn: 0.0052423\ttotal: 21.5s\tremaining: 9.97s\n",
            "683:\tlearn: 0.0052417\ttotal: 21.5s\tremaining: 9.93s\n",
            "684:\tlearn: 0.0052380\ttotal: 21.5s\tremaining: 9.9s\n",
            "685:\tlearn: 0.0052352\ttotal: 21.5s\tremaining: 9.86s\n",
            "686:\tlearn: 0.0052343\ttotal: 21.6s\tremaining: 9.83s\n",
            "687:\tlearn: 0.0052331\ttotal: 21.6s\tremaining: 9.79s\n",
            "688:\tlearn: 0.0052315\ttotal: 21.6s\tremaining: 9.76s\n",
            "689:\tlearn: 0.0052306\ttotal: 21.6s\tremaining: 9.72s\n",
            "690:\tlearn: 0.0052295\ttotal: 21.7s\tremaining: 9.69s\n",
            "691:\tlearn: 0.0052282\ttotal: 21.7s\tremaining: 9.66s\n",
            "692:\tlearn: 0.0052273\ttotal: 21.7s\tremaining: 9.62s\n",
            "693:\tlearn: 0.0052265\ttotal: 21.7s\tremaining: 9.59s\n",
            "694:\tlearn: 0.0052256\ttotal: 21.8s\tremaining: 9.55s\n",
            "695:\tlearn: 0.0052235\ttotal: 21.8s\tremaining: 9.52s\n",
            "696:\tlearn: 0.0052208\ttotal: 21.8s\tremaining: 9.48s\n",
            "697:\tlearn: 0.0052202\ttotal: 21.8s\tremaining: 9.45s\n",
            "698:\tlearn: 0.0052197\ttotal: 21.9s\tremaining: 9.41s\n",
            "699:\tlearn: 0.0052188\ttotal: 21.9s\tremaining: 9.38s\n",
            "700:\tlearn: 0.0052183\ttotal: 21.9s\tremaining: 9.34s\n",
            "701:\tlearn: 0.0052164\ttotal: 21.9s\tremaining: 9.31s\n",
            "702:\tlearn: 0.0052149\ttotal: 22s\tremaining: 9.27s\n",
            "703:\tlearn: 0.0052139\ttotal: 22s\tremaining: 9.24s\n",
            "704:\tlearn: 0.0052118\ttotal: 22s\tremaining: 9.21s\n",
            "705:\tlearn: 0.0052112\ttotal: 22s\tremaining: 9.18s\n",
            "706:\tlearn: 0.0052090\ttotal: 22.1s\tremaining: 9.14s\n",
            "707:\tlearn: 0.0052074\ttotal: 22.1s\tremaining: 9.11s\n",
            "708:\tlearn: 0.0052053\ttotal: 22.1s\tremaining: 9.07s\n",
            "709:\tlearn: 0.0052038\ttotal: 22.1s\tremaining: 9.04s\n",
            "710:\tlearn: 0.0052022\ttotal: 22.2s\tremaining: 9s\n",
            "711:\tlearn: 0.0052013\ttotal: 22.2s\tremaining: 8.97s\n",
            "712:\tlearn: 0.0051998\ttotal: 22.2s\tremaining: 8.94s\n",
            "713:\tlearn: 0.0051982\ttotal: 22.2s\tremaining: 8.9s\n",
            "714:\tlearn: 0.0051964\ttotal: 22.3s\tremaining: 8.87s\n",
            "715:\tlearn: 0.0051958\ttotal: 22.3s\tremaining: 8.83s\n",
            "716:\tlearn: 0.0051947\ttotal: 22.3s\tremaining: 8.8s\n",
            "717:\tlearn: 0.0051923\ttotal: 22.3s\tremaining: 8.77s\n",
            "718:\tlearn: 0.0051919\ttotal: 22.3s\tremaining: 8.73s\n",
            "719:\tlearn: 0.0051900\ttotal: 22.4s\tremaining: 8.7s\n",
            "720:\tlearn: 0.0051868\ttotal: 22.4s\tremaining: 8.67s\n",
            "721:\tlearn: 0.0051849\ttotal: 22.4s\tremaining: 8.63s\n",
            "722:\tlearn: 0.0051826\ttotal: 22.4s\tremaining: 8.6s\n",
            "723:\tlearn: 0.0051789\ttotal: 22.5s\tremaining: 8.57s\n",
            "724:\tlearn: 0.0051785\ttotal: 22.5s\tremaining: 8.53s\n",
            "725:\tlearn: 0.0051777\ttotal: 22.5s\tremaining: 8.5s\n",
            "726:\tlearn: 0.0051769\ttotal: 22.5s\tremaining: 8.46s\n",
            "727:\tlearn: 0.0051748\ttotal: 22.6s\tremaining: 8.43s\n",
            "728:\tlearn: 0.0051744\ttotal: 22.6s\tremaining: 8.39s\n",
            "729:\tlearn: 0.0051737\ttotal: 22.6s\tremaining: 8.36s\n",
            "730:\tlearn: 0.0051721\ttotal: 22.6s\tremaining: 8.33s\n",
            "731:\tlearn: 0.0051708\ttotal: 22.7s\tremaining: 8.29s\n",
            "732:\tlearn: 0.0051692\ttotal: 22.7s\tremaining: 8.26s\n",
            "733:\tlearn: 0.0051682\ttotal: 22.7s\tremaining: 8.23s\n",
            "734:\tlearn: 0.0051667\ttotal: 22.7s\tremaining: 8.2s\n",
            "735:\tlearn: 0.0051661\ttotal: 22.8s\tremaining: 8.16s\n",
            "736:\tlearn: 0.0051655\ttotal: 22.8s\tremaining: 8.13s\n",
            "737:\tlearn: 0.0051653\ttotal: 22.8s\tremaining: 8.1s\n",
            "738:\tlearn: 0.0051642\ttotal: 22.8s\tremaining: 8.06s\n",
            "739:\tlearn: 0.0051634\ttotal: 22.9s\tremaining: 8.03s\n",
            "740:\tlearn: 0.0051620\ttotal: 22.9s\tremaining: 8s\n",
            "741:\tlearn: 0.0051612\ttotal: 22.9s\tremaining: 7.97s\n",
            "742:\tlearn: 0.0051593\ttotal: 22.9s\tremaining: 7.93s\n",
            "743:\tlearn: 0.0051580\ttotal: 23s\tremaining: 7.9s\n",
            "744:\tlearn: 0.0051570\ttotal: 23s\tremaining: 7.87s\n",
            "745:\tlearn: 0.0051499\ttotal: 23s\tremaining: 7.83s\n",
            "746:\tlearn: 0.0051491\ttotal: 23s\tremaining: 7.8s\n",
            "747:\tlearn: 0.0051485\ttotal: 23.1s\tremaining: 7.77s\n",
            "748:\tlearn: 0.0051476\ttotal: 23.1s\tremaining: 7.74s\n",
            "749:\tlearn: 0.0051442\ttotal: 23.1s\tremaining: 7.7s\n",
            "750:\tlearn: 0.0051439\ttotal: 23.1s\tremaining: 7.67s\n",
            "751:\tlearn: 0.0051432\ttotal: 23.2s\tremaining: 7.64s\n",
            "752:\tlearn: 0.0051429\ttotal: 23.2s\tremaining: 7.6s\n",
            "753:\tlearn: 0.0051419\ttotal: 23.2s\tremaining: 7.57s\n",
            "754:\tlearn: 0.0051406\ttotal: 23.2s\tremaining: 7.54s\n",
            "755:\tlearn: 0.0051397\ttotal: 23.3s\tremaining: 7.5s\n",
            "756:\tlearn: 0.0051390\ttotal: 23.3s\tremaining: 7.47s\n",
            "757:\tlearn: 0.0051361\ttotal: 23.3s\tremaining: 7.44s\n",
            "758:\tlearn: 0.0051344\ttotal: 23.3s\tremaining: 7.41s\n",
            "759:\tlearn: 0.0051335\ttotal: 23.3s\tremaining: 7.37s\n",
            "760:\tlearn: 0.0051324\ttotal: 23.4s\tremaining: 7.34s\n",
            "761:\tlearn: 0.0051307\ttotal: 23.4s\tremaining: 7.31s\n",
            "762:\tlearn: 0.0051268\ttotal: 23.4s\tremaining: 7.27s\n",
            "763:\tlearn: 0.0051253\ttotal: 23.4s\tremaining: 7.24s\n",
            "764:\tlearn: 0.0051251\ttotal: 23.5s\tremaining: 7.21s\n",
            "765:\tlearn: 0.0051217\ttotal: 23.5s\tremaining: 7.18s\n",
            "766:\tlearn: 0.0051207\ttotal: 23.5s\tremaining: 7.14s\n",
            "767:\tlearn: 0.0051186\ttotal: 23.5s\tremaining: 7.11s\n",
            "768:\tlearn: 0.0051152\ttotal: 23.6s\tremaining: 7.08s\n",
            "769:\tlearn: 0.0051147\ttotal: 23.6s\tremaining: 7.05s\n",
            "770:\tlearn: 0.0051129\ttotal: 23.6s\tremaining: 7.01s\n",
            "771:\tlearn: 0.0051117\ttotal: 23.6s\tremaining: 6.98s\n",
            "772:\tlearn: 0.0051107\ttotal: 23.7s\tremaining: 6.95s\n",
            "773:\tlearn: 0.0051075\ttotal: 23.7s\tremaining: 6.91s\n",
            "774:\tlearn: 0.0051063\ttotal: 23.7s\tremaining: 6.88s\n",
            "775:\tlearn: 0.0051010\ttotal: 23.7s\tremaining: 6.85s\n",
            "776:\tlearn: 0.0050990\ttotal: 23.8s\tremaining: 6.82s\n",
            "777:\tlearn: 0.0050985\ttotal: 23.8s\tremaining: 6.79s\n",
            "778:\tlearn: 0.0050971\ttotal: 23.8s\tremaining: 6.75s\n",
            "779:\tlearn: 0.0050963\ttotal: 23.8s\tremaining: 6.72s\n",
            "780:\tlearn: 0.0050942\ttotal: 23.9s\tremaining: 6.69s\n",
            "781:\tlearn: 0.0050928\ttotal: 23.9s\tremaining: 6.66s\n",
            "782:\tlearn: 0.0050923\ttotal: 23.9s\tremaining: 6.63s\n",
            "783:\tlearn: 0.0050910\ttotal: 23.9s\tremaining: 6.6s\n",
            "784:\tlearn: 0.0050896\ttotal: 24s\tremaining: 6.57s\n",
            "785:\tlearn: 0.0050889\ttotal: 24s\tremaining: 6.53s\n",
            "786:\tlearn: 0.0050880\ttotal: 24s\tremaining: 6.5s\n",
            "787:\tlearn: 0.0050866\ttotal: 24s\tremaining: 6.47s\n",
            "788:\tlearn: 0.0050842\ttotal: 24.1s\tremaining: 6.43s\n",
            "789:\tlearn: 0.0050834\ttotal: 24.1s\tremaining: 6.4s\n",
            "790:\tlearn: 0.0050829\ttotal: 24.1s\tremaining: 6.37s\n",
            "791:\tlearn: 0.0050811\ttotal: 24.1s\tremaining: 6.34s\n",
            "792:\tlearn: 0.0050794\ttotal: 24.2s\tremaining: 6.31s\n",
            "793:\tlearn: 0.0050782\ttotal: 24.2s\tremaining: 6.27s\n",
            "794:\tlearn: 0.0050762\ttotal: 24.2s\tremaining: 6.24s\n",
            "795:\tlearn: 0.0050741\ttotal: 24.2s\tremaining: 6.21s\n",
            "796:\tlearn: 0.0050693\ttotal: 24.3s\tremaining: 6.18s\n",
            "797:\tlearn: 0.0050683\ttotal: 24.3s\tremaining: 6.14s\n",
            "798:\tlearn: 0.0050674\ttotal: 24.3s\tremaining: 6.11s\n",
            "799:\tlearn: 0.0050647\ttotal: 24.3s\tremaining: 6.08s\n",
            "800:\tlearn: 0.0050642\ttotal: 24.3s\tremaining: 6.05s\n",
            "801:\tlearn: 0.0050627\ttotal: 24.4s\tremaining: 6.02s\n",
            "802:\tlearn: 0.0050618\ttotal: 24.4s\tremaining: 5.99s\n",
            "803:\tlearn: 0.0050610\ttotal: 24.4s\tremaining: 5.95s\n",
            "804:\tlearn: 0.0050606\ttotal: 24.4s\tremaining: 5.92s\n",
            "805:\tlearn: 0.0050593\ttotal: 24.5s\tremaining: 5.89s\n",
            "806:\tlearn: 0.0050575\ttotal: 24.5s\tremaining: 5.86s\n",
            "807:\tlearn: 0.0050566\ttotal: 24.5s\tremaining: 5.83s\n",
            "808:\tlearn: 0.0050559\ttotal: 24.5s\tremaining: 5.79s\n",
            "809:\tlearn: 0.0050543\ttotal: 24.6s\tremaining: 5.76s\n",
            "810:\tlearn: 0.0050521\ttotal: 24.6s\tremaining: 5.73s\n",
            "811:\tlearn: 0.0050503\ttotal: 24.6s\tremaining: 5.7s\n",
            "812:\tlearn: 0.0050488\ttotal: 24.6s\tremaining: 5.67s\n",
            "813:\tlearn: 0.0050483\ttotal: 24.7s\tremaining: 5.64s\n",
            "814:\tlearn: 0.0050414\ttotal: 24.7s\tremaining: 5.6s\n",
            "815:\tlearn: 0.0050399\ttotal: 24.7s\tremaining: 5.58s\n",
            "816:\tlearn: 0.0050374\ttotal: 24.7s\tremaining: 5.54s\n",
            "817:\tlearn: 0.0050365\ttotal: 24.8s\tremaining: 5.51s\n",
            "818:\tlearn: 0.0050332\ttotal: 24.8s\tremaining: 5.48s\n",
            "819:\tlearn: 0.0050314\ttotal: 24.8s\tremaining: 5.45s\n",
            "820:\tlearn: 0.0050280\ttotal: 24.9s\tremaining: 5.42s\n",
            "821:\tlearn: 0.0050264\ttotal: 24.9s\tremaining: 5.39s\n",
            "822:\tlearn: 0.0050254\ttotal: 24.9s\tremaining: 5.36s\n",
            "823:\tlearn: 0.0050243\ttotal: 24.9s\tremaining: 5.33s\n",
            "824:\tlearn: 0.0050234\ttotal: 25s\tremaining: 5.29s\n",
            "825:\tlearn: 0.0050209\ttotal: 25s\tremaining: 5.26s\n",
            "826:\tlearn: 0.0050202\ttotal: 25s\tremaining: 5.23s\n",
            "827:\tlearn: 0.0050186\ttotal: 25s\tremaining: 5.2s\n",
            "828:\tlearn: 0.0050179\ttotal: 25.1s\tremaining: 5.17s\n",
            "829:\tlearn: 0.0050166\ttotal: 25.1s\tremaining: 5.14s\n",
            "830:\tlearn: 0.0050128\ttotal: 25.1s\tremaining: 5.11s\n",
            "831:\tlearn: 0.0050124\ttotal: 25.1s\tremaining: 5.07s\n",
            "832:\tlearn: 0.0050110\ttotal: 25.2s\tremaining: 5.04s\n",
            "833:\tlearn: 0.0050101\ttotal: 25.2s\tremaining: 5.01s\n",
            "834:\tlearn: 0.0050087\ttotal: 25.2s\tremaining: 4.98s\n",
            "835:\tlearn: 0.0050079\ttotal: 25.2s\tremaining: 4.95s\n",
            "836:\tlearn: 0.0050074\ttotal: 25.3s\tremaining: 4.92s\n",
            "837:\tlearn: 0.0050065\ttotal: 25.3s\tremaining: 4.89s\n",
            "838:\tlearn: 0.0050054\ttotal: 25.3s\tremaining: 4.86s\n",
            "839:\tlearn: 0.0049999\ttotal: 25.3s\tremaining: 4.83s\n",
            "840:\tlearn: 0.0049996\ttotal: 25.4s\tremaining: 4.79s\n",
            "841:\tlearn: 0.0049993\ttotal: 25.4s\tremaining: 4.76s\n",
            "842:\tlearn: 0.0049984\ttotal: 25.4s\tremaining: 4.73s\n",
            "843:\tlearn: 0.0049975\ttotal: 25.4s\tremaining: 4.7s\n",
            "844:\tlearn: 0.0049958\ttotal: 25.5s\tremaining: 4.67s\n",
            "845:\tlearn: 0.0049940\ttotal: 25.5s\tremaining: 4.64s\n",
            "846:\tlearn: 0.0049920\ttotal: 25.5s\tremaining: 4.61s\n",
            "847:\tlearn: 0.0049901\ttotal: 25.5s\tremaining: 4.58s\n",
            "848:\tlearn: 0.0049887\ttotal: 25.5s\tremaining: 4.54s\n",
            "849:\tlearn: 0.0049881\ttotal: 25.6s\tremaining: 4.51s\n",
            "850:\tlearn: 0.0049874\ttotal: 25.6s\tremaining: 4.48s\n",
            "851:\tlearn: 0.0049871\ttotal: 25.6s\tremaining: 4.45s\n",
            "852:\tlearn: 0.0049863\ttotal: 25.6s\tremaining: 4.42s\n",
            "853:\tlearn: 0.0049857\ttotal: 25.7s\tremaining: 4.39s\n",
            "854:\tlearn: 0.0049852\ttotal: 25.7s\tremaining: 4.36s\n",
            "855:\tlearn: 0.0049845\ttotal: 25.7s\tremaining: 4.33s\n",
            "856:\tlearn: 0.0049836\ttotal: 25.8s\tremaining: 4.3s\n",
            "857:\tlearn: 0.0049824\ttotal: 25.8s\tremaining: 4.27s\n",
            "858:\tlearn: 0.0049801\ttotal: 25.8s\tremaining: 4.24s\n",
            "859:\tlearn: 0.0049787\ttotal: 25.8s\tremaining: 4.2s\n",
            "860:\tlearn: 0.0049783\ttotal: 25.8s\tremaining: 4.17s\n",
            "861:\tlearn: 0.0049767\ttotal: 25.9s\tremaining: 4.14s\n",
            "862:\tlearn: 0.0049759\ttotal: 25.9s\tremaining: 4.11s\n",
            "863:\tlearn: 0.0049746\ttotal: 25.9s\tremaining: 4.08s\n",
            "864:\tlearn: 0.0049737\ttotal: 25.9s\tremaining: 4.05s\n",
            "865:\tlearn: 0.0049708\ttotal: 26s\tremaining: 4.02s\n",
            "866:\tlearn: 0.0049698\ttotal: 26s\tremaining: 3.99s\n",
            "867:\tlearn: 0.0049693\ttotal: 26s\tremaining: 3.96s\n",
            "868:\tlearn: 0.0049689\ttotal: 26s\tremaining: 3.93s\n",
            "869:\tlearn: 0.0049684\ttotal: 26.1s\tremaining: 3.89s\n",
            "870:\tlearn: 0.0049675\ttotal: 26.1s\tremaining: 3.86s\n",
            "871:\tlearn: 0.0049668\ttotal: 26.1s\tremaining: 3.83s\n",
            "872:\tlearn: 0.0049650\ttotal: 26.1s\tremaining: 3.8s\n",
            "873:\tlearn: 0.0049629\ttotal: 26.2s\tremaining: 3.77s\n",
            "874:\tlearn: 0.0049622\ttotal: 26.2s\tremaining: 3.74s\n",
            "875:\tlearn: 0.0049618\ttotal: 26.2s\tremaining: 3.71s\n",
            "876:\tlearn: 0.0049607\ttotal: 26.2s\tremaining: 3.68s\n",
            "877:\tlearn: 0.0049595\ttotal: 26.3s\tremaining: 3.65s\n",
            "878:\tlearn: 0.0049563\ttotal: 26.3s\tremaining: 3.62s\n",
            "879:\tlearn: 0.0049559\ttotal: 26.3s\tremaining: 3.59s\n",
            "880:\tlearn: 0.0049551\ttotal: 26.3s\tremaining: 3.56s\n",
            "881:\tlearn: 0.0049534\ttotal: 26.4s\tremaining: 3.53s\n",
            "882:\tlearn: 0.0049523\ttotal: 26.4s\tremaining: 3.5s\n",
            "883:\tlearn: 0.0049507\ttotal: 26.4s\tremaining: 3.46s\n",
            "884:\tlearn: 0.0049490\ttotal: 26.4s\tremaining: 3.43s\n",
            "885:\tlearn: 0.0049479\ttotal: 26.5s\tremaining: 3.4s\n",
            "886:\tlearn: 0.0049470\ttotal: 26.5s\tremaining: 3.37s\n",
            "887:\tlearn: 0.0049461\ttotal: 26.5s\tremaining: 3.34s\n",
            "888:\tlearn: 0.0049454\ttotal: 26.5s\tremaining: 3.31s\n",
            "889:\tlearn: 0.0049448\ttotal: 26.6s\tremaining: 3.28s\n",
            "890:\tlearn: 0.0049440\ttotal: 26.6s\tremaining: 3.25s\n",
            "891:\tlearn: 0.0049429\ttotal: 26.6s\tremaining: 3.22s\n",
            "892:\tlearn: 0.0049414\ttotal: 26.6s\tremaining: 3.19s\n",
            "893:\tlearn: 0.0049403\ttotal: 26.6s\tremaining: 3.16s\n",
            "894:\tlearn: 0.0049347\ttotal: 26.7s\tremaining: 3.13s\n",
            "895:\tlearn: 0.0049337\ttotal: 26.7s\tremaining: 3.1s\n",
            "896:\tlearn: 0.0049326\ttotal: 26.8s\tremaining: 3.08s\n",
            "897:\tlearn: 0.0049318\ttotal: 26.8s\tremaining: 3.04s\n",
            "898:\tlearn: 0.0049308\ttotal: 26.8s\tremaining: 3.02s\n",
            "899:\tlearn: 0.0049300\ttotal: 26.9s\tremaining: 2.99s\n",
            "900:\tlearn: 0.0049294\ttotal: 26.9s\tremaining: 2.96s\n",
            "901:\tlearn: 0.0049238\ttotal: 27s\tremaining: 2.93s\n",
            "902:\tlearn: 0.0049226\ttotal: 27s\tremaining: 2.9s\n",
            "903:\tlearn: 0.0049220\ttotal: 27.1s\tremaining: 2.87s\n",
            "904:\tlearn: 0.0049207\ttotal: 27.1s\tremaining: 2.85s\n",
            "905:\tlearn: 0.0049201\ttotal: 27.2s\tremaining: 2.82s\n",
            "906:\tlearn: 0.0049184\ttotal: 27.2s\tremaining: 2.79s\n",
            "907:\tlearn: 0.0049166\ttotal: 27.3s\tremaining: 2.77s\n",
            "908:\tlearn: 0.0049136\ttotal: 27.4s\tremaining: 2.74s\n",
            "909:\tlearn: 0.0049125\ttotal: 27.4s\tremaining: 2.71s\n",
            "910:\tlearn: 0.0049093\ttotal: 27.5s\tremaining: 2.68s\n",
            "911:\tlearn: 0.0049082\ttotal: 27.5s\tremaining: 2.66s\n",
            "912:\tlearn: 0.0049076\ttotal: 27.6s\tremaining: 2.63s\n",
            "913:\tlearn: 0.0049070\ttotal: 27.7s\tremaining: 2.6s\n",
            "914:\tlearn: 0.0049063\ttotal: 27.7s\tremaining: 2.58s\n",
            "915:\tlearn: 0.0049056\ttotal: 27.8s\tremaining: 2.55s\n",
            "916:\tlearn: 0.0049053\ttotal: 27.8s\tremaining: 2.52s\n",
            "917:\tlearn: 0.0048989\ttotal: 27.8s\tremaining: 2.49s\n",
            "918:\tlearn: 0.0048987\ttotal: 27.9s\tremaining: 2.46s\n",
            "919:\tlearn: 0.0048975\ttotal: 27.9s\tremaining: 2.43s\n",
            "920:\tlearn: 0.0048950\ttotal: 28s\tremaining: 2.4s\n",
            "921:\tlearn: 0.0048943\ttotal: 28.1s\tremaining: 2.37s\n",
            "922:\tlearn: 0.0048933\ttotal: 28.1s\tremaining: 2.35s\n",
            "923:\tlearn: 0.0048929\ttotal: 28.2s\tremaining: 2.32s\n",
            "924:\tlearn: 0.0048921\ttotal: 28.3s\tremaining: 2.29s\n",
            "925:\tlearn: 0.0048918\ttotal: 28.3s\tremaining: 2.26s\n",
            "926:\tlearn: 0.0048915\ttotal: 28.4s\tremaining: 2.23s\n",
            "927:\tlearn: 0.0048911\ttotal: 28.4s\tremaining: 2.21s\n",
            "928:\tlearn: 0.0048895\ttotal: 28.5s\tremaining: 2.18s\n",
            "929:\tlearn: 0.0048885\ttotal: 28.6s\tremaining: 2.15s\n",
            "930:\tlearn: 0.0048866\ttotal: 28.6s\tremaining: 2.12s\n",
            "931:\tlearn: 0.0048855\ttotal: 28.7s\tremaining: 2.09s\n",
            "932:\tlearn: 0.0048841\ttotal: 28.8s\tremaining: 2.06s\n",
            "933:\tlearn: 0.0048820\ttotal: 28.8s\tremaining: 2.04s\n",
            "934:\tlearn: 0.0048810\ttotal: 28.9s\tremaining: 2.01s\n",
            "935:\tlearn: 0.0048797\ttotal: 29s\tremaining: 1.98s\n",
            "936:\tlearn: 0.0048793\ttotal: 29s\tremaining: 1.95s\n",
            "937:\tlearn: 0.0048790\ttotal: 29.1s\tremaining: 1.92s\n",
            "938:\tlearn: 0.0048753\ttotal: 29.2s\tremaining: 1.9s\n",
            "939:\tlearn: 0.0048748\ttotal: 29.2s\tremaining: 1.87s\n",
            "940:\tlearn: 0.0048742\ttotal: 29.3s\tremaining: 1.84s\n",
            "941:\tlearn: 0.0048714\ttotal: 29.4s\tremaining: 1.81s\n",
            "942:\tlearn: 0.0048704\ttotal: 29.4s\tremaining: 1.78s\n",
            "943:\tlearn: 0.0048693\ttotal: 29.5s\tremaining: 1.75s\n",
            "944:\tlearn: 0.0048672\ttotal: 29.6s\tremaining: 1.72s\n",
            "945:\tlearn: 0.0048668\ttotal: 29.6s\tremaining: 1.69s\n",
            "946:\tlearn: 0.0048617\ttotal: 29.7s\tremaining: 1.66s\n",
            "947:\tlearn: 0.0048605\ttotal: 29.8s\tremaining: 1.63s\n",
            "948:\tlearn: 0.0048596\ttotal: 29.8s\tremaining: 1.6s\n",
            "949:\tlearn: 0.0048586\ttotal: 29.9s\tremaining: 1.57s\n",
            "950:\tlearn: 0.0048554\ttotal: 30s\tremaining: 1.54s\n",
            "951:\tlearn: 0.0048544\ttotal: 30s\tremaining: 1.51s\n",
            "952:\tlearn: 0.0048475\ttotal: 30.1s\tremaining: 1.48s\n",
            "953:\tlearn: 0.0048469\ttotal: 30.2s\tremaining: 1.45s\n",
            "954:\tlearn: 0.0048467\ttotal: 30.2s\tremaining: 1.42s\n",
            "955:\tlearn: 0.0048461\ttotal: 30.3s\tremaining: 1.39s\n",
            "956:\tlearn: 0.0048448\ttotal: 30.4s\tremaining: 1.36s\n",
            "957:\tlearn: 0.0048431\ttotal: 30.4s\tremaining: 1.33s\n",
            "958:\tlearn: 0.0048415\ttotal: 30.5s\tremaining: 1.3s\n",
            "959:\tlearn: 0.0048402\ttotal: 30.6s\tremaining: 1.27s\n",
            "960:\tlearn: 0.0048392\ttotal: 30.6s\tremaining: 1.24s\n",
            "961:\tlearn: 0.0048374\ttotal: 30.7s\tremaining: 1.21s\n",
            "962:\tlearn: 0.0048366\ttotal: 30.7s\tremaining: 1.18s\n",
            "963:\tlearn: 0.0048331\ttotal: 30.7s\tremaining: 1.15s\n",
            "964:\tlearn: 0.0048321\ttotal: 30.8s\tremaining: 1.11s\n",
            "965:\tlearn: 0.0048307\ttotal: 30.8s\tremaining: 1.08s\n",
            "966:\tlearn: 0.0048291\ttotal: 30.8s\tremaining: 1.05s\n",
            "967:\tlearn: 0.0048289\ttotal: 30.8s\tremaining: 1.02s\n",
            "968:\tlearn: 0.0048285\ttotal: 30.9s\tremaining: 988ms\n",
            "969:\tlearn: 0.0048276\ttotal: 30.9s\tremaining: 956ms\n",
            "970:\tlearn: 0.0048274\ttotal: 30.9s\tremaining: 924ms\n",
            "971:\tlearn: 0.0048268\ttotal: 31s\tremaining: 892ms\n",
            "972:\tlearn: 0.0048252\ttotal: 31s\tremaining: 860ms\n",
            "973:\tlearn: 0.0048244\ttotal: 31s\tremaining: 828ms\n",
            "974:\tlearn: 0.0048240\ttotal: 31s\tremaining: 795ms\n",
            "975:\tlearn: 0.0048219\ttotal: 31s\tremaining: 763ms\n",
            "976:\tlearn: 0.0048206\ttotal: 31.1s\tremaining: 731ms\n",
            "977:\tlearn: 0.0048200\ttotal: 31.1s\tremaining: 699ms\n",
            "978:\tlearn: 0.0048197\ttotal: 31.1s\tremaining: 667ms\n",
            "979:\tlearn: 0.0048185\ttotal: 31.1s\tremaining: 636ms\n",
            "980:\tlearn: 0.0048177\ttotal: 31.2s\tremaining: 604ms\n",
            "981:\tlearn: 0.0048167\ttotal: 31.2s\tremaining: 572ms\n",
            "982:\tlearn: 0.0048160\ttotal: 31.2s\tremaining: 540ms\n",
            "983:\tlearn: 0.0048156\ttotal: 31.2s\tremaining: 508ms\n",
            "984:\tlearn: 0.0048150\ttotal: 31.3s\tremaining: 476ms\n",
            "985:\tlearn: 0.0048134\ttotal: 31.3s\tremaining: 444ms\n",
            "986:\tlearn: 0.0048124\ttotal: 31.3s\tremaining: 412ms\n",
            "987:\tlearn: 0.0048121\ttotal: 31.3s\tremaining: 381ms\n",
            "988:\tlearn: 0.0048109\ttotal: 31.4s\tremaining: 349ms\n",
            "989:\tlearn: 0.0048106\ttotal: 31.4s\tremaining: 317ms\n",
            "990:\tlearn: 0.0048101\ttotal: 31.4s\tremaining: 285ms\n",
            "991:\tlearn: 0.0048085\ttotal: 31.4s\tremaining: 253ms\n",
            "992:\tlearn: 0.0048068\ttotal: 31.5s\tremaining: 222ms\n",
            "993:\tlearn: 0.0048051\ttotal: 31.5s\tremaining: 190ms\n",
            "994:\tlearn: 0.0048045\ttotal: 31.5s\tremaining: 158ms\n",
            "995:\tlearn: 0.0048030\ttotal: 31.5s\tremaining: 127ms\n",
            "996:\tlearn: 0.0048026\ttotal: 31.5s\tremaining: 94.9ms\n",
            "997:\tlearn: 0.0048020\ttotal: 31.6s\tremaining: 63.3ms\n",
            "998:\tlearn: 0.0047992\ttotal: 31.6s\tremaining: 31.6ms\n",
            "999:\tlearn: 0.0047987\ttotal: 31.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c1b4c0da6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9973682825411864\n",
            "F1_macro: 0.9175435844452597\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      1.00      1.00     37244\n",
            "                  PortScan       0.94      0.97      0.96       312\n",
            "                  DoS Hulk       1.00      1.00      1.00     10298\n",
            "                      DDoS       1.00      1.00      1.00      1646\n",
            "                       Bot       1.00      1.00      1.00     13960\n",
            "              Infiltration       1.00      0.99      0.99       836\n",
            "  Web Attack ÔøΩ Brute Force       1.00      0.99      0.99       862\n",
            "          Web Attack ÔøΩ XSS       1.00      1.00      1.00       949\n",
            "Web Attack ÔøΩ Sql Injection       1.00      1.00      1.00         2\n",
            "               FTP-Patator       1.00      1.00      1.00         6\n",
            "               SSH-Patator       1.00      1.00      1.00      9024\n",
            "             DoS slowloris       1.00      1.00      1.00       515\n",
            "          DoS Slowhttptest       0.72      0.80      0.76       235\n",
            "             DoS GoldenEye       0.60      1.00      0.75         3\n",
            "                Heartbleed       0.38      0.27      0.32       104\n",
            "\n",
            "                  accuracy                           1.00     75996\n",
            "                 macro avg       0.91      0.94      0.92     75996\n",
            "              weighted avg       1.00      1.00      1.00     75996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í—ã–≤–æ–¥: –µ—Å–ª–∏ —É–±–∏—Ä–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã, —Ç–æ –≤—Ä–æ–¥–µ –±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è... –û–¥–Ω–∞–∫–æ, —ç—Ç–æ —Ç–∞–∫–æ–π –æ–ø–∞—Å–Ω—ã–π –ø—É—Ç—å, –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ —Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–ª–±—Ü–æ–≤ —É–±—Ä–∞—Ç—å –∏ –∏–º–µ–µ—Ç –ª–∏ —ç—Ç–æ —Å–º—ã—Å–ª..."
      ],
      "metadata": {
        "id": "A4oSqOGRy-oW"
      },
      "id": "A4oSqOGRy-oW"
    },
    {
      "cell_type": "markdown",
      "id": "605e335c",
      "metadata": {
        "id": "605e335c"
      },
      "source": [
        "#### –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d91397da",
      "metadata": {
        "id": "d91397da"
      },
      "outputs": [],
      "source": [
        "# –∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "#!pip install -U scikit-learn\n",
        "\n",
        "col_transformer = ColumnTransformer(transformers=[('ss', StandardScaler(), numeric),('oe', OrdinalEncoder(), cat_columns)], remainder='drop')\n",
        "\n",
        "\n",
        "features_train_oe = col_transformer.fit_transform(features_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "WfSu9X8wMb23",
      "metadata": {
        "id": "WfSu9X8wMb23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824c65f0-2ec4-4018-8f40-b45c4099983e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303984, 78)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303984, 78)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#—É–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–æ—Å—ã\n",
        "features_train.shape\n",
        "\n",
        "for name, values in features_train[numeric].iteritems():\n",
        "    upper_lim = features_train[name].quantile(.95)\n",
        "    lower_lim = features_train[name].quantile(.05)\n",
        "    features_train.loc[(features_train[name] > upper_lim),name] = upper_lim\n",
        "    features_train.loc[(features_train[name] < lower_lim),name] = lower_lim\n",
        "\n",
        "features_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11efac3c",
      "metadata": {
        "id": "11efac3c"
      },
      "source": [
        "#### –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a86af239",
      "metadata": {
        "id": "a86af239"
      },
      "outputs": [],
      "source": [
        "pipe_kNN = Pipeline([('clf', KNeighborsClassifier())])\n",
        "\n",
        "pipe_rfr = Pipeline([('clf', RandomForestClassifier(random_state=12345, class_weight='balanced'))])\n",
        "\n",
        "pipe_lgbm = Pipeline([('clf', LGBMClassifier(boosting_type='gbdt', force_row_wise=True, error_score='raise'))])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8838dac3",
      "metadata": {
        "id": "8838dac3"
      },
      "outputs": [],
      "source": [
        "grid_params_cbc = [{'clf__n_neighbors': range(2,5,1)}]\n",
        "\n",
        "grid_params_rfr = [{'clf__max_depth': range(7,20,3), 'clf__n_estimators': range(200, 500, 100)}]\n",
        "\n",
        "grid_params_lgbm = [{'clf__max_depth': range(1,8,3),\n",
        "                     'clf__n_estimators': range(1, 50, 10),\n",
        "                     'clf__num_leaves': range(1,7,2)}]\n",
        "\n",
        "kNN = GridSearchCV(estimator=pipe_kNN,\n",
        "                   param_grid=grid_params_cbc,\n",
        "                   scoring='f1_macro',\n",
        "                   cv=5)\n",
        "\n",
        "RFR = GridSearchCV(estimator=pipe_rfr,\n",
        "                   param_grid=grid_params_rfr,\n",
        "                   scoring='f1_macro',\n",
        "                   cv=5)\n",
        "\n",
        "LGBM = GridSearchCV(estimator=pipe_lgbm,\n",
        "                    param_grid=grid_params_lgbm,\n",
        "                    scoring='f1_macro',\n",
        "                    cv=5)\n",
        "\n",
        "grids = [kNN, LGBM, RFR]\n",
        "\n",
        "grid_dict = {0: 'kNN',\n",
        "             1: 'LGBMClassifier',\n",
        "             2: 'RandomForestC'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ONKYSM4s_BFU",
      "metadata": {
        "id": "ONKYSM4s_BFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d809a49-ff13-4f9d-cde0-10ec18a073e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing model optimizations...\n",
            "\n",
            "Estimator: kNN\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=Pipeline(steps=[('clf', KNeighborsClassifier())]),\n",
              "             param_grid=[{'clf__n_neighbors': range(2, 5)}],\n",
              "             scoring='f1_macro')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;clf&#x27;, KNeighborsClassifier())]),\n",
              "             param_grid=[{&#x27;clf__n_neighbors&#x27;: range(2, 5)}],\n",
              "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;clf&#x27;, KNeighborsClassifier())]),\n",
              "             param_grid=[{&#x27;clf__n_neighbors&#x27;: range(2, 5)}],\n",
              "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;clf&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params are : {'clf__n_neighbors': 2}\n",
            "Best training accuracy: 0.781\n",
            "\n",
            "Estimator: LGBMClassifier\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382961\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14175\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998688\n",
            "[LightGBM] [Info] Start training from score -3.832560\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.609827\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.778850\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.587455\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14256\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713196\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694529\n",
            "[LightGBM] [Info] Start training from score -4.509134\n",
            "[LightGBM] [Info] Start training from score -4.480050\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.511214\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -9.916679\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14171\n",
            "[LightGBM] [Info] Number of data points in the train set: 243187, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713204\n",
            "[LightGBM] [Info] Start training from score -5.493831\n",
            "[LightGBM] [Info] Start training from score -1.998718\n",
            "[LightGBM] [Info] Start training from score -3.832370\n",
            "[LightGBM] [Info] Start training from score -1.694506\n",
            "[LightGBM] [Info] Start training from score -4.509508\n",
            "[LightGBM] [Info] Start training from score -4.479688\n",
            "[LightGBM] [Info] Start training from score -4.382631\n",
            "[LightGBM] [Info] Start training from score -10.792148\n",
            "[LightGBM] [Info] Start training from score -9.457147\n",
            "[LightGBM] [Info] Start training from score -2.130855\n",
            "[LightGBM] [Info] Start training from score -4.994268\n",
            "[LightGBM] [Info] Start training from score -5.777521\n",
            "[LightGBM] [Info] Start training from score -10.003691\n",
            "[LightGBM] [Info] Start training from score -6.590445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14254\n",
            "[LightGBM] [Info] Number of data points in the train set: 243188, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713208\n",
            "[LightGBM] [Info] Start training from score -5.493835\n",
            "[LightGBM] [Info] Start training from score -1.998722\n",
            "[LightGBM] [Info] Start training from score -3.832564\n",
            "[LightGBM] [Info] Start training from score -1.694510\n",
            "[LightGBM] [Info] Start training from score -4.509138\n",
            "[LightGBM] [Info] Start training from score -4.479692\n",
            "[LightGBM] [Info] Start training from score -4.382965\n",
            "[LightGBM] [Info] Start training from score -10.609831\n",
            "[LightGBM] [Info] Start training from score -9.457151\n",
            "[LightGBM] [Info] Start training from score -2.130824\n",
            "[LightGBM] [Info] Start training from score -4.994272\n",
            "[LightGBM] [Info] Start training from score -5.777525\n",
            "[LightGBM] [Info] Start training from score -10.003695\n",
            "[LightGBM] [Info] Start training from score -6.590449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] Unknown parameter: error_score\n",
            "[LightGBM] [Info] Total Bins 14252\n",
            "[LightGBM] [Info] Number of data points in the train set: 303984, number of used features: 67\n",
            "[LightGBM] [Info] Start training from score -0.713203\n",
            "[LightGBM] [Info] Start training from score -5.493832\n",
            "[LightGBM] [Info] Start training from score -1.998707\n",
            "[LightGBM] [Info] Start training from score -3.832484\n",
            "[LightGBM] [Info] Start training from score -1.694520\n",
            "[LightGBM] [Info] Start training from score -4.509209\n",
            "[LightGBM] [Info] Start training from score -4.479761\n",
            "[LightGBM] [Info] Start training from score -4.382764\n",
            "[LightGBM] [Info] Start training from score -10.678820\n",
            "[LightGBM] [Info] Start training from score -9.489236\n",
            "[LightGBM] [Info] Start training from score -2.130848\n",
            "[LightGBM] [Info] Start training from score -4.994269\n",
            "[LightGBM] [Info] Start training from score -5.777787\n",
            "[LightGBM] [Info] Start training from score -9.985673\n",
            "[LightGBM] [Info] Start training from score -6.589249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('clf',\n",
              "                                        LGBMClassifier(error_score='raise',\n",
              "                                                       force_row_wise=True))]),\n",
              "             param_grid=[{'clf__max_depth': range(1, 8, 3),\n",
              "                          'clf__n_estimators': range(1, 50, 10),\n",
              "                          'clf__num_leaves': range(1, 7, 2)}],\n",
              "             scoring='f1_macro')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
              "                                        LGBMClassifier(error_score=&#x27;raise&#x27;,\n",
              "                                                       force_row_wise=True))]),\n",
              "             param_grid=[{&#x27;clf__max_depth&#x27;: range(1, 8, 3),\n",
              "                          &#x27;clf__n_estimators&#x27;: range(1, 50, 10),\n",
              "                          &#x27;clf__num_leaves&#x27;: range(1, 7, 2)}],\n",
              "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
              "                                        LGBMClassifier(error_score=&#x27;raise&#x27;,\n",
              "                                                       force_row_wise=True))]),\n",
              "             param_grid=[{&#x27;clf__max_depth&#x27;: range(1, 8, 3),\n",
              "                          &#x27;clf__n_estimators&#x27;: range(1, 50, 10),\n",
              "                          &#x27;clf__num_leaves&#x27;: range(1, 7, 2)}],\n",
              "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;clf&#x27;,\n",
              "                 LGBMClassifier(error_score=&#x27;raise&#x27;, force_row_wise=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(error_score=&#x27;raise&#x27;, force_row_wise=True)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params are : {'clf__max_depth': 4, 'clf__n_estimators': 11, 'clf__num_leaves': 5}\n",
            "Best training accuracy: 0.681\n",
            "\n",
            "Estimator: RandomForestC\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('clf',\n",
              "                                        RandomForestClassifier(class_weight='balanced',\n",
              "                                                               random_state=12345))]),\n",
              "             param_grid=[{'clf__max_depth': range(7, 20, 3),\n",
              "                          'clf__n_estimators': range(200, 500, 100)}],\n",
              "             scoring='f1_macro')"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
              "                                        RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                               random_state=12345))]),\n",
              "             param_grid=[{&#x27;clf__max_depth&#x27;: range(7, 20, 3),\n",
              "                          &#x27;clf__n_estimators&#x27;: range(200, 500, 100)}],\n",
              "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
              "                                        RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                               random_state=12345))]),\n",
              "             param_grid=[{&#x27;clf__max_depth&#x27;: range(7, 20, 3),\n",
              "                          &#x27;clf__n_estimators&#x27;: range(200, 500, 100)}],\n",
              "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;clf&#x27;,\n",
              "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                        random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params are : {'clf__max_depth': 19, 'clf__n_estimators': 300}\n",
            "Best training accuracy: 0.869\n",
            "\n",
            "Classifier with best test set accuracy: RandomForestC\n"
          ]
        }
      ],
      "source": [
        "print('Performing model optimizations...')\n",
        "best_acc = -100.0\n",
        "best_clf = 0\n",
        "best_gs = ''\n",
        "for idx, gs in enumerate(grids):\n",
        "    print('\\nEstimator: %s' % grid_dict[idx])\n",
        "    gs.fit(features_train, target_train)\n",
        "    print('Best params are : %s' % gs.best_params_)\n",
        "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
        "    if  gs.best_score_ > best_acc:\n",
        "        best_acc = gs.best_score_\n",
        "        best_gs = gs\n",
        "        best_clf = idx\n",
        "        best_param = gs.best_params_\n",
        "\n",
        "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pip = pd.DataFrame({'–úethod': ['LogisticRegression', 'KNeighborsClassifier', 'RandomForestClassifier', 'LGBMClassifier'],\n",
        "                         'F1_macro': [0.468, 0.781, 0.869, 0.681]})\n",
        "\n",
        "data_pip"
      ],
      "metadata": {
        "id": "p0ji-oI5vlsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "8f567250-58f5-49bd-bbb7-fdcb6e730ac3"
      },
      "id": "p0ji-oI5vlsY",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   –úethod  F1_macro\n",
              "0      LogisticRegression     0.468\n",
              "1    KNeighborsClassifier     0.781\n",
              "2  RandomForestClassifier     0.869\n",
              "3          LGBMClassifier     0.681"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-542b90fc-4ab4-4d6a-bd9b-038d1dccfbf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>–úethod</th>\n",
              "      <th>F1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-542b90fc-4ab4-4d6a-bd9b-038d1dccfbf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-542b90fc-4ab4-4d6a-bd9b-038d1dccfbf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-542b90fc-4ab4-4d6a-bd9b-038d1dccfbf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35c09fae-8fd5-4f97-97b8-ec5f2ad17526\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35c09fae-8fd5-4f97-97b8-ec5f2ad17526')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35c09fae-8fd5-4f97-97b8-ec5f2ad17526 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I7InTeQRx2oW",
      "metadata": {
        "id": "I7InTeQRx2oW"
      },
      "source": [
        "–ü–æ –∏—Ç–æ–≥–∞–º –ø—Ä–æ–≥–æ–Ω–∞ pipeline, –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —ç—Ç–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–∫–∞–∑–∞–ª–∞ –º–æ–¥–µ–ª—å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b63e1090",
      "metadata": {
        "id": "b63e1090"
      },
      "source": [
        "#### –£–ª—É—á—à–∞–µ–º –º–æ–¥–µ–ª—å"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "36902b15",
      "metadata": {
        "id": "36902b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5b65d285-8069-4514-818c-039c04d11fd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=400,\n",
              "                       random_state=12345)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20, n_estimators=400,\n",
              "                       random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20, n_estimators=400,\n",
              "                       random_state=12345)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model_rfc=RandomForestClassifier(max_depth=20,\n",
        "                                 n_estimators=400,\n",
        "                                 random_state=12345,\n",
        "                                 class_weight='balanced')\n",
        "\n",
        "model_rfc.fit(features_train, target_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "58bcc14c",
      "metadata": {
        "id": "58bcc14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "85d13e57-e2f3-4cd3-b7da-2f5609113ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9956839833675457\n",
            "F1_macro: 0.8939749904569199\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      1.00      1.00     37244\n",
            "                  PortScan       0.71      0.99      0.83       312\n",
            "                  DoS Hulk       1.00      1.00      1.00     10298\n",
            "                      DDoS       1.00      1.00      1.00      1646\n",
            "                       Bot       1.00      1.00      1.00     13960\n",
            "              Infiltration       1.00      0.99      1.00       836\n",
            "  Web Attack ÔøΩ Brute Force       1.00      0.99      0.99       862\n",
            "          Web Attack ÔøΩ XSS       1.00      1.00      1.00       949\n",
            "Web Attack ÔøΩ Sql Injection       1.00      1.00      1.00         2\n",
            "               FTP-Patator       1.00      1.00      1.00         6\n",
            "               SSH-Patator       1.00      1.00      1.00      9024\n",
            "             DoS slowloris       1.00      1.00      1.00       515\n",
            "          DoS Slowhttptest       0.76      0.74      0.75       235\n",
            "             DoS GoldenEye       0.50      0.33      0.40         3\n",
            "                Heartbleed       0.43      0.46      0.44       104\n",
            "\n",
            "                  accuracy                           1.00     75996\n",
            "                 macro avg       0.89      0.90      0.89     75996\n",
            "              weighted avg       1.00      1.00      1.00     75996\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=400,\n",
              "                       random_state=12345)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20, n_estimators=400,\n",
              "                       random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20, n_estimators=400,\n",
              "                       random_state=12345)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "prediction(model_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "0mX53wLEKHCH",
      "metadata": {
        "id": "0mX53wLEKHCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929bb880-31fe-46d7-e32b-a67c6872417f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.0999364\ttest: 1.0999366\tbest: 1.0999366 (0)\ttotal: 327ms\tremaining: 5m 26s\n",
            "1:\ttotal: 376ms\tremaining: 3m 7s\n",
            "2:\ttotal: 424ms\tremaining: 2m 20s\n",
            "3:\ttotal: 477ms\tremaining: 1m 58s\n",
            "4:\ttotal: 523ms\tremaining: 1m 44s\n",
            "5:\tlearn: 0.4333591\ttest: 0.4333590\tbest: 0.4333590 (5)\ttotal: 747ms\tremaining: 2m 3s\n",
            "6:\ttotal: 775ms\tremaining: 1m 49s\n",
            "7:\ttotal: 802ms\tremaining: 1m 39s\n",
            "8:\ttotal: 829ms\tremaining: 1m 31s\n",
            "9:\ttotal: 855ms\tremaining: 1m 24s\n",
            "10:\tlearn: 0.2302713\ttest: 0.2302713\tbest: 0.2302713 (10)\ttotal: 1.07s\tremaining: 1m 36s\n",
            "11:\ttotal: 1.09s\tremaining: 1m 29s\n",
            "12:\ttotal: 1.11s\tremaining: 1m 24s\n",
            "13:\ttotal: 1.14s\tremaining: 1m 20s\n",
            "14:\ttotal: 1.17s\tremaining: 1m 17s\n",
            "15:\tlearn: 0.1386107\ttest: 0.1386106\tbest: 0.1386106 (15)\ttotal: 1.4s\tremaining: 1m 25s\n",
            "16:\ttotal: 1.42s\tremaining: 1m 22s\n",
            "17:\ttotal: 1.45s\tremaining: 1m 18s\n",
            "18:\ttotal: 1.47s\tremaining: 1m 15s\n",
            "19:\ttotal: 1.5s\tremaining: 1m 13s\n",
            "20:\tlearn: 0.0901550\ttest: 0.0901550\tbest: 0.0901550 (20)\ttotal: 1.73s\tremaining: 1m 20s\n",
            "21:\ttotal: 1.75s\tremaining: 1m 17s\n",
            "22:\ttotal: 1.77s\tremaining: 1m 15s\n",
            "23:\ttotal: 1.8s\tremaining: 1m 13s\n",
            "24:\ttotal: 1.82s\tremaining: 1m 11s\n",
            "25:\tlearn: 0.0647120\ttest: 0.0647120\tbest: 0.0647120 (25)\ttotal: 2.02s\tremaining: 1m 15s\n",
            "26:\ttotal: 2.04s\tremaining: 1m 13s\n",
            "27:\ttotal: 2.06s\tremaining: 1m 11s\n",
            "28:\ttotal: 2.09s\tremaining: 1m 9s\n",
            "29:\ttotal: 2.11s\tremaining: 1m 8s\n",
            "30:\tlearn: 0.0487661\ttest: 0.0487661\tbest: 0.0487661 (30)\ttotal: 2.31s\tremaining: 1m 12s\n",
            "31:\ttotal: 2.33s\tremaining: 1m 10s\n",
            "32:\ttotal: 2.35s\tremaining: 1m 8s\n",
            "33:\ttotal: 2.38s\tremaining: 1m 7s\n",
            "34:\ttotal: 2.4s\tremaining: 1m 6s\n",
            "35:\tlearn: 0.0408773\ttest: 0.0408773\tbest: 0.0408773 (35)\ttotal: 2.61s\tremaining: 1m 9s\n",
            "36:\ttotal: 2.63s\tremaining: 1m 8s\n",
            "37:\ttotal: 2.65s\tremaining: 1m 7s\n",
            "38:\ttotal: 2.67s\tremaining: 1m 5s\n",
            "39:\ttotal: 2.7s\tremaining: 1m 4s\n",
            "40:\tlearn: 0.0347367\ttest: 0.0347367\tbest: 0.0347367 (40)\ttotal: 2.9s\tremaining: 1m 7s\n",
            "41:\ttotal: 2.93s\tremaining: 1m 6s\n",
            "42:\ttotal: 2.95s\tremaining: 1m 5s\n",
            "43:\ttotal: 2.97s\tremaining: 1m 4s\n",
            "44:\ttotal: 2.99s\tremaining: 1m 3s\n",
            "45:\tlearn: 0.0302524\ttest: 0.0302524\tbest: 0.0302524 (45)\ttotal: 3.21s\tremaining: 1m 6s\n",
            "46:\ttotal: 3.23s\tremaining: 1m 5s\n",
            "47:\ttotal: 3.26s\tremaining: 1m 4s\n",
            "48:\ttotal: 3.28s\tremaining: 1m 3s\n",
            "49:\ttotal: 3.3s\tremaining: 1m 2s\n",
            "50:\tlearn: 0.0270562\ttest: 0.0270562\tbest: 0.0270562 (50)\ttotal: 3.5s\tremaining: 1m 5s\n",
            "51:\ttotal: 3.53s\tremaining: 1m 4s\n",
            "52:\ttotal: 3.55s\tremaining: 1m 3s\n",
            "53:\ttotal: 3.57s\tremaining: 1m 2s\n",
            "54:\ttotal: 3.59s\tremaining: 1m 1s\n",
            "55:\tlearn: 0.0242965\ttest: 0.0242965\tbest: 0.0242965 (55)\ttotal: 3.8s\tremaining: 1m 4s\n",
            "56:\ttotal: 3.83s\tremaining: 1m 3s\n",
            "57:\ttotal: 3.85s\tremaining: 1m 2s\n",
            "58:\ttotal: 3.87s\tremaining: 1m 1s\n",
            "59:\ttotal: 3.89s\tremaining: 1m\n",
            "60:\tlearn: 0.0222062\ttest: 0.0222062\tbest: 0.0222062 (60)\ttotal: 4.11s\tremaining: 1m 3s\n",
            "61:\ttotal: 4.13s\tremaining: 1m 2s\n",
            "62:\ttotal: 4.16s\tremaining: 1m 1s\n",
            "63:\ttotal: 4.18s\tremaining: 1m 1s\n",
            "64:\ttotal: 4.2s\tremaining: 1m\n",
            "65:\tlearn: 0.0204283\ttest: 0.0204283\tbest: 0.0204283 (65)\ttotal: 4.43s\tremaining: 1m 2s\n",
            "66:\ttotal: 4.46s\tremaining: 1m 2s\n",
            "67:\ttotal: 4.48s\tremaining: 1m 1s\n",
            "68:\ttotal: 4.5s\tremaining: 1m\n",
            "69:\ttotal: 4.52s\tremaining: 1m\n",
            "70:\tlearn: 0.0192042\ttest: 0.0192042\tbest: 0.0192042 (70)\ttotal: 4.72s\tremaining: 1m 1s\n",
            "71:\ttotal: 4.74s\tremaining: 1m 1s\n",
            "72:\ttotal: 4.76s\tremaining: 1m\n",
            "73:\ttotal: 4.79s\tremaining: 59.9s\n",
            "74:\ttotal: 4.81s\tremaining: 59.3s\n",
            "75:\tlearn: 0.0180154\ttest: 0.0180154\tbest: 0.0180154 (75)\ttotal: 5.03s\tremaining: 1m 1s\n",
            "76:\ttotal: 5.05s\tremaining: 1m\n",
            "77:\ttotal: 5.07s\tremaining: 60s\n",
            "78:\ttotal: 5.09s\tremaining: 59.4s\n",
            "79:\ttotal: 5.12s\tremaining: 58.9s\n",
            "80:\tlearn: 0.0166786\ttest: 0.0166786\tbest: 0.0166786 (80)\ttotal: 5.38s\tremaining: 1m 1s\n",
            "81:\ttotal: 5.4s\tremaining: 1m\n",
            "82:\ttotal: 5.42s\tremaining: 59.9s\n",
            "83:\ttotal: 5.45s\tremaining: 59.4s\n",
            "84:\ttotal: 5.47s\tremaining: 58.9s\n",
            "85:\tlearn: 0.0158990\ttest: 0.0158990\tbest: 0.0158990 (85)\ttotal: 5.71s\tremaining: 1m\n",
            "86:\ttotal: 5.74s\tremaining: 1m\n",
            "87:\ttotal: 5.76s\tremaining: 59.7s\n",
            "88:\ttotal: 5.78s\tremaining: 59.2s\n",
            "89:\ttotal: 5.81s\tremaining: 58.7s\n",
            "90:\tlearn: 0.0150231\ttest: 0.0150231\tbest: 0.0150231 (90)\ttotal: 6.02s\tremaining: 1m\n",
            "91:\ttotal: 6.04s\tremaining: 59.6s\n",
            "92:\ttotal: 6.07s\tremaining: 59.2s\n",
            "93:\ttotal: 6.09s\tremaining: 58.7s\n",
            "94:\ttotal: 6.12s\tremaining: 58.3s\n",
            "95:\tlearn: 0.0143851\ttest: 0.0143851\tbest: 0.0143851 (95)\ttotal: 6.41s\tremaining: 1m\n",
            "96:\ttotal: 6.46s\tremaining: 1m\n",
            "97:\ttotal: 6.52s\tremaining: 1m\n",
            "98:\ttotal: 6.58s\tremaining: 59.9s\n",
            "99:\ttotal: 6.64s\tremaining: 59.8s\n",
            "100:\tlearn: 0.0137312\ttest: 0.0137312\tbest: 0.0137312 (100)\ttotal: 7.04s\tremaining: 1m 2s\n",
            "101:\ttotal: 7.1s\tremaining: 1m 2s\n",
            "102:\ttotal: 7.15s\tremaining: 1m 2s\n",
            "103:\ttotal: 7.21s\tremaining: 1m 2s\n",
            "104:\ttotal: 7.27s\tremaining: 1m 2s\n",
            "105:\tlearn: 0.0133479\ttest: 0.0133479\tbest: 0.0133479 (105)\ttotal: 7.64s\tremaining: 1m 4s\n",
            "106:\ttotal: 7.7s\tremaining: 1m 4s\n",
            "107:\ttotal: 7.78s\tremaining: 1m 4s\n",
            "108:\ttotal: 7.86s\tremaining: 1m 4s\n",
            "109:\ttotal: 7.92s\tremaining: 1m 4s\n",
            "110:\tlearn: 0.0129035\ttest: 0.0129035\tbest: 0.0129035 (110)\ttotal: 8.31s\tremaining: 1m 6s\n",
            "111:\ttotal: 8.39s\tremaining: 1m 6s\n",
            "112:\ttotal: 8.47s\tremaining: 1m 6s\n",
            "113:\ttotal: 8.55s\tremaining: 1m 6s\n",
            "114:\ttotal: 8.64s\tremaining: 1m 6s\n",
            "115:\tlearn: 0.0123485\ttest: 0.0123485\tbest: 0.0123485 (115)\ttotal: 9.13s\tremaining: 1m 9s\n",
            "116:\ttotal: 9.2s\tremaining: 1m 9s\n",
            "117:\ttotal: 9.27s\tremaining: 1m 9s\n",
            "118:\ttotal: 9.34s\tremaining: 1m 9s\n",
            "119:\ttotal: 9.42s\tremaining: 1m 9s\n",
            "120:\tlearn: 0.0119108\ttest: 0.0119108\tbest: 0.0119108 (120)\ttotal: 9.84s\tremaining: 1m 11s\n",
            "121:\ttotal: 9.92s\tremaining: 1m 11s\n",
            "122:\ttotal: 10s\tremaining: 1m 11s\n",
            "123:\ttotal: 10s\tremaining: 1m 10s\n",
            "124:\ttotal: 10.1s\tremaining: 1m 10s\n",
            "125:\tlearn: 0.0115880\ttest: 0.0115880\tbest: 0.0115880 (125)\ttotal: 10.3s\tremaining: 1m 11s\n",
            "126:\ttotal: 10.4s\tremaining: 1m 11s\n",
            "127:\ttotal: 10.4s\tremaining: 1m 10s\n",
            "128:\ttotal: 10.4s\tremaining: 1m 10s\n",
            "129:\ttotal: 10.4s\tremaining: 1m 9s\n",
            "130:\tlearn: 0.0112478\ttest: 0.0112478\tbest: 0.0112478 (130)\ttotal: 10.7s\tremaining: 1m 10s\n",
            "131:\ttotal: 10.7s\tremaining: 1m 10s\n",
            "132:\ttotal: 10.7s\tremaining: 1m 9s\n",
            "133:\ttotal: 10.7s\tremaining: 1m 9s\n",
            "134:\ttotal: 10.8s\tremaining: 1m 8s\n",
            "135:\tlearn: 0.0108520\ttest: 0.0108520\tbest: 0.0108520 (135)\ttotal: 11s\tremaining: 1m 9s\n",
            "136:\ttotal: 11s\tremaining: 1m 9s\n",
            "137:\ttotal: 11s\tremaining: 1m 8s\n",
            "138:\ttotal: 11s\tremaining: 1m 8s\n",
            "139:\ttotal: 11.1s\tremaining: 1m 7s\n",
            "140:\tlearn: 0.0106183\ttest: 0.0106183\tbest: 0.0106183 (140)\ttotal: 11.3s\tremaining: 1m 8s\n",
            "141:\ttotal: 11.3s\tremaining: 1m 8s\n",
            "142:\ttotal: 11.3s\tremaining: 1m 7s\n",
            "143:\ttotal: 11.3s\tremaining: 1m 7s\n",
            "144:\ttotal: 11.4s\tremaining: 1m 6s\n",
            "145:\tlearn: 0.0104091\ttest: 0.0104091\tbest: 0.0104091 (145)\ttotal: 11.6s\tremaining: 1m 7s\n",
            "146:\ttotal: 11.6s\tremaining: 1m 7s\n",
            "147:\ttotal: 11.6s\tremaining: 1m 6s\n",
            "148:\ttotal: 11.6s\tremaining: 1m 6s\n",
            "149:\ttotal: 11.7s\tremaining: 1m 6s\n",
            "150:\tlearn: 0.0101808\ttest: 0.0101808\tbest: 0.0101808 (150)\ttotal: 11.9s\tremaining: 1m 6s\n",
            "151:\ttotal: 11.9s\tremaining: 1m 6s\n",
            "152:\ttotal: 11.9s\tremaining: 1m 6s\n",
            "153:\ttotal: 12s\tremaining: 1m 5s\n",
            "154:\ttotal: 12s\tremaining: 1m 5s\n",
            "155:\tlearn: 0.0100709\ttest: 0.0100709\tbest: 0.0100709 (155)\ttotal: 12.2s\tremaining: 1m 6s\n",
            "156:\ttotal: 12.2s\tremaining: 1m 5s\n",
            "157:\ttotal: 12.3s\tremaining: 1m 5s\n",
            "158:\ttotal: 12.3s\tremaining: 1m 5s\n",
            "159:\ttotal: 12.3s\tremaining: 1m 4s\n",
            "160:\tlearn: 0.0099266\ttest: 0.0099266\tbest: 0.0099266 (160)\ttotal: 12.5s\tremaining: 1m 5s\n",
            "161:\ttotal: 12.6s\tremaining: 1m 5s\n",
            "162:\ttotal: 12.6s\tremaining: 1m 4s\n",
            "163:\ttotal: 12.6s\tremaining: 1m 4s\n",
            "164:\ttotal: 12.6s\tremaining: 1m 3s\n",
            "165:\tlearn: 0.0097603\ttest: 0.0097603\tbest: 0.0097603 (165)\ttotal: 12.9s\tremaining: 1m 4s\n",
            "166:\ttotal: 12.9s\tremaining: 1m 4s\n",
            "167:\ttotal: 12.9s\tremaining: 1m 4s\n",
            "168:\ttotal: 12.9s\tremaining: 1m 3s\n",
            "169:\ttotal: 13s\tremaining: 1m 3s\n",
            "170:\tlearn: 0.0095873\ttest: 0.0095873\tbest: 0.0095873 (170)\ttotal: 13.2s\tremaining: 1m 3s\n",
            "171:\ttotal: 13.2s\tremaining: 1m 3s\n",
            "172:\ttotal: 13.2s\tremaining: 1m 3s\n",
            "173:\ttotal: 13.3s\tremaining: 1m 2s\n",
            "174:\ttotal: 13.3s\tremaining: 1m 2s\n",
            "175:\tlearn: 0.0094828\ttest: 0.0094828\tbest: 0.0094828 (175)\ttotal: 13.5s\tremaining: 1m 3s\n",
            "176:\ttotal: 13.5s\tremaining: 1m 2s\n",
            "177:\ttotal: 13.5s\tremaining: 1m 2s\n",
            "178:\ttotal: 13.6s\tremaining: 1m 2s\n",
            "179:\ttotal: 13.6s\tremaining: 1m 1s\n",
            "180:\tlearn: 0.0093627\ttest: 0.0093627\tbest: 0.0093627 (180)\ttotal: 13.8s\tremaining: 1m 2s\n",
            "181:\ttotal: 13.8s\tremaining: 1m 2s\n",
            "182:\ttotal: 13.9s\tremaining: 1m 1s\n",
            "183:\ttotal: 13.9s\tremaining: 1m 1s\n",
            "184:\ttotal: 13.9s\tremaining: 1m 1s\n",
            "185:\tlearn: 0.0092136\ttest: 0.0092136\tbest: 0.0092136 (185)\ttotal: 14.1s\tremaining: 1m 1s\n",
            "186:\ttotal: 14.1s\tremaining: 1m 1s\n",
            "187:\ttotal: 14.2s\tremaining: 1m 1s\n",
            "188:\ttotal: 14.2s\tremaining: 1m\n",
            "189:\ttotal: 14.2s\tremaining: 1m\n",
            "190:\tlearn: 0.0090003\ttest: 0.0090003\tbest: 0.0090003 (190)\ttotal: 14.5s\tremaining: 1m 1s\n",
            "191:\ttotal: 14.5s\tremaining: 1m\n",
            "192:\ttotal: 14.5s\tremaining: 1m\n",
            "193:\ttotal: 14.5s\tremaining: 1m\n",
            "194:\ttotal: 14.5s\tremaining: 1m\n",
            "195:\tlearn: 0.0088961\ttest: 0.0088961\tbest: 0.0088961 (195)\ttotal: 14.8s\tremaining: 1m\n",
            "196:\ttotal: 14.8s\tremaining: 1m\n",
            "197:\ttotal: 14.8s\tremaining: 60s\n",
            "198:\ttotal: 14.8s\tremaining: 59.7s\n",
            "199:\ttotal: 14.8s\tremaining: 59.4s\n",
            "200:\tlearn: 0.0088190\ttest: 0.0088190\tbest: 0.0088190 (200)\ttotal: 15.1s\tremaining: 59.9s\n",
            "201:\ttotal: 15.1s\tremaining: 59.6s\n",
            "202:\ttotal: 15.1s\tremaining: 59.4s\n",
            "203:\ttotal: 15.1s\tremaining: 59.1s\n",
            "204:\ttotal: 15.2s\tremaining: 58.8s\n",
            "205:\tlearn: 0.0086662\ttest: 0.0086662\tbest: 0.0086662 (205)\ttotal: 15.4s\tremaining: 59.5s\n",
            "206:\ttotal: 15.5s\tremaining: 59.2s\n",
            "207:\ttotal: 15.5s\tremaining: 58.9s\n",
            "208:\ttotal: 15.5s\tremaining: 58.7s\n",
            "209:\ttotal: 15.5s\tremaining: 58.4s\n",
            "210:\tlearn: 0.0085935\ttest: 0.0085935\tbest: 0.0085935 (210)\ttotal: 15.8s\tremaining: 59s\n",
            "211:\ttotal: 15.8s\tremaining: 58.7s\n",
            "212:\ttotal: 15.8s\tremaining: 58.4s\n",
            "213:\ttotal: 15.8s\tremaining: 58.2s\n",
            "214:\ttotal: 15.9s\tremaining: 57.9s\n",
            "215:\tlearn: 0.0085314\ttest: 0.0085314\tbest: 0.0085314 (215)\ttotal: 16.1s\tremaining: 58.4s\n",
            "216:\ttotal: 16.1s\tremaining: 58.1s\n",
            "217:\ttotal: 16.1s\tremaining: 57.9s\n",
            "218:\ttotal: 16.2s\tremaining: 57.6s\n",
            "219:\ttotal: 16.2s\tremaining: 57.4s\n",
            "220:\tlearn: 0.0084424\ttest: 0.0084424\tbest: 0.0084424 (220)\ttotal: 16.4s\tremaining: 57.9s\n",
            "221:\ttotal: 16.4s\tremaining: 57.6s\n",
            "222:\ttotal: 16.5s\tremaining: 57.4s\n",
            "223:\ttotal: 16.5s\tremaining: 57.2s\n",
            "224:\ttotal: 16.5s\tremaining: 56.9s\n",
            "225:\tlearn: 0.0083743\ttest: 0.0083743\tbest: 0.0083743 (225)\ttotal: 16.8s\tremaining: 57.4s\n",
            "226:\ttotal: 16.8s\tremaining: 57.1s\n",
            "227:\ttotal: 16.8s\tremaining: 56.9s\n",
            "228:\ttotal: 16.8s\tremaining: 56.6s\n",
            "229:\ttotal: 16.8s\tremaining: 56.4s\n",
            "230:\tlearn: 0.0082959\ttest: 0.0082959\tbest: 0.0082959 (230)\ttotal: 17.1s\tremaining: 56.8s\n",
            "231:\ttotal: 17.1s\tremaining: 56.6s\n",
            "232:\ttotal: 17.1s\tremaining: 56.3s\n",
            "233:\ttotal: 17.1s\tremaining: 56.1s\n",
            "234:\ttotal: 17.2s\tremaining: 55.9s\n",
            "235:\tlearn: 0.0082374\ttest: 0.0082374\tbest: 0.0082374 (235)\ttotal: 17.4s\tremaining: 56.3s\n",
            "236:\ttotal: 17.4s\tremaining: 56.1s\n",
            "237:\ttotal: 17.4s\tremaining: 55.8s\n",
            "238:\ttotal: 17.5s\tremaining: 55.6s\n",
            "239:\ttotal: 17.5s\tremaining: 55.4s\n",
            "240:\tlearn: 0.0081808\ttest: 0.0081808\tbest: 0.0081808 (240)\ttotal: 17.7s\tremaining: 55.8s\n",
            "241:\ttotal: 17.7s\tremaining: 55.5s\n",
            "242:\ttotal: 17.8s\tremaining: 55.3s\n",
            "243:\ttotal: 17.8s\tremaining: 55.1s\n",
            "244:\ttotal: 17.8s\tremaining: 54.9s\n",
            "245:\tlearn: 0.0080810\ttest: 0.0080810\tbest: 0.0080810 (245)\ttotal: 18s\tremaining: 55.3s\n",
            "246:\ttotal: 18.1s\tremaining: 55.1s\n",
            "247:\ttotal: 18.1s\tremaining: 54.8s\n",
            "248:\ttotal: 18.1s\tremaining: 54.6s\n",
            "249:\ttotal: 18.1s\tremaining: 54.4s\n",
            "250:\tlearn: 0.0079973\ttest: 0.0079973\tbest: 0.0079973 (250)\ttotal: 18.4s\tremaining: 54.8s\n",
            "251:\ttotal: 18.4s\tremaining: 54.6s\n",
            "252:\ttotal: 18.4s\tremaining: 54.4s\n",
            "253:\ttotal: 18.4s\tremaining: 54.2s\n",
            "254:\ttotal: 18.5s\tremaining: 53.9s\n",
            "255:\tlearn: 0.0079542\ttest: 0.0079542\tbest: 0.0079542 (255)\ttotal: 18.7s\tremaining: 54.3s\n",
            "256:\ttotal: 18.7s\tremaining: 54.1s\n",
            "257:\ttotal: 18.7s\tremaining: 53.9s\n",
            "258:\ttotal: 18.8s\tremaining: 53.6s\n",
            "259:\ttotal: 18.8s\tremaining: 53.4s\n",
            "260:\tlearn: 0.0078493\ttest: 0.0078493\tbest: 0.0078493 (260)\ttotal: 19s\tremaining: 53.8s\n",
            "261:\ttotal: 19s\tremaining: 53.6s\n",
            "262:\ttotal: 19s\tremaining: 53.4s\n",
            "263:\ttotal: 19.1s\tremaining: 53.2s\n",
            "264:\ttotal: 19.1s\tremaining: 52.9s\n",
            "265:\tlearn: 0.0077874\ttest: 0.0077874\tbest: 0.0077874 (265)\ttotal: 19.3s\tremaining: 53.3s\n",
            "266:\ttotal: 19.3s\tremaining: 53.1s\n",
            "267:\ttotal: 19.4s\tremaining: 52.9s\n",
            "268:\ttotal: 19.4s\tremaining: 52.7s\n",
            "269:\ttotal: 19.4s\tremaining: 52.5s\n",
            "270:\tlearn: 0.0077465\ttest: 0.0077465\tbest: 0.0077465 (270)\ttotal: 19.6s\tremaining: 52.8s\n",
            "271:\ttotal: 19.7s\tremaining: 52.6s\n",
            "272:\ttotal: 19.7s\tremaining: 52.4s\n",
            "273:\ttotal: 19.7s\tremaining: 52.2s\n",
            "274:\ttotal: 19.7s\tremaining: 52s\n",
            "275:\tlearn: 0.0077145\ttest: 0.0077145\tbest: 0.0077145 (275)\ttotal: 20s\tremaining: 52.3s\n",
            "276:\ttotal: 20s\tremaining: 52.2s\n",
            "277:\ttotal: 20s\tremaining: 52.1s\n",
            "278:\ttotal: 20.1s\tremaining: 52s\n",
            "279:\ttotal: 20.2s\tremaining: 51.9s\n",
            "280:\tlearn: 0.0076501\ttest: 0.0076501\tbest: 0.0076501 (280)\ttotal: 20.6s\tremaining: 52.8s\n",
            "281:\ttotal: 20.7s\tremaining: 52.6s\n",
            "282:\ttotal: 20.7s\tremaining: 52.5s\n",
            "283:\ttotal: 20.8s\tremaining: 52.5s\n",
            "284:\ttotal: 20.9s\tremaining: 52.4s\n",
            "285:\tlearn: 0.0076196\ttest: 0.0076196\tbest: 0.0076196 (285)\ttotal: 21.4s\tremaining: 53.3s\n",
            "286:\ttotal: 21.4s\tremaining: 53.2s\n",
            "287:\ttotal: 21.5s\tremaining: 53.1s\n",
            "288:\ttotal: 21.6s\tremaining: 53.1s\n",
            "289:\ttotal: 21.6s\tremaining: 53s\n",
            "290:\tlearn: 0.0075639\ttest: 0.0075639\tbest: 0.0075639 (290)\ttotal: 22s\tremaining: 53.7s\n",
            "291:\ttotal: 22.1s\tremaining: 53.6s\n",
            "292:\ttotal: 22.2s\tremaining: 53.6s\n",
            "293:\ttotal: 22.3s\tremaining: 53.5s\n",
            "294:\ttotal: 22.4s\tremaining: 53.5s\n",
            "295:\tlearn: 0.0075047\ttest: 0.0075047\tbest: 0.0075047 (295)\ttotal: 22.8s\tremaining: 54.3s\n",
            "296:\ttotal: 22.9s\tremaining: 54.3s\n",
            "297:\ttotal: 23s\tremaining: 54.2s\n",
            "298:\ttotal: 23.1s\tremaining: 54.2s\n",
            "299:\ttotal: 23.2s\tremaining: 54.1s\n",
            "300:\tlearn: 0.0074779\ttest: 0.0074779\tbest: 0.0074779 (300)\ttotal: 23.6s\tremaining: 54.8s\n",
            "301:\ttotal: 23.7s\tremaining: 54.8s\n",
            "302:\ttotal: 23.8s\tremaining: 54.6s\n",
            "303:\ttotal: 23.8s\tremaining: 54.5s\n",
            "304:\ttotal: 23.8s\tremaining: 54.3s\n",
            "305:\tlearn: 0.0074396\ttest: 0.0074396\tbest: 0.0074396 (305)\ttotal: 24.1s\tremaining: 54.6s\n",
            "306:\ttotal: 24.1s\tremaining: 54.4s\n",
            "307:\ttotal: 24.1s\tremaining: 54.2s\n",
            "308:\ttotal: 24.2s\tremaining: 54s\n",
            "309:\ttotal: 24.2s\tremaining: 53.9s\n",
            "310:\tlearn: 0.0073804\ttest: 0.0073804\tbest: 0.0073804 (310)\ttotal: 24.4s\tremaining: 54.1s\n",
            "311:\ttotal: 24.5s\tremaining: 54s\n",
            "312:\ttotal: 24.5s\tremaining: 53.8s\n",
            "313:\ttotal: 24.5s\tremaining: 53.6s\n",
            "314:\ttotal: 24.6s\tremaining: 53.4s\n",
            "315:\tlearn: 0.0073170\ttest: 0.0073170\tbest: 0.0073170 (315)\ttotal: 24.8s\tremaining: 53.7s\n",
            "316:\ttotal: 24.9s\tremaining: 53.5s\n",
            "317:\ttotal: 24.9s\tremaining: 53.4s\n",
            "318:\ttotal: 24.9s\tremaining: 53.2s\n",
            "319:\ttotal: 24.9s\tremaining: 53s\n",
            "320:\tlearn: 0.0072738\ttest: 0.0072738\tbest: 0.0072738 (320)\ttotal: 25.2s\tremaining: 53.2s\n",
            "321:\ttotal: 25.2s\tremaining: 53s\n",
            "322:\ttotal: 25.2s\tremaining: 52.8s\n",
            "323:\ttotal: 25.2s\tremaining: 52.6s\n",
            "324:\ttotal: 25.2s\tremaining: 52.4s\n",
            "325:\tlearn: 0.0072530\ttest: 0.0072530\tbest: 0.0072530 (325)\ttotal: 25.5s\tremaining: 52.7s\n",
            "326:\ttotal: 25.5s\tremaining: 52.5s\n",
            "327:\ttotal: 25.5s\tremaining: 52.3s\n",
            "328:\ttotal: 25.5s\tremaining: 52.1s\n",
            "329:\ttotal: 25.6s\tremaining: 51.9s\n",
            "330:\tlearn: 0.0072086\ttest: 0.0072086\tbest: 0.0072086 (330)\ttotal: 25.8s\tremaining: 52.2s\n",
            "331:\ttotal: 25.8s\tremaining: 52s\n",
            "332:\ttotal: 25.8s\tremaining: 51.8s\n",
            "333:\ttotal: 25.9s\tremaining: 51.6s\n",
            "334:\ttotal: 25.9s\tremaining: 51.4s\n",
            "335:\tlearn: 0.0071821\ttest: 0.0071821\tbest: 0.0071821 (335)\ttotal: 26.1s\tremaining: 51.6s\n",
            "336:\ttotal: 26.1s\tremaining: 51.4s\n",
            "337:\ttotal: 26.2s\tremaining: 51.3s\n",
            "338:\ttotal: 26.2s\tremaining: 51.1s\n",
            "339:\ttotal: 26.2s\tremaining: 50.9s\n",
            "340:\tlearn: 0.0071590\ttest: 0.0071590\tbest: 0.0071590 (340)\ttotal: 26.5s\tremaining: 51.2s\n",
            "341:\ttotal: 26.5s\tremaining: 51s\n",
            "342:\ttotal: 26.5s\tremaining: 50.8s\n",
            "343:\ttotal: 26.5s\tremaining: 50.6s\n",
            "344:\ttotal: 26.6s\tremaining: 50.4s\n",
            "345:\tlearn: 0.0071102\ttest: 0.0071102\tbest: 0.0071102 (345)\ttotal: 26.8s\tremaining: 50.7s\n",
            "346:\ttotal: 26.8s\tremaining: 50.5s\n",
            "347:\ttotal: 26.9s\tremaining: 50.3s\n",
            "348:\ttotal: 26.9s\tremaining: 50.2s\n",
            "349:\ttotal: 26.9s\tremaining: 50s\n",
            "350:\tlearn: 0.0070723\ttest: 0.0070723\tbest: 0.0070723 (350)\ttotal: 27.1s\tremaining: 50.2s\n",
            "351:\ttotal: 27.2s\tremaining: 50s\n",
            "352:\ttotal: 27.2s\tremaining: 49.8s\n",
            "353:\ttotal: 27.2s\tremaining: 49.6s\n",
            "354:\ttotal: 27.2s\tremaining: 49.5s\n",
            "355:\tlearn: 0.0070551\ttest: 0.0070551\tbest: 0.0070551 (355)\ttotal: 27.5s\tremaining: 49.7s\n",
            "356:\ttotal: 27.5s\tremaining: 49.5s\n",
            "357:\ttotal: 27.5s\tremaining: 49.3s\n",
            "358:\ttotal: 27.5s\tremaining: 49.2s\n",
            "359:\ttotal: 27.6s\tremaining: 49s\n",
            "360:\tlearn: 0.0070364\ttest: 0.0070364\tbest: 0.0070364 (360)\ttotal: 27.8s\tremaining: 49.2s\n",
            "361:\ttotal: 27.8s\tremaining: 49.1s\n",
            "362:\ttotal: 27.9s\tremaining: 48.9s\n",
            "363:\ttotal: 27.9s\tremaining: 48.7s\n",
            "364:\ttotal: 27.9s\tremaining: 48.5s\n",
            "365:\tlearn: 0.0070050\ttest: 0.0070050\tbest: 0.0070050 (365)\ttotal: 28.1s\tremaining: 48.7s\n",
            "366:\ttotal: 28.2s\tremaining: 48.6s\n",
            "367:\ttotal: 28.2s\tremaining: 48.4s\n",
            "368:\ttotal: 28.2s\tremaining: 48.2s\n",
            "369:\ttotal: 28.2s\tremaining: 48.1s\n",
            "370:\tlearn: 0.0069453\ttest: 0.0069453\tbest: 0.0069453 (370)\ttotal: 28.5s\tremaining: 48.3s\n",
            "371:\ttotal: 28.5s\tremaining: 48.1s\n",
            "372:\ttotal: 28.5s\tremaining: 47.9s\n",
            "373:\ttotal: 28.5s\tremaining: 47.8s\n",
            "374:\ttotal: 28.6s\tremaining: 47.6s\n",
            "375:\tlearn: 0.0069115\ttest: 0.0069115\tbest: 0.0069115 (375)\ttotal: 28.8s\tremaining: 47.8s\n",
            "376:\ttotal: 28.8s\tremaining: 47.6s\n",
            "377:\ttotal: 28.8s\tremaining: 47.5s\n",
            "378:\ttotal: 28.9s\tremaining: 47.3s\n",
            "379:\ttotal: 28.9s\tremaining: 47.1s\n",
            "380:\tlearn: 0.0068896\ttest: 0.0068896\tbest: 0.0068896 (380)\ttotal: 29.1s\tremaining: 47.3s\n",
            "381:\ttotal: 29.1s\tremaining: 47.1s\n",
            "382:\ttotal: 29.2s\tremaining: 47s\n",
            "383:\ttotal: 29.2s\tremaining: 46.8s\n",
            "384:\ttotal: 29.2s\tremaining: 46.7s\n",
            "385:\tlearn: 0.0068583\ttest: 0.0068583\tbest: 0.0068583 (385)\ttotal: 29.4s\tremaining: 46.8s\n",
            "386:\ttotal: 29.5s\tremaining: 46.7s\n",
            "387:\ttotal: 29.5s\tremaining: 46.5s\n",
            "388:\ttotal: 29.5s\tremaining: 46.3s\n",
            "389:\ttotal: 29.5s\tremaining: 46.2s\n",
            "390:\tlearn: 0.0068274\ttest: 0.0068274\tbest: 0.0068274 (390)\ttotal: 29.7s\tremaining: 46.3s\n",
            "391:\ttotal: 29.8s\tremaining: 46.2s\n",
            "392:\ttotal: 29.8s\tremaining: 46s\n",
            "393:\ttotal: 29.8s\tremaining: 45.9s\n",
            "394:\ttotal: 29.8s\tremaining: 45.7s\n",
            "395:\tlearn: 0.0068039\ttest: 0.0068039\tbest: 0.0068039 (395)\ttotal: 30.1s\tremaining: 45.9s\n",
            "396:\ttotal: 30.1s\tremaining: 45.7s\n",
            "397:\ttotal: 30.1s\tremaining: 45.6s\n",
            "398:\ttotal: 30.2s\tremaining: 45.4s\n",
            "399:\ttotal: 30.2s\tremaining: 45.3s\n",
            "400:\tlearn: 0.0067820\ttest: 0.0067820\tbest: 0.0067820 (400)\ttotal: 30.4s\tremaining: 45.4s\n",
            "401:\ttotal: 30.4s\tremaining: 45.3s\n",
            "402:\ttotal: 30.4s\tremaining: 45.1s\n",
            "403:\ttotal: 30.5s\tremaining: 44.9s\n",
            "404:\ttotal: 30.5s\tremaining: 44.8s\n",
            "405:\tlearn: 0.0067677\ttest: 0.0067677\tbest: 0.0067677 (405)\ttotal: 30.7s\tremaining: 44.9s\n",
            "406:\ttotal: 30.7s\tremaining: 44.8s\n",
            "407:\ttotal: 30.8s\tremaining: 44.6s\n",
            "408:\ttotal: 30.8s\tremaining: 44.5s\n",
            "409:\ttotal: 30.8s\tremaining: 44.3s\n",
            "410:\tlearn: 0.0067240\ttest: 0.0067240\tbest: 0.0067240 (410)\ttotal: 31s\tremaining: 44.5s\n",
            "411:\ttotal: 31.1s\tremaining: 44.3s\n",
            "412:\ttotal: 31.1s\tremaining: 44.2s\n",
            "413:\ttotal: 31.1s\tremaining: 44s\n",
            "414:\ttotal: 31.1s\tremaining: 43.9s\n",
            "415:\tlearn: 0.0066635\ttest: 0.0066635\tbest: 0.0066635 (415)\ttotal: 31.4s\tremaining: 44s\n",
            "416:\ttotal: 31.4s\tremaining: 43.9s\n",
            "417:\ttotal: 31.4s\tremaining: 43.7s\n",
            "418:\ttotal: 31.4s\tremaining: 43.6s\n",
            "419:\ttotal: 31.5s\tremaining: 43.4s\n",
            "420:\tlearn: 0.0066347\ttest: 0.0066347\tbest: 0.0066347 (420)\ttotal: 31.7s\tremaining: 43.5s\n",
            "421:\ttotal: 31.7s\tremaining: 43.4s\n",
            "422:\ttotal: 31.7s\tremaining: 43.2s\n",
            "423:\ttotal: 31.7s\tremaining: 43.1s\n",
            "424:\ttotal: 31.8s\tremaining: 43s\n",
            "425:\tlearn: 0.0066043\ttest: 0.0066043\tbest: 0.0066043 (425)\ttotal: 32s\tremaining: 43.1s\n",
            "426:\ttotal: 32s\tremaining: 43s\n",
            "427:\ttotal: 32s\tremaining: 42.8s\n",
            "428:\ttotal: 32.1s\tremaining: 42.7s\n",
            "429:\ttotal: 32.1s\tremaining: 42.5s\n",
            "430:\tlearn: 0.0065660\ttest: 0.0065660\tbest: 0.0065660 (430)\ttotal: 32.3s\tremaining: 42.7s\n",
            "431:\ttotal: 32.3s\tremaining: 42.5s\n",
            "432:\ttotal: 32.4s\tremaining: 42.4s\n",
            "433:\ttotal: 32.4s\tremaining: 42.2s\n",
            "434:\ttotal: 32.4s\tremaining: 42.1s\n",
            "435:\tlearn: 0.0065421\ttest: 0.0065421\tbest: 0.0065421 (435)\ttotal: 32.6s\tremaining: 42.2s\n",
            "436:\ttotal: 32.7s\tremaining: 42.1s\n",
            "437:\ttotal: 32.7s\tremaining: 41.9s\n",
            "438:\ttotal: 32.7s\tremaining: 41.8s\n",
            "439:\ttotal: 32.7s\tremaining: 41.7s\n",
            "440:\tlearn: 0.0064988\ttest: 0.0064988\tbest: 0.0064988 (440)\ttotal: 33s\tremaining: 41.8s\n",
            "441:\ttotal: 33s\tremaining: 41.6s\n",
            "442:\ttotal: 33s\tremaining: 41.5s\n",
            "443:\ttotal: 33s\tremaining: 41.4s\n",
            "444:\ttotal: 33.1s\tremaining: 41.2s\n",
            "445:\tlearn: 0.0064747\ttest: 0.0064747\tbest: 0.0064747 (445)\ttotal: 33.3s\tremaining: 41.3s\n",
            "446:\ttotal: 33.3s\tremaining: 41.2s\n",
            "447:\ttotal: 33.3s\tremaining: 41.1s\n",
            "448:\ttotal: 33.4s\tremaining: 40.9s\n",
            "449:\ttotal: 33.4s\tremaining: 40.8s\n",
            "450:\tlearn: 0.0064602\ttest: 0.0064602\tbest: 0.0064602 (450)\ttotal: 33.6s\tremaining: 40.9s\n",
            "451:\ttotal: 33.6s\tremaining: 40.8s\n",
            "452:\ttotal: 33.6s\tremaining: 40.6s\n",
            "453:\ttotal: 33.7s\tremaining: 40.5s\n",
            "454:\ttotal: 33.7s\tremaining: 40.4s\n",
            "455:\tlearn: 0.0064478\ttest: 0.0064478\tbest: 0.0064478 (455)\ttotal: 34s\tremaining: 40.6s\n",
            "456:\ttotal: 34.1s\tremaining: 40.5s\n",
            "457:\ttotal: 34.1s\tremaining: 40.4s\n",
            "458:\ttotal: 34.2s\tremaining: 40.3s\n",
            "459:\ttotal: 34.3s\tremaining: 40.2s\n",
            "460:\tlearn: 0.0064254\ttest: 0.0064254\tbest: 0.0064254 (460)\ttotal: 34.7s\tremaining: 40.5s\n",
            "461:\ttotal: 34.7s\tremaining: 40.4s\n",
            "462:\ttotal: 34.8s\tremaining: 40.3s\n",
            "463:\ttotal: 34.9s\tremaining: 40.3s\n",
            "464:\ttotal: 34.9s\tremaining: 40.2s\n",
            "465:\tlearn: 0.0064060\ttest: 0.0064060\tbest: 0.0064060 (465)\ttotal: 35.4s\tremaining: 40.5s\n",
            "466:\ttotal: 35.4s\tremaining: 40.4s\n",
            "467:\ttotal: 35.5s\tremaining: 40.3s\n",
            "468:\ttotal: 35.6s\tremaining: 40.3s\n",
            "469:\ttotal: 35.6s\tremaining: 40.2s\n",
            "470:\tlearn: 0.0063757\ttest: 0.0063757\tbest: 0.0063757 (470)\ttotal: 36.1s\tremaining: 40.5s\n",
            "471:\ttotal: 36.2s\tremaining: 40.4s\n",
            "472:\ttotal: 36.2s\tremaining: 40.4s\n",
            "473:\ttotal: 36.3s\tremaining: 40.3s\n",
            "474:\ttotal: 36.4s\tremaining: 40.2s\n",
            "475:\tlearn: 0.0063520\ttest: 0.0063520\tbest: 0.0063520 (475)\ttotal: 36.9s\tremaining: 40.6s\n",
            "476:\ttotal: 36.9s\tremaining: 40.5s\n",
            "477:\ttotal: 37s\tremaining: 40.4s\n",
            "478:\ttotal: 37.1s\tremaining: 40.4s\n",
            "479:\ttotal: 37.2s\tremaining: 40.3s\n",
            "480:\tlearn: 0.0063387\ttest: 0.0063387\tbest: 0.0063387 (480)\ttotal: 37.6s\tremaining: 40.6s\n",
            "481:\ttotal: 37.7s\tremaining: 40.5s\n",
            "482:\ttotal: 37.7s\tremaining: 40.4s\n",
            "483:\ttotal: 37.7s\tremaining: 40.2s\n",
            "484:\ttotal: 37.8s\tremaining: 40.1s\n",
            "485:\tlearn: 0.0063158\ttest: 0.0063158\tbest: 0.0063158 (485)\ttotal: 38.1s\tremaining: 40.2s\n",
            "486:\ttotal: 38.1s\tremaining: 40.1s\n",
            "487:\ttotal: 38.1s\tremaining: 40s\n",
            "488:\ttotal: 38.1s\tremaining: 39.9s\n",
            "489:\ttotal: 38.2s\tremaining: 39.7s\n",
            "490:\tlearn: 0.0063036\ttest: 0.0063036\tbest: 0.0063036 (490)\ttotal: 38.4s\tremaining: 39.9s\n",
            "491:\ttotal: 38.5s\tremaining: 39.7s\n",
            "492:\ttotal: 38.5s\tremaining: 39.6s\n",
            "493:\ttotal: 38.5s\tremaining: 39.5s\n",
            "494:\ttotal: 38.6s\tremaining: 39.3s\n",
            "495:\tlearn: 0.0062886\ttest: 0.0062886\tbest: 0.0062886 (495)\ttotal: 38.8s\tremaining: 39.4s\n",
            "496:\ttotal: 38.8s\tremaining: 39.3s\n",
            "497:\ttotal: 38.9s\tremaining: 39.2s\n",
            "498:\ttotal: 38.9s\tremaining: 39.1s\n",
            "499:\ttotal: 38.9s\tremaining: 38.9s\n",
            "500:\tlearn: 0.0062690\ttest: 0.0062690\tbest: 0.0062690 (500)\ttotal: 39.2s\tremaining: 39s\n",
            "501:\ttotal: 39.2s\tremaining: 38.9s\n",
            "502:\ttotal: 39.2s\tremaining: 38.8s\n",
            "503:\ttotal: 39.2s\tremaining: 38.6s\n",
            "504:\ttotal: 39.3s\tremaining: 38.5s\n",
            "505:\tlearn: 0.0062517\ttest: 0.0062517\tbest: 0.0062517 (505)\ttotal: 39.5s\tremaining: 38.5s\n",
            "506:\ttotal: 39.5s\tremaining: 38.4s\n",
            "507:\ttotal: 39.5s\tremaining: 38.3s\n",
            "508:\ttotal: 39.6s\tremaining: 38.2s\n",
            "509:\ttotal: 39.6s\tremaining: 38s\n",
            "510:\tlearn: 0.0062415\ttest: 0.0062415\tbest: 0.0062415 (510)\ttotal: 39.8s\tremaining: 38.1s\n",
            "511:\ttotal: 39.8s\tremaining: 38s\n",
            "512:\ttotal: 39.8s\tremaining: 37.8s\n",
            "513:\ttotal: 39.9s\tremaining: 37.7s\n",
            "514:\ttotal: 39.9s\tremaining: 37.6s\n",
            "515:\tlearn: 0.0062293\ttest: 0.0062293\tbest: 0.0062293 (515)\ttotal: 40.1s\tremaining: 37.6s\n",
            "516:\ttotal: 40.2s\tremaining: 37.5s\n",
            "517:\ttotal: 40.2s\tremaining: 37.4s\n",
            "518:\ttotal: 40.2s\tremaining: 37.3s\n",
            "519:\ttotal: 40.2s\tremaining: 37.1s\n",
            "520:\tlearn: 0.0062135\ttest: 0.0062135\tbest: 0.0062135 (520)\ttotal: 40.4s\tremaining: 37.2s\n",
            "521:\ttotal: 40.5s\tremaining: 37.1s\n",
            "522:\ttotal: 40.5s\tremaining: 36.9s\n",
            "523:\ttotal: 40.5s\tremaining: 36.8s\n",
            "524:\ttotal: 40.5s\tremaining: 36.7s\n",
            "525:\tlearn: 0.0061923\ttest: 0.0061923\tbest: 0.0061923 (525)\ttotal: 40.7s\tremaining: 36.7s\n",
            "526:\ttotal: 40.8s\tremaining: 36.6s\n",
            "527:\ttotal: 40.8s\tremaining: 36.5s\n",
            "528:\ttotal: 40.8s\tremaining: 36.3s\n",
            "529:\ttotal: 40.8s\tremaining: 36.2s\n",
            "530:\tlearn: 0.0061763\ttest: 0.0061763\tbest: 0.0061763 (530)\ttotal: 41.1s\tremaining: 36.3s\n",
            "531:\ttotal: 41.1s\tremaining: 36.2s\n",
            "532:\ttotal: 41.1s\tremaining: 36s\n",
            "533:\ttotal: 41.1s\tremaining: 35.9s\n",
            "534:\ttotal: 41.2s\tremaining: 35.8s\n",
            "535:\tlearn: 0.0061631\ttest: 0.0061631\tbest: 0.0061631 (535)\ttotal: 41.4s\tremaining: 35.8s\n",
            "536:\ttotal: 41.4s\tremaining: 35.7s\n",
            "537:\ttotal: 41.4s\tremaining: 35.6s\n",
            "538:\ttotal: 41.5s\tremaining: 35.5s\n",
            "539:\ttotal: 41.5s\tremaining: 35.3s\n",
            "540:\tlearn: 0.0061496\ttest: 0.0061496\tbest: 0.0061496 (540)\ttotal: 41.7s\tremaining: 35.4s\n",
            "541:\ttotal: 41.7s\tremaining: 35.3s\n",
            "542:\ttotal: 41.8s\tremaining: 35.1s\n",
            "543:\ttotal: 41.8s\tremaining: 35s\n",
            "544:\ttotal: 41.8s\tremaining: 34.9s\n",
            "545:\tlearn: 0.0061333\ttest: 0.0061333\tbest: 0.0061333 (545)\ttotal: 42s\tremaining: 35s\n",
            "546:\ttotal: 42.1s\tremaining: 34.8s\n",
            "547:\ttotal: 42.1s\tremaining: 34.7s\n",
            "548:\ttotal: 42.1s\tremaining: 34.6s\n",
            "549:\ttotal: 42.1s\tremaining: 34.5s\n",
            "550:\tlearn: 0.0061172\ttest: 0.0061172\tbest: 0.0061172 (550)\ttotal: 42.4s\tremaining: 34.5s\n",
            "551:\ttotal: 42.4s\tremaining: 34.4s\n",
            "552:\ttotal: 42.4s\tremaining: 34.3s\n",
            "553:\ttotal: 42.4s\tremaining: 34.2s\n",
            "554:\ttotal: 42.5s\tremaining: 34.1s\n",
            "555:\tlearn: 0.0061033\ttest: 0.0061033\tbest: 0.0061033 (555)\ttotal: 42.7s\tremaining: 34.1s\n",
            "556:\ttotal: 42.7s\tremaining: 34s\n",
            "557:\ttotal: 42.7s\tremaining: 33.9s\n",
            "558:\ttotal: 42.8s\tremaining: 33.7s\n",
            "559:\ttotal: 42.8s\tremaining: 33.6s\n",
            "560:\tlearn: 0.0060937\ttest: 0.0060937\tbest: 0.0060937 (560)\ttotal: 43s\tremaining: 33.7s\n",
            "561:\ttotal: 43s\tremaining: 33.5s\n",
            "562:\ttotal: 43.1s\tremaining: 33.4s\n",
            "563:\ttotal: 43.1s\tremaining: 33.3s\n",
            "564:\ttotal: 43.1s\tremaining: 33.2s\n",
            "565:\tlearn: 0.0060807\ttest: 0.0060807\tbest: 0.0060807 (565)\ttotal: 43.3s\tremaining: 33.2s\n",
            "566:\ttotal: 43.4s\tremaining: 33.1s\n",
            "567:\ttotal: 43.4s\tremaining: 33s\n",
            "568:\ttotal: 43.4s\tremaining: 32.9s\n",
            "569:\ttotal: 43.4s\tremaining: 32.8s\n",
            "570:\tlearn: 0.0060611\ttest: 0.0060611\tbest: 0.0060611 (570)\ttotal: 43.7s\tremaining: 32.8s\n",
            "571:\ttotal: 43.7s\tremaining: 32.7s\n",
            "572:\ttotal: 43.7s\tremaining: 32.6s\n",
            "573:\ttotal: 43.7s\tremaining: 32.5s\n",
            "574:\ttotal: 43.8s\tremaining: 32.3s\n",
            "575:\tlearn: 0.0060423\ttest: 0.0060423\tbest: 0.0060423 (575)\ttotal: 44s\tremaining: 32.4s\n",
            "576:\ttotal: 44s\tremaining: 32.3s\n",
            "577:\ttotal: 44s\tremaining: 32.1s\n",
            "578:\ttotal: 44.1s\tremaining: 32s\n",
            "579:\ttotal: 44.1s\tremaining: 31.9s\n",
            "580:\tlearn: 0.0060302\ttest: 0.0060302\tbest: 0.0060302 (580)\ttotal: 44.3s\tremaining: 32s\n",
            "581:\ttotal: 44.3s\tremaining: 31.8s\n",
            "582:\ttotal: 44.4s\tremaining: 31.7s\n",
            "583:\ttotal: 44.4s\tremaining: 31.6s\n",
            "584:\ttotal: 44.4s\tremaining: 31.5s\n",
            "585:\tlearn: 0.0060215\ttest: 0.0060215\tbest: 0.0060215 (585)\ttotal: 44.6s\tremaining: 31.5s\n",
            "586:\ttotal: 44.7s\tremaining: 31.4s\n",
            "587:\ttotal: 44.7s\tremaining: 31.3s\n",
            "588:\ttotal: 44.7s\tremaining: 31.2s\n",
            "589:\ttotal: 44.7s\tremaining: 31.1s\n",
            "590:\tlearn: 0.0060001\ttest: 0.0060001\tbest: 0.0060001 (590)\ttotal: 45s\tremaining: 31.1s\n",
            "591:\ttotal: 45s\tremaining: 31s\n",
            "592:\ttotal: 45s\tremaining: 30.9s\n",
            "593:\ttotal: 45s\tremaining: 30.8s\n",
            "594:\ttotal: 45.1s\tremaining: 30.7s\n",
            "595:\tlearn: 0.0059870\ttest: 0.0059870\tbest: 0.0059870 (595)\ttotal: 45.3s\tremaining: 30.7s\n",
            "596:\ttotal: 45.3s\tremaining: 30.6s\n",
            "597:\ttotal: 45.4s\tremaining: 30.5s\n",
            "598:\ttotal: 45.4s\tremaining: 30.4s\n",
            "599:\ttotal: 45.4s\tremaining: 30.3s\n",
            "600:\tlearn: 0.0059722\ttest: 0.0059722\tbest: 0.0059722 (600)\ttotal: 45.7s\tremaining: 30.3s\n",
            "601:\ttotal: 45.7s\tremaining: 30.2s\n",
            "602:\ttotal: 45.7s\tremaining: 30.1s\n",
            "603:\ttotal: 45.7s\tremaining: 30s\n",
            "604:\ttotal: 45.8s\tremaining: 29.9s\n",
            "605:\tlearn: 0.0059591\ttest: 0.0059591\tbest: 0.0059591 (605)\ttotal: 46s\tremaining: 29.9s\n",
            "606:\ttotal: 46s\tremaining: 29.8s\n",
            "607:\ttotal: 46s\tremaining: 29.7s\n",
            "608:\ttotal: 46.1s\tremaining: 29.6s\n",
            "609:\ttotal: 46.1s\tremaining: 29.5s\n",
            "610:\tlearn: 0.0059478\ttest: 0.0059478\tbest: 0.0059478 (610)\ttotal: 46.3s\tremaining: 29.5s\n",
            "611:\ttotal: 46.4s\tremaining: 29.4s\n",
            "612:\ttotal: 46.4s\tremaining: 29.3s\n",
            "613:\ttotal: 46.4s\tremaining: 29.2s\n",
            "614:\ttotal: 46.4s\tremaining: 29.1s\n",
            "615:\tlearn: 0.0059249\ttest: 0.0059249\tbest: 0.0059249 (615)\ttotal: 46.7s\tremaining: 29.1s\n",
            "616:\ttotal: 46.7s\tremaining: 29s\n",
            "617:\ttotal: 46.7s\tremaining: 28.9s\n",
            "618:\ttotal: 46.7s\tremaining: 28.8s\n",
            "619:\ttotal: 46.8s\tremaining: 28.7s\n",
            "620:\tlearn: 0.0059090\ttest: 0.0059090\tbest: 0.0059090 (620)\ttotal: 47s\tremaining: 28.7s\n",
            "621:\ttotal: 47s\tremaining: 28.6s\n",
            "622:\ttotal: 47.1s\tremaining: 28.5s\n",
            "623:\ttotal: 47.1s\tremaining: 28.4s\n",
            "624:\ttotal: 47.1s\tremaining: 28.3s\n",
            "625:\tlearn: 0.0058951\ttest: 0.0058951\tbest: 0.0058951 (625)\ttotal: 47.3s\tremaining: 28.3s\n",
            "626:\ttotal: 47.3s\tremaining: 28.2s\n",
            "627:\ttotal: 47.4s\tremaining: 28.1s\n",
            "628:\ttotal: 47.4s\tremaining: 28s\n",
            "629:\ttotal: 47.4s\tremaining: 27.8s\n",
            "630:\tlearn: 0.0058785\ttest: 0.0058785\tbest: 0.0058785 (630)\ttotal: 47.8s\tremaining: 27.9s\n",
            "631:\ttotal: 47.8s\tremaining: 27.8s\n",
            "632:\ttotal: 47.9s\tremaining: 27.8s\n",
            "633:\ttotal: 48s\tremaining: 27.7s\n",
            "634:\ttotal: 48s\tremaining: 27.6s\n",
            "635:\tlearn: 0.0058704\ttest: 0.0058704\tbest: 0.0058704 (635)\ttotal: 48.5s\tremaining: 27.7s\n",
            "636:\ttotal: 48.5s\tremaining: 27.7s\n",
            "637:\ttotal: 48.6s\tremaining: 27.6s\n",
            "638:\ttotal: 48.6s\tremaining: 27.5s\n",
            "639:\ttotal: 48.7s\tremaining: 27.4s\n",
            "640:\tlearn: 0.0058531\ttest: 0.0058531\tbest: 0.0058531 (640)\ttotal: 49.1s\tremaining: 27.5s\n",
            "641:\ttotal: 49.2s\tremaining: 27.4s\n",
            "642:\ttotal: 49.2s\tremaining: 27.3s\n",
            "643:\ttotal: 49.3s\tremaining: 27.3s\n",
            "644:\ttotal: 49.4s\tremaining: 27.2s\n",
            "645:\tlearn: 0.0058385\ttest: 0.0058385\tbest: 0.0058385 (645)\ttotal: 49.8s\tremaining: 27.3s\n",
            "646:\ttotal: 49.9s\tremaining: 27.2s\n",
            "647:\ttotal: 50s\tremaining: 27.1s\n",
            "648:\ttotal: 50.1s\tremaining: 27.1s\n",
            "649:\ttotal: 50.1s\tremaining: 27s\n",
            "650:\tlearn: 0.0058335\ttest: 0.0058335\tbest: 0.0058335 (650)\ttotal: 50.6s\tremaining: 27.1s\n",
            "651:\ttotal: 50.7s\tremaining: 27s\n",
            "652:\ttotal: 50.8s\tremaining: 27s\n",
            "653:\ttotal: 50.8s\tremaining: 26.9s\n",
            "654:\ttotal: 50.9s\tremaining: 26.8s\n",
            "655:\tlearn: 0.0058268\ttest: 0.0058268\tbest: 0.0058268 (655)\ttotal: 51.4s\tremaining: 26.9s\n",
            "656:\ttotal: 51.4s\tremaining: 26.8s\n",
            "657:\ttotal: 51.4s\tremaining: 26.7s\n",
            "658:\ttotal: 51.5s\tremaining: 26.6s\n",
            "659:\ttotal: 51.5s\tremaining: 26.5s\n",
            "660:\tlearn: 0.0058140\ttest: 0.0058140\tbest: 0.0058140 (660)\ttotal: 51.8s\tremaining: 26.5s\n",
            "661:\ttotal: 51.8s\tremaining: 26.4s\n",
            "662:\ttotal: 51.8s\tremaining: 26.3s\n",
            "663:\ttotal: 51.8s\tremaining: 26.2s\n",
            "664:\ttotal: 51.9s\tremaining: 26.1s\n",
            "665:\tlearn: 0.0058024\ttest: 0.0058024\tbest: 0.0058024 (665)\ttotal: 52.1s\tremaining: 26.1s\n",
            "666:\ttotal: 52.1s\tremaining: 26s\n",
            "667:\ttotal: 52.1s\tremaining: 25.9s\n",
            "668:\ttotal: 52.2s\tremaining: 25.8s\n",
            "669:\ttotal: 52.2s\tremaining: 25.7s\n",
            "670:\tlearn: 0.0057891\ttest: 0.0057891\tbest: 0.0057891 (670)\ttotal: 52.4s\tremaining: 25.7s\n",
            "671:\ttotal: 52.5s\tremaining: 25.6s\n",
            "672:\ttotal: 52.5s\tremaining: 25.5s\n",
            "673:\ttotal: 52.5s\tremaining: 25.4s\n",
            "674:\ttotal: 52.5s\tremaining: 25.3s\n",
            "675:\tlearn: 0.0057732\ttest: 0.0057732\tbest: 0.0057732 (675)\ttotal: 52.8s\tremaining: 25.3s\n",
            "676:\ttotal: 52.8s\tremaining: 25.2s\n",
            "677:\ttotal: 52.8s\tremaining: 25.1s\n",
            "678:\ttotal: 52.8s\tremaining: 25s\n",
            "679:\ttotal: 52.8s\tremaining: 24.9s\n",
            "680:\tlearn: 0.0057564\ttest: 0.0057564\tbest: 0.0057564 (680)\ttotal: 53.1s\tremaining: 24.9s\n",
            "681:\ttotal: 53.1s\tremaining: 24.8s\n",
            "682:\ttotal: 53.1s\tremaining: 24.7s\n",
            "683:\ttotal: 53.1s\tremaining: 24.6s\n",
            "684:\ttotal: 53.2s\tremaining: 24.4s\n",
            "685:\tlearn: 0.0057470\ttest: 0.0057470\tbest: 0.0057470 (685)\ttotal: 53.4s\tremaining: 24.4s\n",
            "686:\ttotal: 53.4s\tremaining: 24.3s\n",
            "687:\ttotal: 53.4s\tremaining: 24.2s\n",
            "688:\ttotal: 53.5s\tremaining: 24.1s\n",
            "689:\ttotal: 53.5s\tremaining: 24s\n",
            "690:\tlearn: 0.0057187\ttest: 0.0057187\tbest: 0.0057187 (690)\ttotal: 53.7s\tremaining: 24s\n",
            "691:\ttotal: 53.8s\tremaining: 23.9s\n",
            "692:\ttotal: 53.8s\tremaining: 23.8s\n",
            "693:\ttotal: 53.8s\tremaining: 23.7s\n",
            "694:\ttotal: 53.8s\tremaining: 23.6s\n",
            "695:\tlearn: 0.0057096\ttest: 0.0057096\tbest: 0.0057096 (695)\ttotal: 54.1s\tremaining: 23.6s\n",
            "696:\ttotal: 54.1s\tremaining: 23.5s\n",
            "697:\ttotal: 54.1s\tremaining: 23.4s\n",
            "698:\ttotal: 54.1s\tremaining: 23.3s\n",
            "699:\ttotal: 54.1s\tremaining: 23.2s\n",
            "700:\tlearn: 0.0056967\ttest: 0.0056967\tbest: 0.0056967 (700)\ttotal: 54.4s\tremaining: 23.2s\n",
            "701:\ttotal: 54.4s\tremaining: 23.1s\n",
            "702:\ttotal: 54.4s\tremaining: 23s\n",
            "703:\ttotal: 54.5s\tremaining: 22.9s\n",
            "704:\ttotal: 54.5s\tremaining: 22.8s\n",
            "705:\tlearn: 0.0056845\ttest: 0.0056845\tbest: 0.0056845 (705)\ttotal: 54.7s\tremaining: 22.8s\n",
            "706:\ttotal: 54.8s\tremaining: 22.7s\n",
            "707:\ttotal: 54.8s\tremaining: 22.6s\n",
            "708:\ttotal: 54.8s\tremaining: 22.5s\n",
            "709:\ttotal: 54.8s\tremaining: 22.4s\n",
            "710:\tlearn: 0.0056676\ttest: 0.0056676\tbest: 0.0056676 (710)\ttotal: 55.1s\tremaining: 22.4s\n",
            "711:\ttotal: 55.1s\tremaining: 22.3s\n",
            "712:\ttotal: 55.1s\tremaining: 22.2s\n",
            "713:\ttotal: 55.1s\tremaining: 22.1s\n",
            "714:\ttotal: 55.1s\tremaining: 22s\n",
            "715:\tlearn: 0.0056586\ttest: 0.0056586\tbest: 0.0056586 (715)\ttotal: 55.4s\tremaining: 22s\n",
            "716:\ttotal: 55.4s\tremaining: 21.9s\n",
            "717:\ttotal: 55.4s\tremaining: 21.8s\n",
            "718:\ttotal: 55.4s\tremaining: 21.7s\n",
            "719:\ttotal: 55.5s\tremaining: 21.6s\n",
            "720:\tlearn: 0.0056476\ttest: 0.0056476\tbest: 0.0056476 (720)\ttotal: 55.7s\tremaining: 21.6s\n",
            "721:\ttotal: 55.7s\tremaining: 21.5s\n",
            "722:\ttotal: 55.7s\tremaining: 21.4s\n",
            "723:\ttotal: 55.8s\tremaining: 21.3s\n",
            "724:\ttotal: 55.8s\tremaining: 21.2s\n",
            "725:\tlearn: 0.0056390\ttest: 0.0056390\tbest: 0.0056390 (725)\ttotal: 56s\tremaining: 21.1s\n",
            "726:\ttotal: 56.1s\tremaining: 21.1s\n",
            "727:\ttotal: 56.1s\tremaining: 21s\n",
            "728:\ttotal: 56.1s\tremaining: 20.9s\n",
            "729:\ttotal: 56.1s\tremaining: 20.8s\n",
            "730:\tlearn: 0.0056312\ttest: 0.0056312\tbest: 0.0056312 (730)\ttotal: 56.4s\tremaining: 20.7s\n",
            "731:\ttotal: 56.4s\tremaining: 20.6s\n",
            "732:\ttotal: 56.4s\tremaining: 20.6s\n",
            "733:\ttotal: 56.5s\tremaining: 20.5s\n",
            "734:\ttotal: 56.5s\tremaining: 20.4s\n",
            "735:\tlearn: 0.0056214\ttest: 0.0056214\tbest: 0.0056214 (735)\ttotal: 56.7s\tremaining: 20.4s\n",
            "736:\ttotal: 56.8s\tremaining: 20.3s\n",
            "737:\ttotal: 56.8s\tremaining: 20.2s\n",
            "738:\ttotal: 56.8s\tremaining: 20.1s\n",
            "739:\ttotal: 56.8s\tremaining: 20s\n",
            "740:\tlearn: 0.0056132\ttest: 0.0056132\tbest: 0.0056132 (740)\ttotal: 57.1s\tremaining: 19.9s\n",
            "741:\ttotal: 57.1s\tremaining: 19.8s\n",
            "742:\ttotal: 57.1s\tremaining: 19.8s\n",
            "743:\ttotal: 57.1s\tremaining: 19.7s\n",
            "744:\ttotal: 57.2s\tremaining: 19.6s\n",
            "745:\tlearn: 0.0056077\ttest: 0.0056077\tbest: 0.0056077 (745)\ttotal: 57.4s\tremaining: 19.5s\n",
            "746:\ttotal: 57.4s\tremaining: 19.5s\n",
            "747:\ttotal: 57.5s\tremaining: 19.4s\n",
            "748:\ttotal: 57.5s\tremaining: 19.3s\n",
            "749:\ttotal: 57.5s\tremaining: 19.2s\n",
            "750:\tlearn: 0.0056014\ttest: 0.0056014\tbest: 0.0056014 (750)\ttotal: 57.7s\tremaining: 19.1s\n",
            "751:\ttotal: 57.8s\tremaining: 19.1s\n",
            "752:\ttotal: 57.8s\tremaining: 19s\n",
            "753:\ttotal: 57.8s\tremaining: 18.9s\n",
            "754:\ttotal: 57.8s\tremaining: 18.8s\n",
            "755:\tlearn: 0.0055919\ttest: 0.0055919\tbest: 0.0055919 (755)\ttotal: 58.1s\tremaining: 18.7s\n",
            "756:\ttotal: 58.1s\tremaining: 18.7s\n",
            "757:\ttotal: 58.1s\tremaining: 18.6s\n",
            "758:\ttotal: 58.2s\tremaining: 18.5s\n",
            "759:\ttotal: 58.2s\tremaining: 18.4s\n",
            "760:\tlearn: 0.0055808\ttest: 0.0055808\tbest: 0.0055808 (760)\ttotal: 58.4s\tremaining: 18.3s\n",
            "761:\ttotal: 58.5s\tremaining: 18.3s\n",
            "762:\ttotal: 58.5s\tremaining: 18.2s\n",
            "763:\ttotal: 58.5s\tremaining: 18.1s\n",
            "764:\ttotal: 58.5s\tremaining: 18s\n",
            "765:\tlearn: 0.0055672\ttest: 0.0055672\tbest: 0.0055672 (765)\ttotal: 58.8s\tremaining: 18s\n",
            "766:\ttotal: 58.8s\tremaining: 17.9s\n",
            "767:\ttotal: 58.8s\tremaining: 17.8s\n",
            "768:\ttotal: 58.8s\tremaining: 17.7s\n",
            "769:\ttotal: 58.9s\tremaining: 17.6s\n",
            "770:\tlearn: 0.0055583\ttest: 0.0055583\tbest: 0.0055583 (770)\ttotal: 59.1s\tremaining: 17.6s\n",
            "771:\ttotal: 59.1s\tremaining: 17.5s\n",
            "772:\ttotal: 59.1s\tremaining: 17.4s\n",
            "773:\ttotal: 59.2s\tremaining: 17.3s\n",
            "774:\ttotal: 59.2s\tremaining: 17.2s\n",
            "775:\tlearn: 0.0055487\ttest: 0.0055487\tbest: 0.0055487 (775)\ttotal: 59.4s\tremaining: 17.2s\n",
            "776:\ttotal: 59.5s\tremaining: 17.1s\n",
            "777:\ttotal: 59.5s\tremaining: 17s\n",
            "778:\ttotal: 59.5s\tremaining: 16.9s\n",
            "779:\ttotal: 59.5s\tremaining: 16.8s\n",
            "780:\tlearn: 0.0055357\ttest: 0.0055357\tbest: 0.0055357 (780)\ttotal: 59.8s\tremaining: 16.8s\n",
            "781:\ttotal: 59.8s\tremaining: 16.7s\n",
            "782:\ttotal: 59.8s\tremaining: 16.6s\n",
            "783:\ttotal: 59.8s\tremaining: 16.5s\n",
            "784:\ttotal: 59.9s\tremaining: 16.4s\n",
            "785:\tlearn: 0.0055253\ttest: 0.0055253\tbest: 0.0055253 (785)\ttotal: 1m\tremaining: 16.4s\n",
            "786:\ttotal: 1m\tremaining: 16.3s\n",
            "787:\ttotal: 1m\tremaining: 16.2s\n",
            "788:\ttotal: 1m\tremaining: 16.1s\n",
            "789:\ttotal: 1m\tremaining: 16s\n",
            "790:\tlearn: 0.0055187\ttest: 0.0055187\tbest: 0.0055187 (790)\ttotal: 1m\tremaining: 16s\n",
            "791:\ttotal: 1m\tremaining: 15.9s\n",
            "792:\ttotal: 1m\tremaining: 15.8s\n",
            "793:\ttotal: 1m\tremaining: 15.7s\n",
            "794:\ttotal: 1m\tremaining: 15.6s\n",
            "795:\tlearn: 0.0055149\ttest: 0.0055149\tbest: 0.0055149 (795)\ttotal: 1m\tremaining: 15.6s\n",
            "796:\ttotal: 1m\tremaining: 15.5s\n",
            "797:\ttotal: 1m\tremaining: 15.4s\n",
            "798:\ttotal: 1m\tremaining: 15.3s\n",
            "799:\ttotal: 1m\tremaining: 15.2s\n",
            "800:\tlearn: 0.0055064\ttest: 0.0055064\tbest: 0.0055064 (800)\ttotal: 1m 1s\tremaining: 15.2s\n",
            "801:\ttotal: 1m 1s\tremaining: 15.1s\n",
            "802:\ttotal: 1m 1s\tremaining: 15s\n",
            "803:\ttotal: 1m 1s\tremaining: 14.9s\n",
            "804:\ttotal: 1m 1s\tremaining: 14.8s\n",
            "805:\tlearn: 0.0054993\ttest: 0.0054993\tbest: 0.0054993 (805)\ttotal: 1m 1s\tremaining: 14.8s\n",
            "806:\ttotal: 1m 1s\tremaining: 14.7s\n",
            "807:\ttotal: 1m 1s\tremaining: 14.6s\n",
            "808:\ttotal: 1m 1s\tremaining: 14.5s\n",
            "809:\ttotal: 1m 1s\tremaining: 14.5s\n",
            "810:\tlearn: 0.0054945\ttest: 0.0054945\tbest: 0.0054945 (810)\ttotal: 1m 2s\tremaining: 14.5s\n",
            "811:\ttotal: 1m 2s\tremaining: 14.4s\n",
            "812:\ttotal: 1m 2s\tremaining: 14.3s\n",
            "813:\ttotal: 1m 2s\tremaining: 14.2s\n",
            "814:\ttotal: 1m 2s\tremaining: 14.1s\n",
            "815:\tlearn: 0.0054900\ttest: 0.0054900\tbest: 0.0054900 (815)\ttotal: 1m 2s\tremaining: 14.2s\n",
            "816:\ttotal: 1m 2s\tremaining: 14.1s\n",
            "817:\ttotal: 1m 2s\tremaining: 14s\n",
            "818:\ttotal: 1m 2s\tremaining: 13.9s\n",
            "819:\ttotal: 1m 3s\tremaining: 13.8s\n",
            "820:\tlearn: 0.0054853\ttest: 0.0054853\tbest: 0.0054853 (820)\ttotal: 1m 3s\tremaining: 13.8s\n",
            "821:\ttotal: 1m 3s\tremaining: 13.8s\n",
            "822:\ttotal: 1m 3s\tremaining: 13.7s\n",
            "823:\ttotal: 1m 3s\tremaining: 13.6s\n",
            "824:\ttotal: 1m 3s\tremaining: 13.5s\n",
            "825:\tlearn: 0.0054759\ttest: 0.0054759\tbest: 0.0054759 (825)\ttotal: 1m 4s\tremaining: 13.5s\n",
            "826:\ttotal: 1m 4s\tremaining: 13.5s\n",
            "827:\ttotal: 1m 4s\tremaining: 13.4s\n",
            "828:\ttotal: 1m 4s\tremaining: 13.3s\n",
            "829:\ttotal: 1m 4s\tremaining: 13.2s\n",
            "830:\tlearn: 0.0054687\ttest: 0.0054687\tbest: 0.0054687 (830)\ttotal: 1m 5s\tremaining: 13.2s\n",
            "831:\ttotal: 1m 5s\tremaining: 13.2s\n",
            "832:\ttotal: 1m 5s\tremaining: 13.1s\n",
            "833:\ttotal: 1m 5s\tremaining: 13s\n",
            "834:\ttotal: 1m 5s\tremaining: 12.9s\n",
            "835:\tlearn: 0.0054629\ttest: 0.0054629\tbest: 0.0054629 (835)\ttotal: 1m 5s\tremaining: 12.8s\n",
            "836:\ttotal: 1m 5s\tremaining: 12.8s\n",
            "837:\ttotal: 1m 5s\tremaining: 12.7s\n",
            "838:\ttotal: 1m 5s\tremaining: 12.6s\n",
            "839:\ttotal: 1m 5s\tremaining: 12.5s\n",
            "840:\tlearn: 0.0054551\ttest: 0.0054551\tbest: 0.0054551 (840)\ttotal: 1m 5s\tremaining: 12.4s\n",
            "841:\ttotal: 1m 5s\tremaining: 12.4s\n",
            "842:\ttotal: 1m 5s\tremaining: 12.3s\n",
            "843:\ttotal: 1m 5s\tremaining: 12.2s\n",
            "844:\ttotal: 1m 5s\tremaining: 12.1s\n",
            "845:\tlearn: 0.0054486\ttest: 0.0054486\tbest: 0.0054486 (845)\ttotal: 1m 6s\tremaining: 12s\n",
            "846:\ttotal: 1m 6s\tremaining: 12s\n",
            "847:\ttotal: 1m 6s\tremaining: 11.9s\n",
            "848:\ttotal: 1m 6s\tremaining: 11.8s\n",
            "849:\ttotal: 1m 6s\tremaining: 11.7s\n",
            "850:\tlearn: 0.0054430\ttest: 0.0054430\tbest: 0.0054430 (850)\ttotal: 1m 6s\tremaining: 11.6s\n",
            "851:\ttotal: 1m 6s\tremaining: 11.6s\n",
            "852:\ttotal: 1m 6s\tremaining: 11.5s\n",
            "853:\ttotal: 1m 6s\tremaining: 11.4s\n",
            "854:\ttotal: 1m 6s\tremaining: 11.3s\n",
            "855:\tlearn: 0.0054381\ttest: 0.0054381\tbest: 0.0054381 (855)\ttotal: 1m 6s\tremaining: 11.2s\n",
            "856:\ttotal: 1m 6s\tremaining: 11.2s\n",
            "857:\ttotal: 1m 6s\tremaining: 11.1s\n",
            "858:\ttotal: 1m 6s\tremaining: 11s\n",
            "859:\ttotal: 1m 6s\tremaining: 10.9s\n",
            "860:\tlearn: 0.0054305\ttest: 0.0054305\tbest: 0.0054305 (860)\ttotal: 1m 7s\tremaining: 10.8s\n",
            "861:\ttotal: 1m 7s\tremaining: 10.8s\n",
            "862:\ttotal: 1m 7s\tremaining: 10.7s\n",
            "863:\ttotal: 1m 7s\tremaining: 10.6s\n",
            "864:\ttotal: 1m 7s\tremaining: 10.5s\n",
            "865:\tlearn: 0.0054228\ttest: 0.0054228\tbest: 0.0054228 (865)\ttotal: 1m 7s\tremaining: 10.4s\n",
            "866:\ttotal: 1m 7s\tremaining: 10.4s\n",
            "867:\ttotal: 1m 7s\tremaining: 10.3s\n",
            "868:\ttotal: 1m 7s\tremaining: 10.2s\n",
            "869:\ttotal: 1m 7s\tremaining: 10.1s\n",
            "870:\tlearn: 0.0054163\ttest: 0.0054163\tbest: 0.0054163 (870)\ttotal: 1m 7s\tremaining: 10s\n",
            "871:\ttotal: 1m 7s\tremaining: 9.96s\n",
            "872:\ttotal: 1m 7s\tremaining: 9.87s\n",
            "873:\ttotal: 1m 7s\tremaining: 9.79s\n",
            "874:\ttotal: 1m 7s\tremaining: 9.7s\n",
            "875:\tlearn: 0.0054065\ttest: 0.0054065\tbest: 0.0054065 (875)\ttotal: 1m 8s\tremaining: 9.64s\n",
            "876:\ttotal: 1m 8s\tremaining: 9.56s\n",
            "877:\ttotal: 1m 8s\tremaining: 9.47s\n",
            "878:\ttotal: 1m 8s\tremaining: 9.39s\n",
            "879:\ttotal: 1m 8s\tremaining: 9.3s\n",
            "880:\tlearn: 0.0053956\ttest: 0.0053956\tbest: 0.0053956 (880)\ttotal: 1m 8s\tremaining: 9.25s\n",
            "881:\ttotal: 1m 8s\tremaining: 9.16s\n",
            "882:\ttotal: 1m 8s\tremaining: 9.08s\n",
            "883:\ttotal: 1m 8s\tremaining: 8.99s\n",
            "884:\ttotal: 1m 8s\tremaining: 8.91s\n",
            "885:\tlearn: 0.0053882\ttest: 0.0053882\tbest: 0.0053882 (885)\ttotal: 1m 8s\tremaining: 8.85s\n",
            "886:\ttotal: 1m 8s\tremaining: 8.77s\n",
            "887:\ttotal: 1m 8s\tremaining: 8.68s\n",
            "888:\ttotal: 1m 8s\tremaining: 8.6s\n",
            "889:\ttotal: 1m 8s\tremaining: 8.51s\n",
            "890:\tlearn: 0.0053831\ttest: 0.0053831\tbest: 0.0053831 (890)\ttotal: 1m 9s\tremaining: 8.45s\n",
            "891:\ttotal: 1m 9s\tremaining: 8.37s\n",
            "892:\ttotal: 1m 9s\tremaining: 8.28s\n",
            "893:\ttotal: 1m 9s\tremaining: 8.2s\n",
            "894:\ttotal: 1m 9s\tremaining: 8.12s\n",
            "895:\tlearn: 0.0053718\ttest: 0.0053718\tbest: 0.0053718 (895)\ttotal: 1m 9s\tremaining: 8.06s\n",
            "896:\ttotal: 1m 9s\tremaining: 7.97s\n",
            "897:\ttotal: 1m 9s\tremaining: 7.89s\n",
            "898:\ttotal: 1m 9s\tremaining: 7.81s\n",
            "899:\ttotal: 1m 9s\tremaining: 7.73s\n",
            "900:\tlearn: 0.0053671\ttest: 0.0053671\tbest: 0.0053671 (900)\ttotal: 1m 9s\tremaining: 7.67s\n",
            "901:\ttotal: 1m 9s\tremaining: 7.58s\n",
            "902:\ttotal: 1m 9s\tremaining: 7.5s\n",
            "903:\ttotal: 1m 9s\tremaining: 7.42s\n",
            "904:\ttotal: 1m 9s\tremaining: 7.34s\n",
            "905:\tlearn: 0.0053618\ttest: 0.0053618\tbest: 0.0053618 (905)\ttotal: 1m 10s\tremaining: 7.28s\n",
            "906:\ttotal: 1m 10s\tremaining: 7.19s\n",
            "907:\ttotal: 1m 10s\tremaining: 7.11s\n",
            "908:\ttotal: 1m 10s\tremaining: 7.03s\n",
            "909:\ttotal: 1m 10s\tremaining: 6.94s\n",
            "910:\tlearn: 0.0053589\ttest: 0.0053589\tbest: 0.0053589 (910)\ttotal: 1m 10s\tremaining: 6.88s\n",
            "911:\ttotal: 1m 10s\tremaining: 6.8s\n",
            "912:\ttotal: 1m 10s\tremaining: 6.72s\n",
            "913:\ttotal: 1m 10s\tremaining: 6.64s\n",
            "914:\ttotal: 1m 10s\tremaining: 6.55s\n",
            "915:\tlearn: 0.0053475\ttest: 0.0053475\tbest: 0.0053475 (915)\ttotal: 1m 10s\tremaining: 6.49s\n",
            "916:\ttotal: 1m 10s\tremaining: 6.41s\n",
            "917:\ttotal: 1m 10s\tremaining: 6.33s\n",
            "918:\ttotal: 1m 10s\tremaining: 6.25s\n",
            "919:\ttotal: 1m 10s\tremaining: 6.17s\n",
            "920:\tlearn: 0.0053436\ttest: 0.0053436\tbest: 0.0053436 (920)\ttotal: 1m 11s\tremaining: 6.1s\n",
            "921:\ttotal: 1m 11s\tremaining: 6.02s\n",
            "922:\ttotal: 1m 11s\tremaining: 5.94s\n",
            "923:\ttotal: 1m 11s\tremaining: 5.85s\n",
            "924:\ttotal: 1m 11s\tremaining: 5.77s\n",
            "925:\tlearn: 0.0053372\ttest: 0.0053372\tbest: 0.0053372 (925)\ttotal: 1m 11s\tremaining: 5.71s\n",
            "926:\ttotal: 1m 11s\tremaining: 5.63s\n",
            "927:\ttotal: 1m 11s\tremaining: 5.54s\n",
            "928:\ttotal: 1m 11s\tremaining: 5.46s\n",
            "929:\ttotal: 1m 11s\tremaining: 5.38s\n",
            "930:\tlearn: 0.0053295\ttest: 0.0053295\tbest: 0.0053295 (930)\ttotal: 1m 11s\tremaining: 5.32s\n",
            "931:\ttotal: 1m 11s\tremaining: 5.24s\n",
            "932:\ttotal: 1m 11s\tremaining: 5.16s\n",
            "933:\ttotal: 1m 11s\tremaining: 5.08s\n",
            "934:\ttotal: 1m 11s\tremaining: 5s\n",
            "935:\tlearn: 0.0053214\ttest: 0.0053214\tbest: 0.0053214 (935)\ttotal: 1m 12s\tremaining: 4.93s\n",
            "936:\ttotal: 1m 12s\tremaining: 4.85s\n",
            "937:\ttotal: 1m 12s\tremaining: 4.77s\n",
            "938:\ttotal: 1m 12s\tremaining: 4.69s\n",
            "939:\ttotal: 1m 12s\tremaining: 4.61s\n",
            "940:\tlearn: 0.0053115\ttest: 0.0053115\tbest: 0.0053115 (940)\ttotal: 1m 12s\tremaining: 4.54s\n",
            "941:\ttotal: 1m 12s\tremaining: 4.46s\n",
            "942:\ttotal: 1m 12s\tremaining: 4.38s\n",
            "943:\ttotal: 1m 12s\tremaining: 4.3s\n",
            "944:\ttotal: 1m 12s\tremaining: 4.22s\n",
            "945:\tlearn: 0.0053069\ttest: 0.0053069\tbest: 0.0053069 (945)\ttotal: 1m 12s\tremaining: 4.16s\n",
            "946:\ttotal: 1m 12s\tremaining: 4.08s\n",
            "947:\ttotal: 1m 12s\tremaining: 4s\n",
            "948:\ttotal: 1m 12s\tremaining: 3.92s\n",
            "949:\ttotal: 1m 12s\tremaining: 3.84s\n",
            "950:\tlearn: 0.0053006\ttest: 0.0053006\tbest: 0.0053006 (950)\ttotal: 1m 13s\tremaining: 3.77s\n",
            "951:\ttotal: 1m 13s\tremaining: 3.69s\n",
            "952:\ttotal: 1m 13s\tremaining: 3.61s\n",
            "953:\ttotal: 1m 13s\tremaining: 3.53s\n",
            "954:\ttotal: 1m 13s\tremaining: 3.45s\n",
            "955:\tlearn: 0.0052943\ttest: 0.0052943\tbest: 0.0052943 (955)\ttotal: 1m 13s\tremaining: 3.38s\n",
            "956:\ttotal: 1m 13s\tremaining: 3.3s\n",
            "957:\ttotal: 1m 13s\tremaining: 3.22s\n",
            "958:\ttotal: 1m 13s\tremaining: 3.14s\n",
            "959:\ttotal: 1m 13s\tremaining: 3.06s\n",
            "960:\tlearn: 0.0052907\ttest: 0.0052907\tbest: 0.0052907 (960)\ttotal: 1m 13s\tremaining: 2.99s\n",
            "961:\ttotal: 1m 13s\tremaining: 2.91s\n",
            "962:\ttotal: 1m 13s\tremaining: 2.83s\n",
            "963:\ttotal: 1m 13s\tremaining: 2.76s\n",
            "964:\ttotal: 1m 13s\tremaining: 2.68s\n",
            "965:\tlearn: 0.0052819\ttest: 0.0052819\tbest: 0.0052819 (965)\ttotal: 1m 14s\tremaining: 2.61s\n",
            "966:\ttotal: 1m 14s\tremaining: 2.53s\n",
            "967:\ttotal: 1m 14s\tremaining: 2.45s\n",
            "968:\ttotal: 1m 14s\tremaining: 2.37s\n",
            "969:\ttotal: 1m 14s\tremaining: 2.29s\n",
            "970:\tlearn: 0.0052749\ttest: 0.0052749\tbest: 0.0052749 (970)\ttotal: 1m 14s\tremaining: 2.22s\n",
            "971:\ttotal: 1m 14s\tremaining: 2.14s\n",
            "972:\ttotal: 1m 14s\tremaining: 2.06s\n",
            "973:\ttotal: 1m 14s\tremaining: 1.99s\n",
            "974:\ttotal: 1m 14s\tremaining: 1.91s\n",
            "975:\tlearn: 0.0052669\ttest: 0.0052669\tbest: 0.0052669 (975)\ttotal: 1m 14s\tremaining: 1.84s\n",
            "976:\ttotal: 1m 14s\tremaining: 1.76s\n",
            "977:\ttotal: 1m 14s\tremaining: 1.68s\n",
            "978:\ttotal: 1m 14s\tremaining: 1.6s\n",
            "979:\ttotal: 1m 14s\tremaining: 1.53s\n",
            "980:\tlearn: 0.0052577\ttest: 0.0052577\tbest: 0.0052577 (980)\ttotal: 1m 15s\tremaining: 1.45s\n",
            "981:\ttotal: 1m 15s\tremaining: 1.38s\n",
            "982:\ttotal: 1m 15s\tremaining: 1.3s\n",
            "983:\ttotal: 1m 15s\tremaining: 1.22s\n",
            "984:\ttotal: 1m 15s\tremaining: 1.15s\n",
            "985:\tlearn: 0.0052501\ttest: 0.0052501\tbest: 0.0052501 (985)\ttotal: 1m 15s\tremaining: 1.07s\n",
            "986:\ttotal: 1m 15s\tremaining: 998ms\n",
            "987:\ttotal: 1m 15s\tremaining: 921ms\n",
            "988:\ttotal: 1m 15s\tremaining: 844ms\n",
            "989:\ttotal: 1m 15s\tremaining: 767ms\n",
            "990:\tlearn: 0.0052457\ttest: 0.0052457\tbest: 0.0052457 (990)\ttotal: 1m 16s\tremaining: 694ms\n",
            "991:\ttotal: 1m 16s\tremaining: 617ms\n",
            "992:\ttotal: 1m 16s\tremaining: 540ms\n",
            "993:\ttotal: 1m 16s\tremaining: 463ms\n",
            "994:\ttotal: 1m 16s\tremaining: 386ms\n",
            "995:\tlearn: 0.0052388\ttest: 0.0052388\tbest: 0.0052388 (995)\ttotal: 1m 17s\tremaining: 310ms\n",
            "996:\ttotal: 1m 17s\tremaining: 232ms\n",
            "997:\ttotal: 1m 17s\tremaining: 155ms\n",
            "998:\ttotal: 1m 17s\tremaining: 77.5ms\n",
            "999:\tlearn: 0.0052333\ttest: 0.0052333\tbest: 0.0052333 (999)\ttotal: 1m 17s\tremaining: 0us\n",
            "bestTest = 0.005233300436\n",
            "bestIteration = 999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c1b69d0c4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nan_mode': 'Min', 'gpu_ram_part': 0.95, 'eval_metric': 'MultiClass', 'iterations': 1000, 'leaf_estimation_method': 'Newton', 'observations_to_bootstrap': 'TestOnly', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'devices': '-1', 'eval_fraction': 0, 'pinned_memory_bytes': '104857600', 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'gpu_cat_features_storage': 'GpuRam', 'fold_size_loss_normalization': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'use_best_model': True, 'meta_l2_frequency': 0, 'class_names': ['BENIGN', 'Bot', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS slowloris', 'FTP-Patator', 'Heartbleed', 'Infiltration', 'PortScan', 'SSH-Patator', 'Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ Sql Injection', 'Web Attack ÔøΩ XSS'], 'random_seed': 12345, 'depth': 6, 'border_count': 128, 'min_fold_size': 100, 'data_partition': 'DocParallel', 'bagging_temperature': 1, 'classes_count': 0, 'auto_class_weights': 'None', 'custom_metric': ['AUC'], 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'min_data_in_leaf': 1, 'add_ridge_penalty_to_loss_function': False, 'loss_function': 'MultiClass', 'learning_rate': 0.15000000596046448, 'meta_l2_exponent': 1, 'score_function': 'Cosine', 'task_type': 'GPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'Bayesian', 'max_leaves': 64}\n"
          ]
        }
      ],
      "source": [
        "# —É–ª—É—á—à–∞–µ–º CatBOOst\n",
        "\n",
        "model_bas_cb = CatBoostClassifier(task_type=\"GPU\",\n",
        "                                  random_state=12345,\n",
        "                                  learning_rate=0.15,\n",
        "                                  custom_loss=['AUC'],\n",
        "                                  )\n",
        "\n",
        "model_bas_cb.fit(features_train, target_train,\n",
        "                 eval_set=(features_train, target_train))\n",
        "\n",
        "print(model_bas_cb.get_all_params())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "j4M_JYukKTJ_",
      "metadata": {
        "id": "j4M_JYukKTJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7174759-dafa-426e-9e29-ad9e9eb54ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.997486709826833\n",
            "F1_macro: 0.9299855030838736\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      1.00      1.00     37244\n",
            "                  PortScan       0.94      0.98      0.96       312\n",
            "                  DoS Hulk       1.00      1.00      1.00     10298\n",
            "                      DDoS       1.00      1.00      1.00      1646\n",
            "                       Bot       1.00      1.00      1.00     13960\n",
            "              Infiltration       0.99      0.99      0.99       836\n",
            "  Web Attack ÔøΩ Brute Force       1.00      0.99      0.99       862\n",
            "          Web Attack ÔøΩ XSS       1.00      1.00      1.00       949\n",
            "Web Attack ÔøΩ Sql Injection       1.00      1.00      1.00         2\n",
            "               FTP-Patator       1.00      1.00      1.00         6\n",
            "               SSH-Patator       1.00      1.00      1.00      9024\n",
            "             DoS slowloris       1.00      1.00      1.00       515\n",
            "          DoS Slowhttptest       0.73      0.85      0.78       235\n",
            "             DoS GoldenEye       0.75      1.00      0.86         3\n",
            "                Heartbleed       0.48      0.30      0.37       104\n",
            "\n",
            "                  accuracy                           1.00     75996\n",
            "                 macro avg       0.93      0.94      0.93     75996\n",
            "              weighted avg       1.00      1.00      1.00     75996\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c1b69d0c4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "prediction(model_bas_cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ —Ç–∞–º –≤ –∫–ª–∞—Å—Å–µ Heartbleed. –ù–µ–ø–æ–Ω—è—Ç–Ω–æ –ø–æ—á–µ–º—É –æ–Ω —Ö—É–∂–µ –≤—Å–µ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è."
      ],
      "metadata": {
        "id": "JXYCifWL43BB"
      },
      "id": "JXYCifWL43BB"
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['Label']=='Heartbleed'].head(30)\n"
      ],
      "metadata": {
        "id": "oJzNAPlL41-2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "a6b50217-ffe0-42ee-b909-bbaeaeec2892"
      },
      "id": "oJzNAPlL41-2",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Destination Port   Flow Duration   Total Fwd Packets  \\\n",
              "534666               444       119302728                2685   \n",
              "534669               444       119262215                2792   \n",
              "534672               444       119261118                2794   \n",
              "534675               444       119260295                2791   \n",
              "534678               444       119297996                2782   \n",
              "534692               444       119259886                2782   \n",
              "534695               444       119259012                2801   \n",
              "534708               444       119257653                2802   \n",
              "534711               444       119299621                2805   \n",
              "534712               444       119296592                2797   \n",
              "534713               444        24719667                 590   \n",
              "\n",
              "         Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "534666                     1729                         8299   \n",
              "534669                     2110                        13712   \n",
              "534672                     2130                        12264   \n",
              "534675                     2114                        13712   \n",
              "534678                     2089                         9368   \n",
              "534692                     2091                        12264   \n",
              "534695                     2069                        12264   \n",
              "534708                     2067                        20858   \n",
              "534711                     2028                        13712   \n",
              "534712                     2006                        13712   \n",
              "534713                      436                         7442   \n",
              "\n",
              "         Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
              "534666                       7556917                     517   \n",
              "534669                       7878135                    5792   \n",
              "534672                       7879536                    4344   \n",
              "534675                       7878088                    5792   \n",
              "534678                       7882432                    1448   \n",
              "534692                       7879536                    4344   \n",
              "534695                       7879536                    4344   \n",
              "534708                       7812389                    5792   \n",
              "534711                       7878627                    5792   \n",
              "534712                       7878088                    5792   \n",
              "534713                       1636683                    5792   \n",
              "\n",
              "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
              "534666                       0                    3.092   \n",
              "534669                       0                    4.910   \n",
              "534672                       0                    4.390   \n",
              "534675                       0                    4.914   \n",
              "534678                       0                    3.367   \n",
              "534692                       0                    4.410   \n",
              "534695                       0                    4.380   \n",
              "534708                       0                    7.445   \n",
              "534711                       0                    4.887   \n",
              "534712                       0                    4.902   \n",
              "534713                       0                   12.620   \n",
              "\n",
              "         Fwd Packet Length Std  Bwd Packet Length Max   Bwd Packet Length Min  \\\n",
              "534666                   16.86                  17376                       0   \n",
              "534669                  110.40                  14480                       0   \n",
              "534672                   83.20                  13032                       0   \n",
              "534675                  110.40                  13032                       0   \n",
              "534678                   30.50                  17376                       0   \n",
              "534692                   83.40                  15928                       0   \n",
              "534695                   83.10                  15928                       0   \n",
              "534708                  126.06                  13032                       0   \n",
              "534711                  110.10                  17376                       0   \n",
              "534712                  110.25                  13032                       0   \n",
              "534713                  238.80                  13032                       0   \n",
              "\n",
              "         Bwd Packet Length Mean   Bwd Packet Length Std  Flow Bytes/s  \\\n",
              "534666                   4372.0                  2566.0   63411.92802   \n",
              "534669                   3734.0                  2366.0   66172.23234   \n",
              "534672                   3700.0                  2314.0   66172.44692   \n",
              "534675                   3726.0                  2284.0   66172.90356   \n",
              "534678                   3774.0                  2372.0   66151.99135   \n",
              "534692                   3768.0                  2374.0   66173.13050   \n",
              "534695                   3808.0                  2460.0   66173.61546   \n",
              "534708                   3780.0                  2380.0   65683.39057   \n",
              "534711                   3884.0                  2524.0   66155.60832   \n",
              "534712                   3928.0                  2444.0   66152.76990   \n",
              "534713                   3754.0                  2364.0   66510.80696   \n",
              "\n",
              "         Flow Packets/s   Flow IAT Mean   Flow IAT Std   Flow IAT Max  \\\n",
              "534666        36.998316       27034.383      174625.77        5024984   \n",
              "534669        41.102708       24334.262      152902.28         995350   \n",
              "534672        41.287555       24225.293      152596.56         995259   \n",
              "534675        41.128525       24318.984      152794.80         995259   \n",
              "534678        40.830527       24496.508      153244.69         995302   \n",
              "534692        40.860344       24478.630      153117.48         995232   \n",
              "534695        40.835488       24493.533      153287.53         995262   \n",
              "534708        40.827569       24498.285      153803.62        1995346   \n",
              "534711        40.511445       24689.490      152728.52         996008   \n",
              "534712        40.260999       24843.105      153403.72         995988   \n",
              "534713        41.505413       24116.748      149983.89         995832   \n",
              "\n",
              "         Flow IAT Min  Fwd IAT Total   Fwd IAT Mean   Fwd IAT Std  \\\n",
              "534666              0      119000000      44449.508     222461.72   \n",
              "534669              0      119000000      42730.980     200884.22   \n",
              "534672              0      119000000      42699.918     200852.50   \n",
              "534675             -1      119000000      42745.530     200841.34   \n",
              "534678              0      119000000      42897.500     201057.42   \n",
              "534692              0      119000000      42883.793     200919.11   \n",
              "534695              0      119000000      42592.480     200437.97   \n",
              "534708             -1      119000000      42576.800     201441.28   \n",
              "534711             -1      119000000      42531.965     199646.58   \n",
              "534712             -1      119000000      42666.880     200137.52   \n",
              "534713              0       24700000      41968.875     197466.20   \n",
              "\n",
              "         Fwd IAT Max   Fwd IAT Min  Bwd IAT Total   Bwd IAT Mean  \\\n",
              "534666       5025702             0      119000000      69040.910   \n",
              "534669        996350             0      119000000      56549.170   \n",
              "534672        996402             0      119000000      56017.426   \n",
              "534675        997791             0      119000000      56441.210   \n",
              "534678        998229             0      119000000      57135.035   \n",
              "534692        996222             0      119000000      57062.140   \n",
              "534695        996257             0      119000000      57668.760   \n",
              "534708       1996118             0      119000000      57723.930   \n",
              "534711        996884             0      119000000      58855.258   \n",
              "534712        996943             0      119000000      59480.766   \n",
              "534713        996919             0       24100000      55301.758   \n",
              "\n",
              "         Bwd IAT Std   Bwd IAT Max   Bwd IAT Min  Fwd PSH Flags  \\\n",
              "534666     273867.44       5024984             1              0   \n",
              "534669     229177.94        995350             1              0   \n",
              "534672     228206.64        995259             1              0   \n",
              "534675     228878.53        995259             1              0   \n",
              "534678     230051.98        995302             2              0   \n",
              "534692     229801.25        995232             1              0   \n",
              "534695     231138.53        995262             2              0   \n",
              "534708     233324.72       1995346             1              0   \n",
              "534711     232967.11        996008             1              0   \n",
              "534712     234233.89        995988             1              0   \n",
              "534713     225933.60        995832             2              0   \n",
              "\n",
              "         Bwd PSH Flags   Fwd URG Flags   Bwd URG Flags   Fwd Header Length  \\\n",
              "534666               0               0               0               85928   \n",
              "534669               0               0               0               89356   \n",
              "534672               0               0               0               89408   \n",
              "534675               0               0               0               89312   \n",
              "534678               0               0               0               89024   \n",
              "534692               0               0               0               89024   \n",
              "534695               0               0               0               89632   \n",
              "534708               0               0               0               89664   \n",
              "534711               0               0               0               89772   \n",
              "534712               0               0               0               89504   \n",
              "534713               0               0               0               18880   \n",
              "\n",
              "         Bwd Header Length  Fwd Packets/s   Bwd Packets/s   Min Packet Length  \\\n",
              "534666               55336      22.505772       14.492544                   0   \n",
              "534669               67520      23.410600       17.692108                   0   \n",
              "534672               68160      23.427586       17.859970                   0   \n",
              "534675               67648      23.402592       17.725933                   0   \n",
              "534678               66848      23.319756       17.510773                   0   \n",
              "534692               66912      23.327206       17.533138                   0   \n",
              "534695               66208      23.486694       17.348793                   0   \n",
              "534708               66144      23.495348       17.332220                   0   \n",
              "534711               64896      23.512228       16.999216                   0   \n",
              "534712               64192      23.445766       16.815233                   0   \n",
              "534713               13952      23.867636       17.637777                   0   \n",
              "\n",
              "         Max Packet Length   Packet Length Mean   Packet Length Std  \\\n",
              "534666               17376               1714.0              2670.0   \n",
              "534669               14480               1611.0              2414.0   \n",
              "534672               13032               1603.0              2382.0   \n",
              "534675               13032               1610.0              2378.0   \n",
              "534678               17376               1620.0              2428.0   \n",
              "534692               15928               1620.0              2428.0   \n",
              "534695               15928               1621.0              2472.0   \n",
              "534708               13032               1610.0              2428.0   \n",
              "534711               17376               1634.0              2520.0   \n",
              "534712               13032               1644.0              2498.0   \n",
              "534713               13032               1607.0              2416.0   \n",
              "\n",
              "         Packet Length Variance  FIN Flag Count   SYN Flag Count  \\\n",
              "534666                7125639.5               0                0   \n",
              "534669                5827835.0               0                0   \n",
              "534672                5673493.5               0                0   \n",
              "534675                5654668.0               0                0   \n",
              "534678                5893662.5               0                0   \n",
              "534692                5894571.0               0                0   \n",
              "534695                6109806.0               0                0   \n",
              "534708                5893055.5               0                0   \n",
              "534711                6348930.5               0                0   \n",
              "534712                6244886.0               0                0   \n",
              "534713                5839353.0               0                0   \n",
              "\n",
              "         RST Flag Count   PSH Flag Count   ACK Flag Count   URG Flag Count  \\\n",
              "534666                0                1                0                0   \n",
              "534669                0                0                1                0   \n",
              "534672                0                0                1                0   \n",
              "534675                0                0                1                0   \n",
              "534678                0                0                1                0   \n",
              "534692                0                0                1                0   \n",
              "534695                0                0                1                0   \n",
              "534708                0                0                1                0   \n",
              "534711                0                0                1                0   \n",
              "534712                0                0                1                0   \n",
              "534713                0                0                1                0   \n",
              "\n",
              "         CWE Flag Count   ECE Flag Count   Down/Up Ratio  \\\n",
              "534666                0                0               0   \n",
              "534669                0                0               0   \n",
              "534672                0                0               0   \n",
              "534675                0                0               0   \n",
              "534678                0                0               0   \n",
              "534692                0                0               0   \n",
              "534695                0                0               0   \n",
              "534708                0                0               0   \n",
              "534711                0                0               0   \n",
              "534712                0                0               0   \n",
              "534713                0                0               0   \n",
              "\n",
              "         Average Packet Size   Avg Fwd Segment Size   Avg Bwd Segment Size  \\\n",
              "534666                1714.0                  3.092                 4372.0   \n",
              "534669                1611.0                  4.910                 3734.0   \n",
              "534672                1604.0                  4.390                 3700.0   \n",
              "534675                1610.0                  4.914                 3726.0   \n",
              "534678                1620.0                  3.367                 3774.0   \n",
              "534692                1620.0                  4.410                 3768.0   \n",
              "534695                1621.0                  4.380                 3808.0   \n",
              "534708                1610.0                  7.445                 3780.0   \n",
              "534711                1634.0                  4.887                 3884.0   \n",
              "534712                1644.0                  4.902                 3928.0   \n",
              "534713                1608.0                 12.620                 3754.0   \n",
              "\n",
              "         Fwd Header Length.1  Fwd Avg Bytes/Bulk   Fwd Avg Packets/Bulk  \\\n",
              "534666                 85928                   0                      0   \n",
              "534669                 89356                   0                      0   \n",
              "534672                 89408                   0                      0   \n",
              "534675                 89312                   0                      0   \n",
              "534678                 89024                   0                      0   \n",
              "534692                 89024                   0                      0   \n",
              "534695                 89632                   0                      0   \n",
              "534708                 89664                   0                      0   \n",
              "534711                 89772                   0                      0   \n",
              "534712                 89504                   0                      0   \n",
              "534713                 18880                   0                      0   \n",
              "\n",
              "         Fwd Avg Bulk Rate   Bwd Avg Bytes/Bulk   Bwd Avg Packets/Bulk  \\\n",
              "534666                   0                    0                      0   \n",
              "534669                   0                    0                      0   \n",
              "534672                   0                    0                      0   \n",
              "534675                   0                    0                      0   \n",
              "534678                   0                    0                      0   \n",
              "534692                   0                    0                      0   \n",
              "534695                   0                    0                      0   \n",
              "534708                   0                    0                      0   \n",
              "534711                   0                    0                      0   \n",
              "534712                   0                    0                      0   \n",
              "534713                   0                    0                      0   \n",
              "\n",
              "        Bwd Avg Bulk Rate  Subflow Fwd Packets   Subflow Fwd Bytes  \\\n",
              "534666                  0                 2685                8299   \n",
              "534669                  0                 2792               13712   \n",
              "534672                  0                 2794               12264   \n",
              "534675                  0                 2791               13712   \n",
              "534678                  0                 2782                9368   \n",
              "534692                  0                 2782               12264   \n",
              "534695                  0                 2801               12264   \n",
              "534708                  0                 2802               20858   \n",
              "534711                  0                 2805               13712   \n",
              "534712                  0                 2797               13712   \n",
              "534713                  0                  590                7442   \n",
              "\n",
              "         Subflow Bwd Packets   Subflow Bwd Bytes  Init_Win_bytes_forward  \\\n",
              "534666                  1729             7556917                   29200   \n",
              "534669                  2110             7878135                     235   \n",
              "534672                  2130             7879536                     235   \n",
              "534675                  2114             7878088                     235   \n",
              "534678                  2089             7882432                     235   \n",
              "534692                  2091             7879536                     235   \n",
              "534695                  2069             7879536                     235   \n",
              "534708                  2067             7812389                     235   \n",
              "534711                  2028             7878627                     349   \n",
              "534712                  2006             7878088                     349   \n",
              "534713                   436             1636683                     349   \n",
              "\n",
              "         Init_Win_bytes_backward   act_data_pkt_fwd   min_seg_size_forward  \\\n",
              "534666                       235                118                     32   \n",
              "534669                       235                120                     32   \n",
              "534672                       235                120                     32   \n",
              "534675                       235                120                     32   \n",
              "534678                       235                120                     32   \n",
              "534692                       235                120                     32   \n",
              "534695                       235                120                     32   \n",
              "534708                       349                123                     32   \n",
              "534711                       349                120                     32   \n",
              "534712                       349                120                     32   \n",
              "534713                       349                 25                     32   \n",
              "\n",
              "        Active Mean   Active Std   Active Max   Active Min  Idle Mean  \\\n",
              "534666       2217.0          0.0         2217         2217  5024984.0   \n",
              "534669          0.0          0.0            0            0        0.0   \n",
              "534672          0.0          0.0            0            0        0.0   \n",
              "534675          0.0          0.0            0            0        0.0   \n",
              "534678          0.0          0.0            0            0        0.0   \n",
              "534692          0.0          0.0            0            0        0.0   \n",
              "534695          0.0          0.0            0            0        0.0   \n",
              "534708          0.0          0.0            0            0        0.0   \n",
              "534711          0.0          0.0            0            0        0.0   \n",
              "534712          0.0          0.0            0            0        0.0   \n",
              "534713          0.0          0.0            0            0        0.0   \n",
              "\n",
              "         Idle Std   Idle Max   Idle Min       Label  \n",
              "534666        0.0    5024984    5024984  Heartbleed  \n",
              "534669        0.0          0          0  Heartbleed  \n",
              "534672        0.0          0          0  Heartbleed  \n",
              "534675        0.0          0          0  Heartbleed  \n",
              "534678        0.0          0          0  Heartbleed  \n",
              "534692        0.0          0          0  Heartbleed  \n",
              "534695        0.0          0          0  Heartbleed  \n",
              "534708        0.0          0          0  Heartbleed  \n",
              "534711        0.0          0          0  Heartbleed  \n",
              "534712        0.0          0          0  Heartbleed  \n",
              "534713        0.0          0          0  Heartbleed  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c171ccb-9d76-4fcc-8d87-bcde0aad968d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>534666</th>\n",
              "      <td>444</td>\n",
              "      <td>119302728</td>\n",
              "      <td>2685</td>\n",
              "      <td>1729</td>\n",
              "      <td>8299</td>\n",
              "      <td>7556917</td>\n",
              "      <td>517</td>\n",
              "      <td>0</td>\n",
              "      <td>3.092</td>\n",
              "      <td>16.86</td>\n",
              "      <td>17376</td>\n",
              "      <td>0</td>\n",
              "      <td>4372.0</td>\n",
              "      <td>2566.0</td>\n",
              "      <td>63411.92802</td>\n",
              "      <td>36.998316</td>\n",
              "      <td>27034.383</td>\n",
              "      <td>174625.77</td>\n",
              "      <td>5024984</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>44449.508</td>\n",
              "      <td>222461.72</td>\n",
              "      <td>5025702</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>69040.910</td>\n",
              "      <td>273867.44</td>\n",
              "      <td>5024984</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85928</td>\n",
              "      <td>55336</td>\n",
              "      <td>22.505772</td>\n",
              "      <td>14.492544</td>\n",
              "      <td>0</td>\n",
              "      <td>17376</td>\n",
              "      <td>1714.0</td>\n",
              "      <td>2670.0</td>\n",
              "      <td>7125639.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1714.0</td>\n",
              "      <td>3.092</td>\n",
              "      <td>4372.0</td>\n",
              "      <td>85928</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2685</td>\n",
              "      <td>8299</td>\n",
              "      <td>1729</td>\n",
              "      <td>7556917</td>\n",
              "      <td>29200</td>\n",
              "      <td>235</td>\n",
              "      <td>118</td>\n",
              "      <td>32</td>\n",
              "      <td>2217.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2217</td>\n",
              "      <td>2217</td>\n",
              "      <td>5024984.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5024984</td>\n",
              "      <td>5024984</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534669</th>\n",
              "      <td>444</td>\n",
              "      <td>119262215</td>\n",
              "      <td>2792</td>\n",
              "      <td>2110</td>\n",
              "      <td>13712</td>\n",
              "      <td>7878135</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>4.910</td>\n",
              "      <td>110.40</td>\n",
              "      <td>14480</td>\n",
              "      <td>0</td>\n",
              "      <td>3734.0</td>\n",
              "      <td>2366.0</td>\n",
              "      <td>66172.23234</td>\n",
              "      <td>41.102708</td>\n",
              "      <td>24334.262</td>\n",
              "      <td>152902.28</td>\n",
              "      <td>995350</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42730.980</td>\n",
              "      <td>200884.22</td>\n",
              "      <td>996350</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>56549.170</td>\n",
              "      <td>229177.94</td>\n",
              "      <td>995350</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89356</td>\n",
              "      <td>67520</td>\n",
              "      <td>23.410600</td>\n",
              "      <td>17.692108</td>\n",
              "      <td>0</td>\n",
              "      <td>14480</td>\n",
              "      <td>1611.0</td>\n",
              "      <td>2414.0</td>\n",
              "      <td>5827835.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1611.0</td>\n",
              "      <td>4.910</td>\n",
              "      <td>3734.0</td>\n",
              "      <td>89356</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2792</td>\n",
              "      <td>13712</td>\n",
              "      <td>2110</td>\n",
              "      <td>7878135</td>\n",
              "      <td>235</td>\n",
              "      <td>235</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534672</th>\n",
              "      <td>444</td>\n",
              "      <td>119261118</td>\n",
              "      <td>2794</td>\n",
              "      <td>2130</td>\n",
              "      <td>12264</td>\n",
              "      <td>7879536</td>\n",
              "      <td>4344</td>\n",
              "      <td>0</td>\n",
              "      <td>4.390</td>\n",
              "      <td>83.20</td>\n",
              "      <td>13032</td>\n",
              "      <td>0</td>\n",
              "      <td>3700.0</td>\n",
              "      <td>2314.0</td>\n",
              "      <td>66172.44692</td>\n",
              "      <td>41.287555</td>\n",
              "      <td>24225.293</td>\n",
              "      <td>152596.56</td>\n",
              "      <td>995259</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42699.918</td>\n",
              "      <td>200852.50</td>\n",
              "      <td>996402</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>56017.426</td>\n",
              "      <td>228206.64</td>\n",
              "      <td>995259</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89408</td>\n",
              "      <td>68160</td>\n",
              "      <td>23.427586</td>\n",
              "      <td>17.859970</td>\n",
              "      <td>0</td>\n",
              "      <td>13032</td>\n",
              "      <td>1603.0</td>\n",
              "      <td>2382.0</td>\n",
              "      <td>5673493.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1604.0</td>\n",
              "      <td>4.390</td>\n",
              "      <td>3700.0</td>\n",
              "      <td>89408</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2794</td>\n",
              "      <td>12264</td>\n",
              "      <td>2130</td>\n",
              "      <td>7879536</td>\n",
              "      <td>235</td>\n",
              "      <td>235</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534675</th>\n",
              "      <td>444</td>\n",
              "      <td>119260295</td>\n",
              "      <td>2791</td>\n",
              "      <td>2114</td>\n",
              "      <td>13712</td>\n",
              "      <td>7878088</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>4.914</td>\n",
              "      <td>110.40</td>\n",
              "      <td>13032</td>\n",
              "      <td>0</td>\n",
              "      <td>3726.0</td>\n",
              "      <td>2284.0</td>\n",
              "      <td>66172.90356</td>\n",
              "      <td>41.128525</td>\n",
              "      <td>24318.984</td>\n",
              "      <td>152794.80</td>\n",
              "      <td>995259</td>\n",
              "      <td>-1</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42745.530</td>\n",
              "      <td>200841.34</td>\n",
              "      <td>997791</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>56441.210</td>\n",
              "      <td>228878.53</td>\n",
              "      <td>995259</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89312</td>\n",
              "      <td>67648</td>\n",
              "      <td>23.402592</td>\n",
              "      <td>17.725933</td>\n",
              "      <td>0</td>\n",
              "      <td>13032</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>2378.0</td>\n",
              "      <td>5654668.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>4.914</td>\n",
              "      <td>3726.0</td>\n",
              "      <td>89312</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2791</td>\n",
              "      <td>13712</td>\n",
              "      <td>2114</td>\n",
              "      <td>7878088</td>\n",
              "      <td>235</td>\n",
              "      <td>235</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534678</th>\n",
              "      <td>444</td>\n",
              "      <td>119297996</td>\n",
              "      <td>2782</td>\n",
              "      <td>2089</td>\n",
              "      <td>9368</td>\n",
              "      <td>7882432</td>\n",
              "      <td>1448</td>\n",
              "      <td>0</td>\n",
              "      <td>3.367</td>\n",
              "      <td>30.50</td>\n",
              "      <td>17376</td>\n",
              "      <td>0</td>\n",
              "      <td>3774.0</td>\n",
              "      <td>2372.0</td>\n",
              "      <td>66151.99135</td>\n",
              "      <td>40.830527</td>\n",
              "      <td>24496.508</td>\n",
              "      <td>153244.69</td>\n",
              "      <td>995302</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42897.500</td>\n",
              "      <td>201057.42</td>\n",
              "      <td>998229</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>57135.035</td>\n",
              "      <td>230051.98</td>\n",
              "      <td>995302</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89024</td>\n",
              "      <td>66848</td>\n",
              "      <td>23.319756</td>\n",
              "      <td>17.510773</td>\n",
              "      <td>0</td>\n",
              "      <td>17376</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>2428.0</td>\n",
              "      <td>5893662.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>3.367</td>\n",
              "      <td>3774.0</td>\n",
              "      <td>89024</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2782</td>\n",
              "      <td>9368</td>\n",
              "      <td>2089</td>\n",
              "      <td>7882432</td>\n",
              "      <td>235</td>\n",
              "      <td>235</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534692</th>\n",
              "      <td>444</td>\n",
              "      <td>119259886</td>\n",
              "      <td>2782</td>\n",
              "      <td>2091</td>\n",
              "      <td>12264</td>\n",
              "      <td>7879536</td>\n",
              "      <td>4344</td>\n",
              "      <td>0</td>\n",
              "      <td>4.410</td>\n",
              "      <td>83.40</td>\n",
              "      <td>15928</td>\n",
              "      <td>0</td>\n",
              "      <td>3768.0</td>\n",
              "      <td>2374.0</td>\n",
              "      <td>66173.13050</td>\n",
              "      <td>40.860344</td>\n",
              "      <td>24478.630</td>\n",
              "      <td>153117.48</td>\n",
              "      <td>995232</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42883.793</td>\n",
              "      <td>200919.11</td>\n",
              "      <td>996222</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>57062.140</td>\n",
              "      <td>229801.25</td>\n",
              "      <td>995232</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89024</td>\n",
              "      <td>66912</td>\n",
              "      <td>23.327206</td>\n",
              "      <td>17.533138</td>\n",
              "      <td>0</td>\n",
              "      <td>15928</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>2428.0</td>\n",
              "      <td>5894571.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>4.410</td>\n",
              "      <td>3768.0</td>\n",
              "      <td>89024</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2782</td>\n",
              "      <td>12264</td>\n",
              "      <td>2091</td>\n",
              "      <td>7879536</td>\n",
              "      <td>235</td>\n",
              "      <td>235</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534695</th>\n",
              "      <td>444</td>\n",
              "      <td>119259012</td>\n",
              "      <td>2801</td>\n",
              "      <td>2069</td>\n",
              "      <td>12264</td>\n",
              "      <td>7879536</td>\n",
              "      <td>4344</td>\n",
              "      <td>0</td>\n",
              "      <td>4.380</td>\n",
              "      <td>83.10</td>\n",
              "      <td>15928</td>\n",
              "      <td>0</td>\n",
              "      <td>3808.0</td>\n",
              "      <td>2460.0</td>\n",
              "      <td>66173.61546</td>\n",
              "      <td>40.835488</td>\n",
              "      <td>24493.533</td>\n",
              "      <td>153287.53</td>\n",
              "      <td>995262</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42592.480</td>\n",
              "      <td>200437.97</td>\n",
              "      <td>996257</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>57668.760</td>\n",
              "      <td>231138.53</td>\n",
              "      <td>995262</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89632</td>\n",
              "      <td>66208</td>\n",
              "      <td>23.486694</td>\n",
              "      <td>17.348793</td>\n",
              "      <td>0</td>\n",
              "      <td>15928</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>2472.0</td>\n",
              "      <td>6109806.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4.380</td>\n",
              "      <td>3808.0</td>\n",
              "      <td>89632</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2801</td>\n",
              "      <td>12264</td>\n",
              "      <td>2069</td>\n",
              "      <td>7879536</td>\n",
              "      <td>235</td>\n",
              "      <td>235</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534708</th>\n",
              "      <td>444</td>\n",
              "      <td>119257653</td>\n",
              "      <td>2802</td>\n",
              "      <td>2067</td>\n",
              "      <td>20858</td>\n",
              "      <td>7812389</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>7.445</td>\n",
              "      <td>126.06</td>\n",
              "      <td>13032</td>\n",
              "      <td>0</td>\n",
              "      <td>3780.0</td>\n",
              "      <td>2380.0</td>\n",
              "      <td>65683.39057</td>\n",
              "      <td>40.827569</td>\n",
              "      <td>24498.285</td>\n",
              "      <td>153803.62</td>\n",
              "      <td>1995346</td>\n",
              "      <td>-1</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42576.800</td>\n",
              "      <td>201441.28</td>\n",
              "      <td>1996118</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>57723.930</td>\n",
              "      <td>233324.72</td>\n",
              "      <td>1995346</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89664</td>\n",
              "      <td>66144</td>\n",
              "      <td>23.495348</td>\n",
              "      <td>17.332220</td>\n",
              "      <td>0</td>\n",
              "      <td>13032</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>2428.0</td>\n",
              "      <td>5893055.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>7.445</td>\n",
              "      <td>3780.0</td>\n",
              "      <td>89664</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2802</td>\n",
              "      <td>20858</td>\n",
              "      <td>2067</td>\n",
              "      <td>7812389</td>\n",
              "      <td>235</td>\n",
              "      <td>349</td>\n",
              "      <td>123</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534711</th>\n",
              "      <td>444</td>\n",
              "      <td>119299621</td>\n",
              "      <td>2805</td>\n",
              "      <td>2028</td>\n",
              "      <td>13712</td>\n",
              "      <td>7878627</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>4.887</td>\n",
              "      <td>110.10</td>\n",
              "      <td>17376</td>\n",
              "      <td>0</td>\n",
              "      <td>3884.0</td>\n",
              "      <td>2524.0</td>\n",
              "      <td>66155.60832</td>\n",
              "      <td>40.511445</td>\n",
              "      <td>24689.490</td>\n",
              "      <td>152728.52</td>\n",
              "      <td>996008</td>\n",
              "      <td>-1</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42531.965</td>\n",
              "      <td>199646.58</td>\n",
              "      <td>996884</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>58855.258</td>\n",
              "      <td>232967.11</td>\n",
              "      <td>996008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89772</td>\n",
              "      <td>64896</td>\n",
              "      <td>23.512228</td>\n",
              "      <td>16.999216</td>\n",
              "      <td>0</td>\n",
              "      <td>17376</td>\n",
              "      <td>1634.0</td>\n",
              "      <td>2520.0</td>\n",
              "      <td>6348930.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1634.0</td>\n",
              "      <td>4.887</td>\n",
              "      <td>3884.0</td>\n",
              "      <td>89772</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2805</td>\n",
              "      <td>13712</td>\n",
              "      <td>2028</td>\n",
              "      <td>7878627</td>\n",
              "      <td>349</td>\n",
              "      <td>349</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534712</th>\n",
              "      <td>444</td>\n",
              "      <td>119296592</td>\n",
              "      <td>2797</td>\n",
              "      <td>2006</td>\n",
              "      <td>13712</td>\n",
              "      <td>7878088</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>4.902</td>\n",
              "      <td>110.25</td>\n",
              "      <td>13032</td>\n",
              "      <td>0</td>\n",
              "      <td>3928.0</td>\n",
              "      <td>2444.0</td>\n",
              "      <td>66152.76990</td>\n",
              "      <td>40.260999</td>\n",
              "      <td>24843.105</td>\n",
              "      <td>153403.72</td>\n",
              "      <td>995988</td>\n",
              "      <td>-1</td>\n",
              "      <td>119000000</td>\n",
              "      <td>42666.880</td>\n",
              "      <td>200137.52</td>\n",
              "      <td>996943</td>\n",
              "      <td>0</td>\n",
              "      <td>119000000</td>\n",
              "      <td>59480.766</td>\n",
              "      <td>234233.89</td>\n",
              "      <td>995988</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89504</td>\n",
              "      <td>64192</td>\n",
              "      <td>23.445766</td>\n",
              "      <td>16.815233</td>\n",
              "      <td>0</td>\n",
              "      <td>13032</td>\n",
              "      <td>1644.0</td>\n",
              "      <td>2498.0</td>\n",
              "      <td>6244886.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1644.0</td>\n",
              "      <td>4.902</td>\n",
              "      <td>3928.0</td>\n",
              "      <td>89504</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2797</td>\n",
              "      <td>13712</td>\n",
              "      <td>2006</td>\n",
              "      <td>7878088</td>\n",
              "      <td>349</td>\n",
              "      <td>349</td>\n",
              "      <td>120</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534713</th>\n",
              "      <td>444</td>\n",
              "      <td>24719667</td>\n",
              "      <td>590</td>\n",
              "      <td>436</td>\n",
              "      <td>7442</td>\n",
              "      <td>1636683</td>\n",
              "      <td>5792</td>\n",
              "      <td>0</td>\n",
              "      <td>12.620</td>\n",
              "      <td>238.80</td>\n",
              "      <td>13032</td>\n",
              "      <td>0</td>\n",
              "      <td>3754.0</td>\n",
              "      <td>2364.0</td>\n",
              "      <td>66510.80696</td>\n",
              "      <td>41.505413</td>\n",
              "      <td>24116.748</td>\n",
              "      <td>149983.89</td>\n",
              "      <td>995832</td>\n",
              "      <td>0</td>\n",
              "      <td>24700000</td>\n",
              "      <td>41968.875</td>\n",
              "      <td>197466.20</td>\n",
              "      <td>996919</td>\n",
              "      <td>0</td>\n",
              "      <td>24100000</td>\n",
              "      <td>55301.758</td>\n",
              "      <td>225933.60</td>\n",
              "      <td>995832</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18880</td>\n",
              "      <td>13952</td>\n",
              "      <td>23.867636</td>\n",
              "      <td>17.637777</td>\n",
              "      <td>0</td>\n",
              "      <td>13032</td>\n",
              "      <td>1607.0</td>\n",
              "      <td>2416.0</td>\n",
              "      <td>5839353.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1608.0</td>\n",
              "      <td>12.620</td>\n",
              "      <td>3754.0</td>\n",
              "      <td>18880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>590</td>\n",
              "      <td>7442</td>\n",
              "      <td>436</td>\n",
              "      <td>1636683</td>\n",
              "      <td>349</td>\n",
              "      <td>349</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heartbleed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c171ccb-9d76-4fcc-8d87-bcde0aad968d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c171ccb-9d76-4fcc-8d87-bcde0aad968d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c171ccb-9d76-4fcc-8d87-bcde0aad968d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-677f733e-6ccc-473e-a89e-af67b5e7d84a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-677f733e-6ccc-473e-a89e-af67b5e7d84a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-677f733e-6ccc-473e-a89e-af67b5e7d84a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "—Ç–∞–º –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö –ø–æ–ª—É—á–∞—é—Ç—Å—è –Ω—É–ª–∏. –î–∞–Ω–Ω—ã—Ö –º–∞–ª–æ –ø–æ —ç—Ç–æ–º—É –∫–ª–∞—Å—Å—É, –∏ –µ—â–µ –∏ —Ç–∞–∫ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ. –ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —Å —ç—Ç–∏–º –Ω–∏—á–µ–≥–æ –Ω–µ–ª—å–∑—è –æ—Å–æ–±–æ —Å–¥–µ–ª–∞—Ç—å..."
      ],
      "metadata": {
        "id": "oNOgftddruFG"
      },
      "id": "oNOgftddruFG"
    },
    {
      "cell_type": "markdown",
      "id": "kwe74IhYvM3w",
      "metadata": {
        "id": "kwe74IhYvM3w"
      },
      "source": [
        "–õ—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–æ–±–∏—Ç—å—Å—è –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ª—å–∫–æ —è –±—ã –º–æ–¥–µ–ª—å –Ω–µ –∫—Ä—É—Ç–∏–ª–∞.\n",
        "\n",
        "–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Å—å –Ω–∞ CatBoost, —É –Ω–µ–≥–æ –º–µ—Ç—Ä–∏–∫–∏ —á—É—Ç—å –≤—ã—à–µ —á–µ–º —É –õ–µ—Å–∞."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#–Ω–µ–º–Ω–æ–≥–æ –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏\n",
        "\n",
        "data_final = pd.DataFrame({'–úethod': ['LogisticRegression', 'RandomForestClassifier', 'CatBoostClassifier'],\n",
        "                           'Accuracy': [0.653889, 0.995683, 0.997486],\n",
        "                           'F1_macro': [0.468025, 0.893974, 0.929985]})"
      ],
      "metadata": {
        "id": "ozQt2ftSvAS2"
      },
      "id": "ozQt2ftSvAS2",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_final"
      ],
      "metadata": {
        "id": "XHhA3zl-vEs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "5a6691f8-7806-4ec8-a0e7-718b1eea9e0d"
      },
      "id": "XHhA3zl-vEs8",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   –úethod  Accuracy  F1_macro\n",
              "0      LogisticRegression  0.653889  0.468025\n",
              "1  RandomForestClassifier  0.995683  0.893974\n",
              "2      CatBoostClassifier  0.997486  0.929985"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4b10b04-177e-4c07-b7ea-b3bac591712f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>–úethod</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.653889</td>\n",
              "      <td>0.468025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.995683</td>\n",
              "      <td>0.893974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoostClassifier</td>\n",
              "      <td>0.997486</td>\n",
              "      <td>0.929985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b10b04-177e-4c07-b7ea-b3bac591712f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4b10b04-177e-4c07-b7ea-b3bac591712f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4b10b04-177e-4c07-b7ea-b3bac591712f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f5d750e-d257-40da-b872-ebbe81e244e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f5d750e-d257-40da-b872-ebbe81e244e9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f5d750e-d257-40da-b872-ebbe81e244e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_final[['–úethod', 'Accuracy', 'F1_macro']].plot(x='–úethod', kind='bar')"
      ],
      "metadata": {
        "id": "5COHzez3xVRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "165121de-0586-4341-b398-5dab429c9b41"
      },
      "id": "5COHzez3xVRJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='–úethod'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dw3G26zy17gq",
      "metadata": {
        "id": "Dw3G26zy17gq"
      },
      "source": [
        "### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03d19b32",
      "metadata": {
        "id": "03d19b32"
      },
      "outputs": [],
      "source": [
        "model_bas_cb.save_model('model.cbm', format=\"cbm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NA-cFSBW2S3A",
      "metadata": {
        "id": "NA-cFSBW2S3A"
      },
      "source": [
        "### –ß–∏—Ç–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e246574d",
      "metadata": {
        "id": "e246574d"
      },
      "outputs": [],
      "source": [
        "model = CatBoostClassifier()      # parameters not required.\n",
        "model.load_model('model.cbm')\n",
        "\n",
        "\n",
        "preds = model.predict(features_test)\n",
        "\n",
        "print('–ú–µ—Ç—Ä–∏–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:')\n",
        "preds\n",
        "print(' ')\n",
        "print (\"Accuracy:\",accuracy_score(target_test, preds))\n",
        "print (\"F1_macro:\", f1_score(target_test, preds, average='macro'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XXI_VHfgxENB",
      "metadata": {
        "id": "XXI_VHfgxENB"
      },
      "source": [
        "F1 –Ω–∞ —Ç–µ—Å—Ç–µ —á—É—Ç—å —Ö—É–∂–µ, –Ω–æ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –Ω–∞–≤–µ—Ä–Ω–æ–µ."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}